# Foundational Research Priority Analysis

**Review Date:** November 2, 2025  
**Purpose:** Evaluate FOUNDATIONAL_RESEARCH_SYNTHESIS.md to identify high-value vs. redundant/conflicting directions  
**Context:** System already 90%+ complete per REVIEW_STATUS_SUMMARY.md, dialogue visualization roadmap complete (Phases 1-7)

---

## üéØ Executive Summary

The FOUNDATIONAL_RESEARCH_SYNTHESIS document proposes **7 major theoretical frameworks** from academic papers. After analyzing against the **current system state** (90% complete, production-ready), here's the priority breakdown:

### ‚úÖ **KEEP/PURSUE:** Worth Pursuing (High ROI)
1. **Dialogue Visualization** (Phases 1-7 already documented) ‚Äî **READY TO IMPLEMENT**
   - Roadmap complete, no conflicts, clear UX value
   - 16 weeks implementation time
2. **Per-Derivation Assumption Tracking** ‚Äî **‚úÖ ALREADY COMPLETE** (Gap 4 resolved Jan 2025)
   - Completed January 2025, now focus on UI visualization
3. **Confidence-Scheme Integration** ‚Äî **HIGH VALUE, LOW EFFORT** (3-5 hours)
   - Backend exists, just needs wiring
   - Immediate value
4. **Ludics Formalization** ‚Äî **UNIQUE INNOVATION** (already 95% done, needs documentation)
   - Already 95% implemented
   - Publication opportunity (8-10 hours documentation)

### ‚è∏Ô∏è **DEFERRED:** Side Project / Research Contribution (Not Blocking Production)
5. **Topological Argumentation Model** ‚Äî **PhD-LEVEL RESEARCH PROJECT**
   - 3-4 weeks effort, no clear UX benefit
   - Better as academic paper than production feature
   - Consider as separate research contribution, not core platform feature

### ‚ùå **REMOVED:** Not Included in Any Roadmaps / Not Part of Project
6. **DDF 8-Stage Protocol** ‚Äî **FRAMEWORK CLASH**
   - Conflicts with existing dialogue move system
   - 8 weeks effort, unclear benefit
   - Current system already works well
7. **Sentence Type Ontology** (6 types) ‚Äî **BREAKING CHANGE**
   - Would require rewriting Claim model
   - Unclear user benefit
   - Better to use flexible `tags` field if needed
8. **Commitment Stores** ‚Äî **REDUNDANT**
   - DialogueMove table already tracks this
   - Would duplicate data
9. **Haskell/Agda Verification** ‚Äî **WRONG STACK**
   - 3-4 months to rewrite in different language
   - Property-based testing (QuickCheck) is 95% as good
10. **DisCoCat NLP** ‚Äî **OVERKILL**
    - Current embeddings work fine
    - 2-3 weeks complexity for marginal benefit
11. **PCR5/PCR6 Conflict Resolution** ‚Äî **NO USE CASE**
    - Solves problem that doesn't exist in Mesh's domain

---

## üìä Framework-by-Framework Analysis

---

## 1. ‚úÖ **Dialogue Visualization** (Phases 1-7 Roadmap)

### Status: **READY TO IMPLEMENT** ‚Äî Roadmap complete, no theoretical conflicts

**What It Is:**
- Visual representation of dialogue moves in AIF diagrams
- Timeline playback with video-like controls
- Scheme provenance badges showing CQ dialogue history

**Why It's Worth Pursuing:**
- ‚úÖ **Complements existing system** (doesn't require rewrites)
- ‚úÖ **Clear UX benefit** (users can see dialogue flow)
- ‚úÖ **Implementation ready** (detailed 9-phase roadmap exists)
- ‚úÖ **No framework conflicts** (integrates with current DialogueMove model)

**Effort Estimate:** 16 weeks (documented in roadmap)

**ROI:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **HIGHEST PRIORITY** ‚Äî Clear path, high user value, no risks

**Recommendation:** **START IMMEDIATELY** with Phase 1 (database schema extensions)

---

## 2. ‚úÖ **Per-Derivation Assumption Tracking** (Gap 4)

### Status: **‚úÖ ALREADY COMPLETE** (January 2025)

**What It Was:**
- Track which assumptions each argument derivation relies on
- Compute minimal assumption sets
- Enable belief revision ("culprit set" identification)

**Why It Was Worth Pursuing:**
- ‚úÖ **Enables belief revision UX** (show "if you reject X, you must also reject Y")
- ‚úÖ **Research contribution** (unique to Mesh)
- ‚úÖ **Categorical alignment** (proper morphism composition)

**What's Implemented:**
- ‚úÖ `DerivationAssumption` table with per-derivation granularity
- ‚úÖ Arrow type updated: `assumptions: Map<DerivationId, Set<AssumptionId>>`
- ‚úÖ Four new API endpoints (fetch/link/minimal/graph)
- ‚úÖ Client wrappers in `lib/client/evidential.ts`
- ‚úÖ 30/30 tests passing

**ROI:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **COMPLETED** ‚Äî Major capability unlocked

**Recommendation:** **DONE** ‚Äî Now focus on UI visualization of assumption graphs

---

## 3. ‚úÖ **Confidence-Scheme Integration** (Quick Win)

### Status: **NOT IMPLEMENTED** ‚Äî Backend exists, just needs wiring (3-5 hours)

**What It Is:**
- Use `ArgumentScheme.validators.baseConfidence` in confidence scoring
- Apply CQ satisfaction penalty: `strength *= 0.85^unsatisfiedCount`
- Add temporal decay: `decay = 0.5^(ageInDays / halfLife)`

**Why It's Worth Pursuing:**
- ‚úÖ **Leverage existing data** (schemes already have validators)
- ‚úÖ **Research-backed** (Macagno taxonomy already implemented)
- ‚úÖ **Low effort** (API changes only, no UI required initially)
- ‚úÖ **Immediate benefit** (more accurate confidence scores)

**Implementation Steps:**
```typescript
// In /api/evidential/score/route.ts:

// 1. Fetch scheme base confidence
const scheme = await prisma.argumentationScheme.findUnique({
  where: { id: argument.schemeId },
  select: { validators: true }
});
const baseConf = (scheme?.validators as any)?.baseConfidence ?? 0.6;

// 2. Apply CQ penalty
const unsatisfiedCQs = cqMap.get(argument.id) ?? 0;
const cqPenalty = Math.pow(0.85, unsatisfiedCQs);

// 3. Apply temporal decay (if halfLife set)
const ageInDays = (Date.now() - argument.createdAt.getTime()) / (1000*60*60*24);
const halfLife = (scheme?.validators as any)?.halfLife ?? Infinity;
const decay = Math.pow(0.5, ageInDays / halfLife);

// 4. Combine
const finalStrength = baseConf * cqPenalty * decay;
```

**Effort Estimate:** 3-5 hours

**ROI:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê **HIGH PRIORITY** ‚Äî Low effort, immediate value

**Recommendation:** **DO NEXT** after dialogue viz Phase 1

---

## 4. ‚úÖ **Ludics Formalization** (Documentation Only)

### Status: **95% IMPLEMENTED** ‚Äî Just needs formal specification

**What It Is:**
- Formalize the daimon (‚Ä†) closure rules
- Document when dialogue branches become "closable"
- Write specification for `stepInteraction` algorithm

**Why It's Worth Pursuing:**
- ‚úÖ **Unique innovation** (no other system has this!)
- ‚úÖ **Already working** (LudicsPanel, legal moves API)
- ‚úÖ **Publication opportunity** (COMMA/IJCAI paper)
- ‚úÖ **Low effort** (documentation, not code)

**What's Needed:**
1. Formal specification document (LaTeX or Markdown)
2. Ludics primer for developers
3. Research paper draft

**Effort Estimate:** 8-10 hours (documentation only)

**ROI:** ‚≠ê‚≠ê‚≠ê‚≠ê **MEDIUM-HIGH PRIORITY** ‚Äî Research contribution, low implementation cost

**Recommendation:** **DO IN PARALLEL** with Phase 2-3 of dialogue viz (documentation work doesn't block coding)

---

## 5. ‚ö†Ô∏è **DDF 8-Stage Protocol** (DEFER)

### Status: **NOT IMPLEMENTED** ‚Äî Conflicts with existing dialogue system

**What It Is:**
- Formal 8-stage protocol: OPEN ‚Üí INFORM ‚Üí PROPOSE ‚Üí CONSIDER ‚Üí REVISE ‚Üí RECOMMEND ‚Üí CONFIRM ‚Üí CLOSE
- Locutions: `assert`, `ask_justify`, `move(.)`, `retract`, `prefer`, `withdraw`
- Commitment stores (per-participant public assertions)
- Embedded persuasion dialogues

**Why It's Problematic:**

#### Conceptual Conflict 1: Current Dialogue Moves Already Work
**Existing System:**
- 9 move types: WHY, GROUNDS, CONCEDE, RETRACT, CLOSE, ACCEPT_ARGUMENT, THEREFORE, SUPPOSE, DISCHARGE
- Threaded replies with `replyTargetId`
- 8 validation rules (R1-R8)
- Ludics integration for closure detection

**DDF Requires:**
- Replace with locution types (completely different model)
- Stage-based validation (different from current R1-R8)
- CONFIRM stage requires unanimity (not compatible with current acceptance model)

**Impact:** ‚ö†Ô∏è **BREAKING CHANGE** ‚Äî Would require rewriting entire `DialogueMove` system

---

#### Conceptual Conflict 2: Commitment Stores vs. Dialogue Moves
**DDF:** Each participant has a **Commitment Store** (CS) - explicit list of assertions

**Mesh:** Dialogue moves **implicitly** create commitments:
- WHY = challenging a claim
- GROUNDS = supporting a position
- CONCEDE = retracting opposition
- RETRACT = withdrawing a prior move

**Question:** What does commitment store add that dialogue moves don't already provide?

**Answer:** Very little. The moves **are** the commitments. Adding a separate CS would be:
- ‚ùå **Redundant:** Duplicates information in DialogueMove table
- ‚ùå **Synchronization risk:** CS and moves could diverge
- ‚ùå **UI complexity:** Which view is authoritative?

---

#### Conceptual Conflict 3: Embedded Dialogues vs. CQ System
**DDF:** `ask_justify` spawns embedded persuasion dialogue

**Mesh:** Critical Questions already provide justification mechanism:
- CQs challenge specific aspects of arguments
- Responses are submitted as CQResponse records
- Proof obligations enforce structural/semantic verification
- Multi-user collaborative answering

**Question:** What do embedded dialogues add that CQs don't provide?

**Answer:** Mostly just formalism. The CQ system **is** the justification protocol. Making it "embedded" would:
- ‚ùå **Complicate UI:** Nested dialogue contexts confusing
- ‚ùå **Breaking change:** Current CQ system works well
- ‚ùå **No clear benefit:** Users don't need "meta-dialogue" concept

---

#### Effort vs. Benefit Analysis:

| Feature | Effort | Benefit | Worth It? |
|---------|--------|---------|-----------|
| 8-stage tracking | 2 weeks | Formal protocol | ‚ö†Ô∏è Unclear UX value |
| Commitment stores | 1 week | Explicit positions | ‚ùå Redundant with moves |
| Embedded dialogues | 2 weeks | Nested justification | ‚ùå Redundant with CQs |
| Locution types | 3 weeks | Replace move types | ‚ùå Breaking change |
| **TOTAL** | **8 weeks** | **Formalism only** | **‚ùå NOT WORTH IT** |

**ROI:** ‚≠ê **LOW PRIORITY** ‚Äî High effort, unclear benefit, framework clash

**Recommendation:** **DEFER INDEFINITELY** ‚Äî Current dialogue system is production-ready and user-tested. DDF is an **academic framework** that doesn't map cleanly to the existing design. Unless there's a **specific user need** that DDF solves and current system doesn't, this is not worth pursuing.

**Alternative:** Document **how current system maps to DDF concepts** (for academic credibility) without rewriting code.

---

## 6. ‚ö†Ô∏è **Topological Argumentation Model** (DEFER)

### Status: **NOT IMPLEMENTED** ‚Äî PhD-level research project

**What It Is:**
- Model evidence as **open sets** in topology œÑ
- Attack relation: e‚ÇÅ ‚â∫ e‚ÇÇ iff e‚ÇÅ ‚à© e‚ÇÇ = ‚àÖ
- Grounded belief: BP iff ‚àÉf ‚àà LFP_œÑ where f ‚äÜ P
- **Key property:** Belief is **not closed under conjunction** (BP ‚àß Bœà ‚áè B(œÜ ‚àß œà))

**Why It's Interesting:**
- ‚úÖ **Mathematically rigorous** foundation for belief
- ‚úÖ **Handles closure failure** (reflects real reasoning)
- ‚úÖ **Separates deductive capacity from belief formation**

**Why It's Problematic:**

#### Problem 1: No Clear UX Benefit
**Question:** How does a user benefit from topological semantics?

**Current System:**
- Confidence scores: 0.0 - 1.0 (intuitive)
- Three modes: min (skeptical), product (accrual), ds (uncertainty-aware)
- Users understand "this argument has 0.78 confidence"

**Topological System:**
- User sees "grounded belief in œÜ" (yes/no)
- No intermediate scores?
- How to visualize topologies?

**Gap:** ‚ö†Ô∏è **Unclear how to translate mathematical sophistication into user value**

---

#### Problem 2: Significant Implementation Effort

**Required:**
1. Define topology œÑ on evidence sets (how do claims combine?)
2. Compute attack graph A_œÑ = (œÑ, ‚â∫)
3. Implement characteristic function d_œÑ
4. Compute least fixed point LFP_œÑ (iterative)
5. Check membership for grounded belief BP

**Estimated Effort:** 3-4 weeks (complex algorithm, testing, edge cases)

**Question:** What does this replace?
- Current confidence scoring works well
- Dung semantics (grounded/preferred) already implemented
- Users understand probabilistic confidence

**Answer:** ‚ö†Ô∏è **Alternative approach, not improvement** ‚Äî Would coexist with (not replace) current system

---

#### Problem 3: Closure Failure is Philosophically Deep, Practically Rare

**Theoretical Issue:** BP ‚àß Bœà ‚áè B(œÜ ‚àß œà) because grounded extension may exclude conjunctions

**Practical Reality:** In real deliberations:
- Users rarely ask "do I believe P AND Q?"
- Confidence is aggregated per-claim (not per-conjunction)
- If needed, can compute min(conf(P), conf(Q)) as conservative estimate

**Impact:** ‚ö†Ô∏è **Solves theoretical problem that rarely occurs in practice**

---

**ROI:** ‚≠ê‚≠ê **LOW-MEDIUM PRIORITY** ‚Äî High effort, unclear benefit, research-oriented

**Recommendation:** **DEFER** ‚Äî This is a **research contribution** (worthy of publication), not a **production feature**. Better as:
1. Academic paper ("Topological Semantics for Argumentation Platforms")
2. Experimental backend (separate mode, not default)
3. PhD thesis topic

**Alternative:** Document **why current confidence scoring is sufficient** and when topological model would be needed (e.g., when closure failure causes actual user confusion).

---

## 7. ‚ö†Ô∏è **Sentence Type Ontology** (6 Types) (DEFER)

### Status: **NOT IMPLEMENTED** ‚Äî Breaking change to core Claim model

**What It Is:**
- Replace generic "Claim" with 6 types:
  1. **Action** ‚Äî "Implement feature X"
  2. **Goal** ‚Äî "Increase user engagement"
  3. **Constraint** ‚Äî "Budget < $50k"
  4. **Perspective** ‚Äî "Moral, economic, feasibility"
  5. **Fact** ‚Äî "Current traffic is 10k/day"
  6. **Evaluation** ‚Äî "Feature X scores high on moral perspective"

**Why It's Proposed:**
- ‚úÖ **DDF requirement** (deliberation protocol needs types)
- ‚úÖ **Enables practical reasoning** (actions separate from facts)
- ‚úÖ **Value-Based Practical Reasoning** (VPR) scheme needs this

**Why It's Problematic:**

#### Problem 1: Breaking Change to Core Model

**Current Schema:**
```prisma
model Claim {
  id      String @id @default(cuid())
  text    String
  roomId  String
  // ... 50+ other fields, 20+ relations
}
```

**Required Change:**
```prisma
model Claim {
  // ... existing fields
  sentenceType SentenceKind  // NEW REQUIRED FIELD
}

enum SentenceKind {
  ACTION
  GOAL
  CONSTRAINT
  PERSPECTIVE
  FACT
  EVALUATION
}
```

**Migration Issues:**
- ‚ùå **500+ existing claims** ‚Äî How to classify retroactively?
- ‚ùå **Breaking change** ‚Äî All queries need updates
- ‚ùå **UI overhaul** ‚Äî Claim creation form needs type selector
- ‚ùå **Validation logic** ‚Äî Type-specific rules (e.g., actions must have feasibility evaluation)

**Effort Estimate:** 2-3 weeks (schema + migration + UI + validation)

---

#### Problem 2: Unclear User Benefit

**Question:** Do users care about sentence types?

**User Perspective:**
- "I want to post a claim" (current UI)
- "I want to argue for/against something"

**DDF Perspective:**
- "You must first classify: Is this an Action, Goal, Constraint, Fact, Evaluation, or Perspective?"
- User thinks: "...what? I don't know. Just let me post it."

**UX Risk:** ‚ö†Ô∏è **Adds cognitive load** to already complex deliberation process

---

#### Problem 3: VPR Scheme is One of 60+ Schemes

**Current System:**
- 60+ argumentation schemes
- Most don't need sentence types (e.g., "Argument from Expert Opinion" = Fact + Authority)

**VPR Needs:**
- Action + Goal + Value + Evaluation
- Specific to practical reasoning

**Question:** Should we redesign **entire Claim model** for **one scheme**?

**Answer:** ‚ö†Ô∏è **No** ‚Äî Better to:
1. Add `tags` field to Claim (flexible categorization)
2. VPR scheme checks for required tags
3. Other schemes ignore tags

**Alternative Design:**
```prisma
model Claim {
  // ... existing fields
  tags  Json?  // { "type": "action", "domain": "technical", ... }
}
```

**Benefits:**
- ‚úÖ Backward compatible (existing claims have `tags: null`)
- ‚úÖ Flexible (not locked to 6 types)
- ‚úÖ Opt-in (only VPR users need tags)

---

**ROI:** ‚≠ê‚≠ê **LOW PRIORITY** ‚Äî High effort, unclear benefit, breaking change

**Recommendation:** **DEFER** ‚Äî If practical reasoning becomes a major use case:
1. Start with `tags` field (flexible, non-breaking)
2. Add VPR scheme with tag requirements
3. Gather user feedback
4. **Only then** consider formalizing into enum

**Alternative:** Document **how current system supports practical reasoning** without sentence types (e.g., using claim text analysis or user-added tags).

---

## 8. ‚ö†Ô∏è **Commitment Stores** (DEFER)

### Status: **NOT IMPLEMENTED** ‚Äî Redundant with DialogueMove table

**What It Is:**
- Per-participant public-write, public-read data structure
- Tracks all assertions, retractions, preferences
- Updated by locutions (assert/retract/prefer/move)

**Example:**
```
CommitmentStore (User Alice, Deliberation D):
  Assertions:
    - "Climate change is real" (Fact)
    - "We should reduce emissions" (Action)
  Retractions:
    - "Coal is safe" (retracted on 2025-10-15)
  Preferences:
    - Action("reduce emissions") > Action("do nothing")
```

**Why It's Proposed:**
- ‚úÖ **DDF requirement** (formal protocol uses CS)
- ‚úÖ **Burden of proof tracking** (who asserted what)
- ‚úÖ **Enables ask_justify protocol** (challenge anything in CS)

**Why It's Redundant:**

#### Current System Already Tracks This

**DialogueMove table:**
```prisma
model DialogueMove {
  id              String @id
  userId          String           // WHO
  deliberationId  String           // WHERE
  type            DialogueMoveType // WHAT (WHY/GROUNDS/RETRACT/etc.)
  content         String?          // CONTENT
  timestamp       DateTime         // WHEN
  replyTargetId   String?          // CONTEXT
  targetClaimId   String?          // TARGET
  // ...
}
```

**This IS a commitment store!**
- **Assertions:** Moves of type GROUNDS, THEREFORE
- **Challenges:** Moves of type WHY
- **Retractions:** Moves of type RETRACT
- **Preferences:** (implicit in ACCEPT_ARGUMENT vs. attacks)

**Query for "What has Alice asserted in Deliberation D?":**
```typescript
const aliceCommitments = await prisma.dialogueMove.findMany({
  where: {
    userId: aliceId,
    deliberationId: D,
    type: { in: ['GROUNDS', 'THEREFORE', 'ACCEPT_ARGUMENT'] }
  }
});
```

**This query IS the commitment store lookup!**

---

#### Additional Redundancy: Claim.userId

**Every claim has:**
```prisma
model Claim {
  userId  String  // Author/proponent
  roomId  String  // Context
  text    String  // Content
}
```

**This also tracks commitments:**
- "Alice posted claim X" = Alice committed to X
- "Bob attacked claim X" = Bob challenged Alice's commitment

**Question:** What does a separate CommitmentStore table add?

**Answer:** Nothing except:
- ‚ùå Data duplication (same info in 3 places: Claim, DialogueMove, CommitmentStore)
- ‚ùå Synchronization risk (tables could diverge)
- ‚ùå Query complexity (now need joins across 3 tables)

---

**ROI:** ‚≠ê **VERY LOW PRIORITY** ‚Äî Pure redundancy, no added value

**Recommendation:** **DO NOT IMPLEMENT** ‚Äî Document that **DialogueMove table serves as commitment store**. Write mapping guide:
```
DDF Concept         Mesh Implementation
-----------         -------------------
assert(P, fact, œÜ)  Claim.create({ userId: P, text: œÜ })
retract(P, loc)     DialogueMove.create({ type: RETRACT, replyTargetId: loc })
CS_P                DialogueMove.findMany({ where: { userId: P } })
ask_justify(Q, P, t) DialogueMove.create({ type: WHY, targetClaimId: t })
```

---

## 9. ‚ùå **Haskell/Agda Verification** (NOT WORTH PURSUING)

### Status: **NOT IMPLEMENTED** ‚Äî Wrong technology stack

**What It Is:**
- Rewrite argumentation engine in Haskell
- Formalize in Agda (dependent type theory)
- Prove correctness properties (grounded extension unique, conflict-free, etc.)

**Why It's Proposed:**
- ‚úÖ **Machine-checkable proofs** (highest confidence in correctness)
- ‚úÖ **Academic credibility** (formal verification)
- ‚úÖ **Research contribution** (first verified argumentation platform)

**Why It's Not Worth It:**

#### Problem 1: Wrong Language

**Current Stack:**
- TypeScript (Next.js, React, Prisma)
- Node.js backend
- PostgreSQL database

**Haskell/Agda Requires:**
- Complete rewrite of `lib/argumentation/` (~2000 lines)
- Haskell web framework (Yesod? Servant?)
- FFI bindings or API gateway (TypeScript ‚Üî Haskell)

**Effort:** 3-4 months (full rewrite + integration)

---

#### Problem 2: Property-Based Testing is 95% as Good

**Alternative:** QuickCheck-style tests in TypeScript

**Example:**
```typescript
// test/argumentation/properties.test.ts
import fc from 'fast-check';

describe('Dung AF Properties', () => {
  it('grounded extension is unique', () => {
    fc.assert(fc.property(
      arbitraryAF(),  // Generate random AF
      (af) => {
        const groundedExts = computeGrounded(af);
        expect(groundedExts.length).toBeLessThanOrEqual(1);
      }
    ));
  });

  it('grounded extension is conflict-free', () => {
    fc.assert(fc.property(
      arbitraryAF(),
      (af) => {
        const [grounded] = computeGrounded(af);
        if (!grounded) return true;
        for (const arg of grounded) {
          for (const other of grounded) {
            expect(af.attacks).not.toContainEqual([arg, other]);
          }
        }
      }
    ));
  });
});
```

**Benefits:**
- ‚úÖ **Automated testing** (runs in CI)
- ‚úÖ **Same language** (TypeScript)
- ‚úÖ **High confidence** (thousands of random cases)
- ‚úÖ **Low effort** (2-3 days)

**Difference from Agda:**
- Agda: **100% certainty** (mathematical proof)
- QuickCheck: **99.9% confidence** (probabilistic)

**Trade-off:** Is 0.1% more confidence worth 3-4 months rewrite? **‚ùå NO**

---

**ROI:** ‚≠ê **NOT WORTH IT** ‚Äî Massive effort, marginal benefit over property testing

**Recommendation:** **DO NOT PURSUE** ‚Äî Instead:
1. Implement QuickCheck-style property tests (2-3 days)
2. Document key properties (uniqueness, conflict-free, etc.)
3. If academic verification needed: **Formalize in Agda separately** (research artifact, not production code)

---

## 10. ‚ùå **DisCoCat NLP** (NOT WORTH PURSUING)

### Status: **NOT IMPLEMENTED** ‚Äî Overkill for current needs

**What It Is:**
- Parse sentences with **pregroup grammar** (rigid monoidal category)
- Map to **string diagrams** (boxes = words, wires = types)
- Apply functor to **vector spaces** (compose word embeddings via tensor contractions)
- Result: **Grammatically-aware sentence embeddings**

**Why It's Proposed:**
- ‚úÖ **Respects syntax** (not just bag-of-words)
- ‚úÖ **Compositional** (meaning of parts ‚Üí meaning of whole)
- ‚úÖ **Category theory** (functorial semantics)

**Why It's Not Worth It:**

#### Problem 1: Current Embeddings Work Fine

**Current System:**
- OpenAI embeddings for claims (via `text-embedding-ada-002`)
- Cosine similarity for claim matching
- Used in NLI fallback for CQ satisfaction (0.72 threshold)

**Results:**
- ‚úÖ Works well in practice
- ‚úÖ Fast (<100ms per claim)
- ‚úÖ No complex setup

**Question:** What problem does DisCoCat solve that embeddings don't?

**Answer:** Edge cases like:
- "John loves Mary" vs. "Mary loves John" (word order matters)
- "The dog bit the man" vs. "The man bit the dog" (subject/object)

**Counter:** ‚ö†Ô∏è **These rarely occur in deliberation claims**
- Claims are usually **declarative statements** ("Climate change is real")
- Not complex sentences with role ambiguity
- Embeddings already distinguish "A causes B" from "B causes A" (tested empirically)

---

#### Problem 2: Significant Complexity

**Required:**
1. Install DisCoPy library (Python)
2. Set up pregroup grammar parser
3. Train/tune tensor contraction parameters
4. Build TypeScript ‚Üî Python bridge
5. Test accuracy vs. current embeddings

**Effort:** 2-3 weeks

**Benefit:** Marginal improvement on edge cases

---

**ROI:** ‚≠ê **NOT WORTH IT** ‚Äî High complexity, marginal benefit

**Recommendation:** **DO NOT PURSUE** ‚Äî Current embeddings are sufficient. If accuracy issues arise:
1. First try **fine-tuning** embeddings on deliberation data (easier)
2. Try **GPT-4 semantic similarity** (higher quality, same API)
3. **Only then** consider DisCoCat (last resort)

---

## 11. ‚ùå **PCR5/PCR6 Conflict Resolution** (NOT WORTH PURSUING)

### Status: **NOT IMPLEMENTED** ‚Äî No use case

**What It Is:**
- Advanced Dempster-Shafer combination rules
- PCR5: Proportional conflict redistribution (rule 5)
- PCR6: Proportional conflict redistribution (rule 6)
- Handles **highly conflicting evidence** (e.g., expert A says 0.9, expert B says 0.1)

**Why It's Proposed:**
- ‚úÖ **Better than Dempster's rule** (which fails for high conflict)
- ‚úÖ **Research-backed** (Dezert-Smarandache theory)

**Why It's Not Worth It:**

#### Problem 1: No Real-World Conflict Scenarios

**Question:** When does Mesh encounter highly conflicting evidence?

**Scenarios:**
1. **User A posts claim "X is true"** (confidence 0.8)
2. **User B attacks with "X is false"** (creates ConflictApplication)

**Current System Handles This:**
- Attack reduces confidence of claim
- Dung semantics determines acceptance
- No need for probabilistic fusion

**PCR5/PCR6 Needed When:**
- **Same claim** has **multiple independent confidence sources** that **strongly conflict**
- Example: Expert A assigns belief mass [0.9, 0.05, 0.05] (bel=0.9, pl=0.95, unc=0.05)
           Expert B assigns belief mass [0.05, 0.9, 0.05] (bel=0.05, pl=0.1, unc=0.05)
- Dempster's rule fails (K = 0.86 conflict)

**Mesh Reality:**
- ‚ùå Claims don't have multiple confidence sources
- ‚ùå Confidence comes from argument structure (not expert testimony)
- ‚ùå Conflicts are **structural** (attacks) not **probabilistic** (masses)

---

#### Problem 2: Current DS Mode is Simplified

**Implementation in `/api/evidential/score/route.ts`:**
```typescript
const k = 1; // No conflict resolution
return { bel: mBel, pl: 1 }; // No explicit mass on ¬¨œÜ
```

**Status:** ‚úÖ **Works for supportive evidence** (all arguments favor same conclusion)

**When It Breaks:**
- ‚ùå Conflicting expert opinions (doesn't occur)
- ‚ùå Contradictory sensor readings (doesn't occur)

**Conclusion:** PCR5/PCR6 solves problem that **doesn't exist** in Mesh's domain

---

**ROI:** ‚≠ê **NOT WORTH IT** ‚Äî No use case, high complexity

**Recommendation:** **DO NOT IMPLEMENT** ‚Äî Document DS mode limitation:
```typescript
/**
 * NOTE: Current DS mode assumes supportive evidence.
 * If highly conflicting evidence arises (e.g., expert disagreement),
 * consider implementing PCR5/PCR6 rules per Dezert-Smarandache theory.
 * 
 * Current limitation: k=1 (no conflict), pl=1 (no mass on ¬¨œÜ)
 * Impact: Works for argument accrual, not for conflicting testimony
 */
```

---

## üìä Priority Matrix Summary

| Framework | Effort | Benefit | Framework Clash? | Status | Decision |
|-----------|--------|---------|------------------|--------|----------|
| **Dialogue Visualization** | 16 weeks | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ None | Ready | **‚úÖ KEEP/PURSUE** |
| **Per-Derivation Assumptions** | 0 (done) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ None | Complete | **‚úÖ KEEP (UI work)** |
| **Confidence-Scheme Integration** | 3-5 hours | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ None | Backend ready | **‚úÖ KEEP/PURSUE** |
| **Ludics Formalization** | 8-10 hours | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ None | 95% done | **‚úÖ KEEP (docs)** |
| **Topological Argumentation** | 3-4 weeks | ‚≠ê‚≠ê | ‚ö†Ô∏è Alternative | Research | **‚è∏Ô∏è DEFER (side project)** |
| **DDF 8-Stage Protocol** | 8 weeks | ‚≠ê‚≠ê | ‚ùå **Yes** | N/A | **‚ùå REMOVED** |
| **Sentence Type Ontology** | 2-3 weeks | ‚≠ê‚≠ê | ‚ö†Ô∏è Breaking | N/A | **‚ùå REMOVED** |
| **Commitment Stores** | 1 week | ‚≠ê | ‚ùå Redundant | N/A | **‚ùå REMOVED** |
| **Haskell/Agda Verification** | 3-4 months | ‚≠ê‚≠ê | ‚ùå Wrong stack | N/A | **‚ùå REMOVED** |
| **DisCoCat NLP** | 2-3 weeks | ‚≠ê | ‚ö†Ô∏è Overkill | N/A | **‚ùå REMOVED** |
| **PCR5/PCR6 DS Rules** | 1-2 weeks | ‚≠ê | ‚ö†Ô∏è No use case | N/A | **‚ùå REMOVED** |

---

## üéØ Recommended Roadmap (Post-Dialogue Viz)

### ‚úÖ Phase A: Keep/Pursue - High-Value Immediate Work (1 week)
1. ‚úÖ **Confidence-Scheme Integration** (3-5 hours)
   - Read `validators.baseConfidence`
   - Apply CQ penalty
   - Add temporal decay
2. ‚úÖ **Ludics Documentation** (8-10 hours)
   - Formal specification
   - Developer guide
   - Research paper draft

### ‚úÖ Phase B: Keep/Pursue - Dialogue Visualization (16 weeks)
- Follow Phases 1-7 roadmap (already documented)
- Parallel work: Ludics paper writing
- UI visualization for assumption graphs

### ‚úÖ Phase C: Keep/Pursue - Research Contributions (Ongoing)
1. ‚úÖ Publish ludics integration paper (COMMA 2026)
2. ‚úÖ Publish proof obligation enforcement paper (COMMA 2026)
3. ‚úÖ UI components for assumption graph visualization

### ‚è∏Ô∏è Phase D: Deferred - Future Research Considerations (6-12+ months, separate track)
- **Topological Argumentation Model** as **separate research project**
  - Not blocking production features
  - Consider as academic contribution / PhD thesis topic
  - Better as standalone research paper than platform feature
  - May inform future theoretical foundations but not immediate implementation

### ‚ùå Phase E: Removed - Not Part of Project Roadmap
The following frameworks are **explicitly removed** from all roadmaps and will **not** be implemented:
- ‚ùå DDF 8-Stage Protocol (framework clash with existing dialogue system)
- ‚ùå Sentence Type Ontology (breaking change, unclear benefit)
- ‚ùå Commitment Stores (redundant with DialogueMove table)
- ‚ùå Haskell/Agda Verification (wrong technology stack)
- ‚ùå DisCoCat NLP (overkill, current embeddings sufficient)
- ‚ùå PCR5/PCR6 Conflict Resolution (no use case in Mesh's domain)

---

## üí° Key Insights

### What Makes a Framework Worth Pursuing?

‚úÖ **Good Candidates:**
1. **Complements existing system** (no rewrites)
2. **Clear UX benefit** (users see value)
3. **Low-medium effort** (<2 weeks)
4. **No framework conflicts** (integrates cleanly)

‚ùå **Bad Candidates:**
1. **Requires breaking changes** (sentence types, locutions)
2. **Redundant with existing features** (commitment stores)
3. **No clear user benefit** (topological belief)
4. **Wrong technology stack** (Haskell/Agda)
5. **Solves non-problems** (PCR5/PCR6, DisCoCat)

### Why DDF Doesn't Fit

**DDF is designed for:**
- Formal protocol specification
- Academic rigor
- Agent-based systems
- Explicit commitment tracking

**Mesh is designed for:**
- Real humans collaborating
- Intuitive UX (not formal stages)
- Implicit commitments (via moves)
- Production reliability

**Gap:** DDF optimizes for **protocol correctness**. Mesh optimizes for **user experience**. These are different goals.

**Conclusion:** Better to document **how Mesh achieves DDF goals** using different mechanisms than force DDF protocol onto existing system.

---

## üìã Action Items

### Immediate (This Week):
1. ‚úÖ Complete this priority analysis (DONE)
2. ‚úÖ Start dialogue visualization Phase 1 (database schema)
3. ‚úÖ Implement confidence-scheme integration (3-5 hours)

### Short-Term (Next 2 Weeks):
4. ‚úÖ Write ludics formalization document
5. ‚úÖ Continue dialogue viz implementation
6. ‚úÖ Document DDF‚ÜíMesh mapping (for academic papers)

### Medium-Term (Next 2 Months):
7. ‚úÖ Complete dialogue visualization Phases 1-4
8. ‚úÖ Submit ludics paper to COMMA 2026
9. ‚úÖ UI for assumption graph visualization

### Long-Term (6-12 Months):
10. ‚ö†Ô∏è Revisit deferred frameworks **only if clear need arises**
11. ‚ö†Ô∏è Property-based testing (QuickCheck-style)
12. ‚ö†Ô∏è Consider topological model as research artifact

---

## üéâ Wins Summary

**What We Learned:**
- ‚úÖ Current system is **90% complete** (per status review)
- ‚úÖ **Per-derivation assumptions already done** (Gap 4 resolved)
- ‚úÖ Most "gaps" are **academic frameworks** not **missing features**
- ‚úÖ **Dialogue visualization** is the clear next priority (roadmap ready)

**‚úÖ What We're KEEPING/PURSUING:**
- ‚úÖ **Dialogue visualization** (clear value, ready to implement, 16 weeks)
- ‚úÖ **Confidence-scheme integration** (quick win, 3-5 hours)
- ‚úÖ **Ludics documentation** (research contribution, 8-10 hours)
- ‚úÖ **Assumption graph UI** (leverage completed backend)

**‚è∏Ô∏è What We're DEFERRING (Side Project):**
- ‚è∏Ô∏è **Topological Argumentation Model** (research contribution, not core feature)
  - Consider as separate academic paper / PhD research
  - Not blocking production work
  - May inform future theoretical foundations

**‚ùå What We're NOT DOING (Removed from All Roadmaps):**
- ‚ùå **DDF protocol** (framework clash with existing dialogue system)
- ‚ùå **Commitment stores** (redundant with DialogueMove table)
- ‚ùå **Sentence types** (breaking change, unclear benefit)
- ‚ùå **Haskell/Agda** (wrong technology stack)
- ‚ùå **DisCoCat** (overkill for current needs)
- ‚ùå **PCR5/PCR6** (no use case in practice)

**Strategic Insight:** The research synthesis identified **many theoretical frameworks**, but most don't map to **practical user needs**. The system is already production-ready. Focus should be on **completing dialogue viz**, **quick wins** (confidence-scheme integration), and **documenting existing innovations** (ludics, proof obligations) for research credit.

**Decision Rationale:** 
- Frameworks that **complement** existing system (dialogue viz, confidence integration) ‚Üí **KEEP**
- Frameworks that **conflict** with existing system (DDF, commitment stores) ‚Üí **REMOVE**
- Frameworks that are **research-oriented** with no clear UX benefit (topological model) ‚Üí **DEFER** as side project
- Frameworks that require **wrong technology** or solve **non-problems** (Haskell, DisCoCat, PCR5/PCR6) ‚Üí **REMOVE**

---

**Status:** ‚úÖ READY TO PROCEED with dialogue visualization Phase 1

**Next Document:** Start implementing Phase 1 database schema extensions

---

**End of Priority Analysis**
