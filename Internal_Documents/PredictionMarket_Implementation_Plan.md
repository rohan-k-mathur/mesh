Prediction Market Feature Implementation Plan for Mesh
Executive Summary
MVP Approach: Implement a simple binary YES/NO prediction market using an automated market maker (starting with the Logarithmic Market Scoring Rule, LMSR) to provide continuous liquidity and 0–100% probability pricing. This basic design is easy to build and can be extended later to match the sophistication of platforms like Kalshi or Manifold.
Virtual Currency (Credits): Utilize Mesh’s in-app virtual credits as the trading currency, treating 1 credit as $0.01 of play money. Trades should debit and credit user balances atomically, ensuring that wallet balances update consistently with each trade. No special new tokenomics are needed initially beyond the existing credit system.
Data Model Extensions: Extend the backend models to support prediction markets. This involves adding a PredictionMarket subtype (linked to the Post model) and a Trade log. The PredictionMarket table will store each market’s question, current YES/NO pools, state (OPEN/CLOSED/RESOLVED), etc., and each Trade record will log individual trades (user, side, shares purchased, price, cost in credits). These database migrations have already been applied in the codebase.
Current Progress: The Mesh codebase already has some groundwork in place for this feature. Database tables for markets and trades exist, core LMSR math utilities (for price and cost calculations) are written, and the UI supports creating a prediction post type. Remaining tasks include implementing the backend trading logic and resolution process, wiring up API routes, and building the interactive trading interface on the frontend.
Trading Logic: Develop a robust placeTrade service function to handle buying/selling shares. This should lock the user’s wallet row to prevent race conditions, verify the user has sufficient balance, compute the cost and number of shares via the LMSR formula, then atomically debit the user’s credits, update the market’s YES/NO pools, and create a Trade record. This atomic transaction design prevents double-spending and ensures ledger integrity. The LMSR cost function will dynamically adjust prices so that each purchase increases the next share’s cost, maintaining fair, arbitrage-free pricing.
Resolution Mechanism: Implement resolution of markets via moderators or designated oracles. Only the market creator, an assigned oracle, or an admin can resolve a market once it’s closed. A resolveMarket function should lock the market, record the chosen outcome (YES or NO), and pay out winners by crediting their wallets (e.g. each YES share gets 1 credit if outcome=YES). All resolution events are recorded in a new ResolutionLog table for transparency and auditing. To prevent self-dealing, the resolver/oracle should be blocked from trading after market close.
API Endpoints & Auth: Expose REST or tRPC endpoints for all key market actions. For example: create a market (POST /api/market), place a trade (POST /api/market/{id}/trade), resolve a market (POST /api/market/{id}/resolve), and fetch market data (GET /api/market/{id}). Enforce proper authentication and authorization on these routes (only logged-in users can trade; only authorized users can resolve). All critical calculations (like share counts and prices) should be done server-side (ignoring any client-supplied values) to prevent tampering.
Frontend Interface: Build a user-friendly UI for creating and trading in markets. This includes a market creation form (for entering the question, close date, and initial liquidity parameter), a PredictionMarket card in the feed showing the question, current probability and status (open/closed/resolved) with a “Trade” button, and a trade modal where users can select an amount to spend (via slider), see the estimated shares and new probability, and confirm the trade. Use real-time updates (polling every few seconds or websockets) so all users see new odds within seconds of a trade. Ensure the UI handles market closing and resolution (e.g. disabling trading when closed, showing final outcome when resolved).
Theoretical Soundness & Security: The LMSR market maker ensures continuous liquidity and arbitrage-free pricing – as traders buy shares, the price increases, so they can’t infinite-money exploit the system. The system should conserve credits: total credits paid out on resolution should equal total credits paid in (minus any permanent “liquidity subsidy” held by the market maker), preventing creation or loss of money. To maintain integrity, use row locking and database transactions for all balance and pool updates, and consider maintaining a wallet ledger for a clear audit trail of all credit movements. Add safeguards like rate limiting (e.g. max trades per minute per user) to prevent spam or abuse, and thoroughly validate/sanitize all user inputs (question text, etc.) to avoid XSS or injection. A feature flag and kill-switch mechanism should allow disabling the feature quickly if an exploit or severe bug is discovered.
Phased Development & Rollout: Divide the implementation into logical phases with clear milestones: set up the database and locking first, then implement core trading/resolution logic with tests, build out API endpoints and background jobs, develop the frontend UI, and finally add enhancements (notifications, analytics, security checks) before rigorous testing. Perform unit tests on LMSR math and simulate concurrent trades to ensure race conditions are handled. Do an end-to-end test of creating, trading, closing, and resolving a market to verify the entire flow. Gradually roll out the feature behind a feature flag – start on a staging environment, then enable for internal testers, then a small percentage of users, monitoring performance (ensure ~<300ms trade latency at 95th percentile) and correcting any issues before full launch. This cautious rollout and thorough QA will ensure the prediction market is production-ready and on par with the reliability of Kalshi or Manifold (albeit using play money).
Phase 0: Foundations & Prerequisites
Goal: Before adding new functionality, make sure the groundwork is in place and the partial implementations are understood.
Database Schema in Place: Verify that the PredictionMarket and Trade tables/models exist in the database (the plan indicates this migration was already done). Also ensure there is a base wallet/balance table for user credits, since trades will debit and credit user balances.
Feature Flags & Config: Set up a feature flag (e.g. an environment config like PREDICTION_MARKETS_ENABLED) to gate the new feature. This allows turning the prediction market on or off for rollout. Additionally, prepare any configuration needed for scheduled jobs or real-time features (for example, a MARKET_CRON_SECRET for authenticating a cron job that closes markets, or a NEXT_PUBLIC_MARKETS_WS URL if using websockets later).
Review Existing Code: Examine any partial implementation already in the codebase so you can build on it. For instance, confirm the LMSR math utility functions (likely in lib/prediction/lmsr.ts) are present and tested. Also check the UI components for prediction posts: there might be a basic CreatePredictionPost form and a PredictionMarketCard component (and possibly a trade modal) already scaffolded. Familiarize yourself with their current state so you can integrate new functionality seamlessly rather than duplicating work.
(By completing Phase 0, we ensure the baseline schema and toggles are ready, and we understand the starting point in the code. This prevents re-doing work and allows safe incremental development.)
Phase 1: Database & Wallet Hardening
Goal: Ensure the database layer can safely handle concurrent trades and resolutions without consistency issues.
Add Wallet Locking: Implement a row-level locking mechanism for user wallets to prevent race conditions when multiple trades happen simultaneously. For example, you can add a small PostgreSQL function or use a query like SELECT ... FOR UPDATE on the wallet table. Ensure that whenever a trade or payout occurs, you lock the user's wallet row first. This guarantees two trades on the same user won’t overspend the same credits.
Optimize Indexes: Add any necessary database indexes to support efficient queries. A composite index on the Trade table by (marketId, userId) is useful for quick lookups of a user’s trades in a given market (needed for computing a user’s current position or checking if they have traded before). Proper indexing will also help when querying trade history or resolving markets.
Resolution Audit Log: Create a new table (e.g. ResolutionLog) to record details whenever a market is resolved. Each entry should include the market ID, who resolved it (the moderator/admin’s userId), the chosen outcome (YES or NO), and a timestamp. This provides an audit trail for transparency and helps debug or analyze resolutions (for example, to confirm that outcomes are being set correctly and to gather statistics on outcomes).
Outcome: By the end of Phase 1, the database will have all necessary structures and safety mechanisms in place. We can be confident that transactions affecting balances or market state (trades and resolutions) will maintain consistency by locking the appropriate rows and preventing conflicts.
Phase 2: Core Service Logic (Trading & Resolution)
Goal: Implement the backend logic for executing trades and resolving markets in a theoretically sound way. This covers the critical LMSR price calculations, trade execution flow, and resolution payouts.
LMSR Cost Calculation: Ensure the LMSR formula is correctly implemented and used for pricing. LMSR (Logarithmic Market Scoring Rule) keeps track of two state variables: q_yes and q_no (the total YES and NO shares in existence, which correspond to the YES and NO pools in the market). The instantaneous price for a YES share is given by:
P 
YES
​
 = 
exp(q 
yes
​
 /b)+exp(q 
no
​
 /b)
exp(q 
yes
​
 /b)
​
 ,
 ,
where b is the liquidity parameter controlling how much the price moves per share. Buying Δ shares of YES will increase q_yes, and the cost to buy those shares is the increase in the LMSR cost function C(q_yes, q_no) before vs. after the trade. This mechanism guarantees liquidity (the market maker is always ready to sell shares) and ensures no arbitrage opportunities because the price will always move against a trader as they purchase more shares (so you can’t buy infinite underpriced shares). For now, LMSR is a solid choice for a play-money prediction market. It’s the same class of market maker used by many platforms (Manifold uses a variant of a constant-product market maker, but LMSR is equally well-founded for binary markets). We design the system such that we could swap in other mechanisms later if needed (like an order-book model for Kalshi-style trading, or a Uniswap-style CPMM), but LMSR provides a good balance of simplicity and theoretical soundness to start.
Implement Trade Execution (placeTrade): In the service layer (e.g., lib/prediction/service.ts), implement a placeTrade function that encapsulates the logic for a user buying or selling shares in a market as a single atomic transaction. The steps should be:
Lock Wallet: Lock the user’s wallet row (e.g., using the lock_wallet(userId) query added earlier) so their balance can’t be modified concurrently.
Fetch Current State: Retrieve the user’s current credit balance and the market’s current state (current YES and NO pool sizes q_yes, q_no, and the market’s status).
Validate Conditions: Ensure the market is still open for trading. If the market’s state is not OPEN (i.e., it’s CLOSED or already RESOLVED), abort with an error (“Market closed”). Also check the user’s balance is >= the amount they intend to spend; if not, throw an “Insufficient funds” error.
Compute Shares & Cost: Use the LMSR pricing formula to determine how many shares the user will receive for their intended spend, and exactly how much that spend will cost in credits. Typically, this involves using the LMSR cost function: determine Δq (change in q_yes or q_no depending on side) such that the cost C(new_q_yes, new_q_no) – C(old_q_yes, old_q_no) = X credits (or as close as possible to X). In practice, a binary search or iterative approach can find the number of shares for the given spend. (The codebase might already include a helper for this.) The result will be the number of shares (Δq) and the actual cost in credits for that trade. Round up or down sensibly (e.g., ceil cost to nearest credit to avoid fractional credits).
Persist the Trade Atomically: Still inside the database transaction, update all relevant records: deduct the spent credits from the user’s wallet balance, increment the market’s YES or NO pool (q_yes or q_no) by the number of shares bought, and insert a new Trade record logging the trade (including userId, marketId, side, shares, price, and cost). All these writes must commit together or all fail, to prevent any partial updates.
Return Result: Once committed, return the details (perhaps the number of shares bought and the new market probability) to the caller. The transaction ensures that if two trades hit at nearly the same time, one will wait on the wallet lock until the other commits, thereby preserving consistency.
Implement Market Resolution (resolveMarket): Create a service function resolveMarket to handle closing out a market when the outcome is known. The logic should:
a. Authorization & State Check: Verify that the caller has permission to resolve (must be the market’s creator, assigned oracle, or an admin) and that the market is in the correct state to resolve (i.e., it’s CLOSED after reaching its deadline, but not yet RESOLVED). If these checks fail, reject the action (HTTP 403 or similar).
b. Lock Market for Resolution: It can be wise to lock the market row or otherwise ensure only one resolution happens. Mark the market’s state as RESOLVED, and record the outcome (YES or NO) in the PredictionMarket record. Also record a resolvesAt timestamp or similar.
c. Calculate Payouts: Determine payouts for all participants. The simplest approach in a binary market: if the outcome is YES, each YES share pays 1 credit; if outcome is NO, each NO share pays 1 credit. Essentially, all winning shares become worth 1 credit each, and losing shares become worthless. You can compute each user’s net outcome by summing their trades: e.g., sum of YES shares bought minus sum of NO shares (or vice-versa) – but since LMSR doesn’t track explicit per-user share ownership in a straightforward way, an easier method is to pay out based on the final outcome and initial cost. However, for a play-money implementation, simply treating each share as a redeemable token for 1 credit is intuitive and ensures total payout equals total money paid in (the LMSR market maker’s bank covers any differences).
d. Credit Winners: For every user who has a positive number of winning shares (which can be derived from their trade history or from stored “position” if you maintain one), credit their wallet with the appropriate number of credits. This can be done by iterating over all trades or maintaining an aggregate of user positions. The key is that the sum of credits paid out to winners should equal the total credits spent by traders (minus any remainder in the market maker pool), to uphold conservation of credits.
e. Record Resolution: Insert a row into the ResolutionLog table capturing who resolved the market and what the outcome was (for audit purposes).
f. Notify and Finalize: Mark any related in-memory state or caches as updated, and consider emitting a real-time event (e.g., via WebSocket or Pusher) to notify clients that the market has resolved. All these steps (b through e) should occur within a database transaction so that the outcome change and all payouts are atomic. If any step fails, the transaction can roll back and avoid partial payouts.
Auto-Close Markets: Implement a background job (cron task) that periodically scans for markets whose closing time has passed and moves them from OPEN to CLOSED state. This ensures trading is halted at the predetermined deadline, even if no one manually closes the market. For example, a script could run every 5 minutes to find any PredictionMarket where state = 'OPEN' AND closesAt <= NOW() and set those to state = 'CLOSED'. If this job is exposed via an API route, protect it with a secret token (e.g., require a MARKET_CRON_SECRET header) so only your cron service can invoke it. This guarantees the market lifecycle (Open → Closed → Resolved) progresses correctly.
Wallet Ledger (Optional): For added transparency and debugging, consider maintaining a wallet ledger table that logs every credit debit/credit event. Instead of solely relying on a balance field, each trade would create a ledger entry (debit X credits for trade #123) and each resolution would create entries for payouts. This makes it much easier to audit that all credits are accounted for and track each user’s profit/loss over time. While not strictly required for functionality, this practice is common in financial systems for ensuring no funds mysteriously disappear or appear.
Outcome: By the end of Phase 2, the backend services will be able to handle trades and resolutions correctly and securely. We’ll have confidence in the market mechanism’s correctness (shares are priced and purchased without arbitrage opportunities, and payouts are fair) and the integrity of transactions (no race conditions or balance inconsistencies thanks to locking and transactions).
Phase 3: API and Endpoint Integration
Goal: Expose the prediction market functionality via well-defined API (or tRPC) endpoints and ensure they are properly secured. This lets the frontend (and any external integrations) interact with the markets (create, trade, resolve, query) through a stable interface.
Create Market Endpoint: Implement an endpoint (e.g., POST /api/market) to allow users to create a new prediction market. This handler should accept the market parameters from the client (question text, closing date/time, and possibly the initial liquidity parameter b). On execution, it will:
Create a new Post with type = PREDICTION (or whatever enum denotes a prediction market post).
Create a corresponding PredictionMarket record linked to that post, storing the question, close time, initial pools (which can start at 0 YES and 0 NO shares, or if you want to initialize with some liquidity, you could pre-populate both pools equally to start at 50/50 odds), and the b value.
Mark the creator’s userId as the market’s creator (and possibly as the default resolver/moderator if that’s the design).
Return the new market’s ID (or the full market object) in the response.
This allows the frontend to redirect the user to the newly created market or update the feed. Make sure to validate input (e.g., question length, close date is in the future, etc.) on the server as well. Only authenticated users can create markets, of course.
Trade Endpoint: Implement an endpoint for placing trades, e.g., POST /api/market/{id}/trade. The client will specify the market ID (in URL), side (YES or NO), and amount of credits to spend (in the request body). The endpoint handler should:
Verify the user is logged in (authentication middleware).
Call the placeTrade service function with the current user’s ID, market ID, chosen side, and spend amount.
Return the result of the trade (e.g., success status, number of shares purchased, new probability or market state). Possibly include updated pool sizes or the user’s new balance if the frontend needs it.
Also consider rate limiting this route (and possibly the create route) to prevent spam or excessive load. For example, a user might be limited to, say, 10 trades per minute (the exact limit can be tuned). If the limit is exceeded, return HTTP 429 (Too Many Requests). This can be done with an in-memory counter or a distributed cache (like Redis) if you have multiple servers.
Resolve Endpoint: Implement POST /api/market/{id}/resolve for resolving a market. This should:
Authenticate the user and ensure they are authorized to resolve this market (check that the user is the market creator, or designated oracle, or an admin).
Verify the market’s state is CLOSED (trading has ended) and not yet RESOLVED. If it’s still open or already resolved, reject the request (HTTP 400/409 error).
Possibly require an idempotency token to guard against duplicate resolutions. Because resolution is a one-time action, you want to ensure that if the client accidentally submits the request twice (or a network retry happens), you don’t double-pay users. Using an Idempotency-Key header or similar, you can have the server remember a recent resolve request and ignore duplicates.
Call the resolveMarket service to perform the resolution logic.
Return the outcome or success status.
Make sure to log or record who resolved the market (the service already does this via ResolutionLog). After resolving, the endpoint might also trigger any notification sending (or that can be done in the service).
Get Market Data Endpoint: Implement GET /api/market/{id} to retrieve the details of a specific market. This should return all information needed to display the market: the question, current YES/NO pool sizes or current probability, the market’s state (open/closed/resolved), the closing time, the creator (if needed for display), and possibly recent trades or the user’s own position. This endpoint will be used to render the market’s detail page or modal. It can be a public endpoint (no auth required just to read market info). Consider adding simple caching or use of stale-while-revalidate headers on this GET route, since many users might be polling market data frequently. For example, a 5-15 second cache could drastically reduce load while still keeping data fresh.
Integrate with Post Feed: Ensure that prediction market posts appear in the home feed or relevant section of the app alongside other post types. The backend may already have a mechanism to fetch posts (maybe via a /api/posts or similar). Update that logic so that when a PREDICTION type post is fetched, it includes the necessary fields from the PredictionMarket (like current probability and state). This might involve a database join or an explicit query to include prediction market data. On the frontend, ensure the feed item component for a prediction post uses this data to display the market card correctly (e.g., showing the current probability and closing status).
Security & Validation: Double-check that all inputs to these endpoints are validated on the server side. For instance, the trade endpoint should not trust the client’s reported price or share count; it should only take the desired spend amount and compute the rest itself (which we do). The resolve endpoint should enforce the user’s permission and that the market is in the correct state. All endpoints should handle attempts to do things out of order (e.g., trading on a closed market, resolving an open market, etc.) gracefully with appropriate error responses. Write tests for these scenarios. Also ensure that the API responses do not leak any sensitive info.
Outcome: By the end of Phase 3, the backend capabilities (from Phase 2) are fully exposed via APIs, and secured. We will be able to create markets, place trades, close and resolve markets, and fetch market data through standard endpoints. At this point, the system supports all core actions programmatically; the next step is to build the user interface to make it accessible to end users.
Phase 4: Frontend User Interface
Goal: Develop a rich UI so that users can interact with the prediction markets intuitively and in real-time. The frontend will allow users to create markets, view market cards, trade shares via a modal, and see outcomes/resolutions.
Market Creation Form: Integrate a Create Prediction Market form into the app (likely as part of the post creation flow). If a component like CreatePredictionPost.tsx doesn’t already exist, create it. This form should gather the market question (with a character limit, e.g. 140 chars), the close date/time (using a date-time picker UI), and possibly an initial liquidity parameter b (for MVP this can default to a reasonable value like 100, but advanced users or admins might adjust it). Add basic validation: the question should not be empty and should be under the char limit; the close time must be in the future, etc. On submission, call the create market API (Phase 3) to actually create the market, then redirect the user to the newly created market’s page or show it in their feed.
Prediction Market Card (Feed Display): Implement the UI component that displays a prediction market in the feed (the plan references PredictionMarketCard.tsx). This card should show the market question, the current probability (as a percentage or odds). A visual indicator like a filled bar or progress bar can illustrate the current YES probability (for example, if current probability of YES is 60%, fill 60% of the bar in one color and the rest in another). Also display the market’s status: if it’s open, perhaps show “Open until [date]”; if it’s closed (awaiting resolution), indicate “Closed, awaiting resolution”; if resolved, clearly show the final outcome (e.g., “Outcome: YES” or “Outcome: NO”). The card should include a “Trade” button which opens the trading modal. If the market is closed or resolved, this button should be disabled or replaced with a label like “Market Closed”.
Trading Modal: Create a TradePredictionModal.tsx component (if not already started) that pops up when the user clicks “Trade”. In this modal:
Allow the user to input how many credits they want to spend. A slider control is a user-friendly way to do this. The slider’s max should be the lesser of the user’s available balance and some reasonable cap (you might not want to allow one user to spend all their credits in one go if that would be unusual, but that’s a product decision – initially, the user can spend up to their full balance).
As the user adjusts the spend amount, display the estimated number of shares they would purchase and the new predicted probability if the trade goes through. This can be calculated in real-time on the client by duplicating the LMSR formula (the GET market endpoint provides current q_yes, q_no, and b, so the client can simulate adding Δ to one of them and recompute the probability). Alternatively, you could create a lightweight /previewTrade API that returns the result for a given spend, but doing it on the client is fine for instant feedback. For example: if current probability is 60% YES and the user plans to buy 100 credits of YES shares, the modal might show “Estimated outcome: You will get ~X YES shares, new market probability ~65%”.
Show the cost and balance update clearly. E.g., “Cost: 100 credits” and “Your new balance: [current_balance - 100] credits”. If you allow selling shares (not in MVP scope perhaps), the modal would similarly handle selling by giving credits in return and lowering the probability. (Initial implementation can just allow buys; selling or shorting could be a later feature if desired.)
Provide a confirmation button (“Buy” or “Trade”) that triggers the trade. On click, call the trade API endpoint (with appropriate parameters). If the API call succeeds, close the modal and update the UI: the market card’s probability should update to the new value. You can do this via an optimistic update (update the state based on your pre-calculation) or by refetching the market data from the API to get the authoritative new state.
Handle errors gracefully: if the trade fails (due to insufficient balance, market just closed, etc.), display a clear error message (possibly using a toast notification or an inline alert in the modal) and do not close the modal so the user can adjust.
Live Updates: To ensure all users see the latest market data, implement live updates for market changes. There are two approaches:
Polling: The simplest approach is to use periodic polling on the client. For example, using React Query or SWR to re-fetch the market data every 5 seconds or so. This will update the probability bar and other details if other users have traded. Polling is easy to implement and reliable, though it has a small performance cost.
Realtime via WebSockets/Pusher: For a more responsive system, set up a realtime channel (websocket or using a service like Pusher/Supabase realtime). The server would emit an event whenever a trade is executed or a market is resolved. Clients subscribed to that market’s channel would receive the event and update the market data immediately. This provides instant updates. However, it’s more complex to implement and can be added once the basic system is stable. For MVP, polling is acceptable, but design the code such that you can upgrade to realtime updates later (e.g., keep environment variables or hooks in place to enable websocket updates down the road).
Resolution UI: If the current user is allowed to resolve a market (i.e., they are the creator/oracle and the market is closed), the frontend should show a “Resolve” button on that market’s page or card. Implement a simple resolution dialog: when clicked, it opens a prompt for the moderator to choose the outcome (YES or NO). This could be a modal with two options (radio buttons or a select dropdown) and a confirmation button. Include a warning like “Are you sure? Resolving will distribute payouts and cannot be undone.” On confirmation, call the resolve API. After a successful response, update the UI to display the chosen outcome clearly (for example, replace the probability bar with a label “Resolved: YES won” in green or red). Also consider immediately reflecting any credit payouts in the user’s balances (though that might be handled by the backend and just shown via updated balance in the UI on next fetch).
Market Details & History (Stretch Goal): Eventually, it would be great to have a detailed view for each market, showing more information: e.g., a chart of probability over time, the list of recent trades, comments or discussion related to the market. For the MVP, this can be minimal. Perhaps the existing post detail page can double as the market detail page, showing the market card and a comments section. Logging each trade with timestamp means you could display a basic trade history table under the post. This is not critical for the initial release but is a nice enhancement to plan for when polishing the feature.
Outcome: By the end of Phase 4, users can fully interact through the UI: they can create new prediction markets, see those markets in the app, make trades with an intuitive interface, and resolve markets if they are moderators. The feature will be functionally complete from a user perspective — all core interactions are possible through the frontend.
Phase 5: Additional Features and Enhancements
Goal: Add supporting features that enhance the user experience, robustness, and engagement of the prediction market, making it feel production-ready and on par with established platforms.
Notifications: Implement a notification system for key events. For example, when a market is resolved, every user who participated could get an in-app notification (or email) like “Market X resolved to YES. You earned 120 credits”. Similarly, after a trade, a user might get a confirmation notification: “Your trade on Market X was executed at 60%”. These notifications increase transparency and encourage users to re-engage (they’ll come back to see results). Implementing this could involve creating Notification records in the database as part of the resolveMarket transaction (so it’s all atomic), and a process to deliver those notifications to the frontend (either via real-time push or the next time the user refreshes). If using websockets or a service, you can push the notification in real-time as well.
Analytics & Leaderboards: Track usage analytics for the prediction markets and potentially gamify user performance. Emit events or logs for actions such as market creation, trades, and resolution (e.g., market_created, market_traded, market_resolved events with relevant metadata). These can feed into analytics pipelines (for instance, sending to Segment or a database like ClickHouse) to analyze feature adoption, volume of trades, etc. On the user side, use the trade and resolution data to compute leaderboards or stats – for example, track each user’s profit and loss (P&L) over time or their forecasting accuracy. You could show a leaderboard of top earners or a profile badge for a user’s prediction market performance, adding a competitive element that platforms like Manifold use to drive engagement.
Theoretical Upgrades (Market Types): With the binary YES/NO market functioning, plan for more advanced market types once the system is stable. This could include multi-outcome markets (e.g., a question with multiple possible answers) which would require extending the LMSR formula to multiple outcomes or using a different market maker that supports categorical outcomes. Another possibility is numeric range markets or scalar markets (predict a number, like a stock price or temperature, by a certain date). These often involve many discrete outcomes or an automated way to pay out on a range, and might require a continuous market maker or an order-book. While these are beyond the MVP, the architecture should keep these in mind. For instance, LMSR with more outcome buckets could be used for multi-choice, or a separate mechanism could be slotted in for those market types. Document ideas for how multi-outcome LMSR or a future order-book mechanism could be integrated so that when it comes time to implement, it fits neatly into the existing system.
Liquidity Provision and Market Funding: In the future, consider features to let users themselves provide liquidity or stake credit in markets. Platforms like Manifold Markets allow users to add funds to a market to increase its liquidity pool (so that large trades don’t shift the probability as much). This could be implemented by allowing the market creator or others to contribute credits to both YES and NO pools at creation or during the market (essentially increasing the LMSR b parameter or initial pool sizes). Another idea is to let users create markets with their own capital at risk, which can incentivize well-calibrated markets but requires handling how those funds are returned or kept depending on outcome. These are advanced features and come with additional complexity, but the MVP’s design (with a configurable b and a clear separation of market data) should make it possible to add such capabilities later.
Alternate Market Mechanisms: Evaluate other market-making mechanisms if needed as the platform grows. For instance, order book exchanges (like Kalshi or traditional stock markets) could be introduced if you want to support features like limit orders and an order matching engine. This would be a significant undertaking (requires building matchmaking logic and perhaps automated market makers to seed liquidity), and might run parallel to LMSR markets rather than replacing them. Another option is a Constant Product Market Maker (CPMM), similar to Uniswap’s x*y=k formula, which some prediction platforms use for simplicity. CPMM is easier to implement but can suffer from liquidity issues at extremes (prices approach 0 or 1 asymptotically). Each mechanism has trade-offs: LMSR charges a liquidity fee on every trade (meaning the house bankroll absorbs some loss to provide infinite liquidity), CPMM can run out of liquidity and create huge spreads near 0/100%, and order books require active participation or bots to fill orders. For the Mesh prediction markets, starting with LMSR is perfectly reasonable as it is theoretically sound and widely used for play-money markets. The system should be designed modularly so that additional mechanisms could be added in the future if product requirements shift.
At this stage, the prediction market feature should be quite robust and engaging, offering a similar core experience to other platforms. The enhancements in Phase 5 ensure the feature feels polished and ready for a wider audience (with notifications, analytics, etc.), and set the stage for even more advanced features down the line.
Phase 6: Testing and Quality Assurance
Goal: Rigorously test the entire prediction market system to ensure correctness, security, and reliability before a full release. This includes unit tests, integration tests, performance tests, and end-to-end user testing.
Unit Testing (Logic): Thoroughly test the LMSR math functions and any other pure logic. For example, given certain q_yes, q_no, and b, verify that the price calculation is correct (e.g., starting with zero shares gives 50%/50% price). Test the cost function by simulating small trades and checking that buying shares changes the probability appropriately and that the cost difference matches expectations. Include edge cases: very large or very small liquidity b, or very imbalanced markets (e.g., almost all shares on one side) to ensure no division-by-zero or overflow issues. Also test any rounding behavior (ensuring we don’t accidentally create or lose a fraction of a credit due to rounding). If a binary search is used for computing shares per cost, test that function with various inputs to ensure it converges correctly.
Integration Testing (API flows): Use API-level tests (with a tool like Supertest for Next.js/Node or via tRPC testing utilities) to simulate end-to-end flows. For instance:
Create a new market via the API, assert that it returns success and the database now has the market.
Place some trades: test a normal trade (user has enough balance, market is open) and verify the response (e.g., number of shares returned). Then test edge conditions: try to trade with insufficient funds (should get an error), try to trade on a market after its close time or after marking it closed (should be rejected).
Resolve the market via the API and verify that the outcome is set and winners are paid out. After resolution, check that the sum of all user balances is equal to what it was before the market (conservation of credits) within any rounding error.
Test that unauthorized actions are blocked: e.g., a normal user trying to resolve a market they don’t own should get a 403, etc..
Concurrent Trading Test: Write tests or scripts to simulate high-concurrency scenarios. For example, fire off 50 or 100 trade requests at the same time (using multiple threads or an async loop) on the same market and see that the system handles it. The expectation is that all trades will be processed one after the other (thanks to wallet locking) without any corruption: no two trades should deduct from the wallet at the exact same time, and the final pools and probabilities should be as if the trades happened sequentially in some order. Check that no shares or credits are mysteriously created or lost in this process. This kind of load test can surface any race conditions or deadlocks. If using Postgres row locking, verify that it doesn’t seriously degrade performance under contention (brief locks are fine).
Performance and Load Testing: Although this is a play-money market, it’s worth testing performance. Use monitoring or manual timing to ensure that a single trade execution is fast (under a few tens of milliseconds on the backend logic). If possible, test with a larger number of markets and trades to see if any queries (like retrieving a user’s position or writing a trade) become slow. This might involve creating e.g. 1000 markets and simulating trades in all of them to ensure the database can handle it. Also test the auto-close cron in a scenario with many markets closing at the same time. This helps verify that the feature will scale as usage grows.
End-to-End (UX) Testing: Use a tool like Cypress or Playwright to simulate a real user’s experience across the system. For example:
User A creates a new market via the UI.
User B views the feed, finds that market, opens it, and places a trade.
Fast-forward the time or manually trigger the cron job to close the market.
User A (the creator) or an admin resolves the market via the UI.
Verify that at each step, the UI updates correctly: after User B’s trade, the probability changed; after market close, the trade button became disabled; after resolution, the outcome is displayed and User B’s balance increased by the payout.
Also verify notifications if possible (e.g., check that a resolution notification appears for User B). These end-to-end tests ensure that all pieces (frontend, backend, background jobs, etc.) work together as expected in a realistic scenario.
Security Testing: Try to think like an attacker or mischievous user. Attempt actions such as modifying API calls (e.g., send a trade request with a negative spend or an extremely large number, or try to resolve someone else’s market via API). Ensure the system properly validates and rejects these. If the code is open source, consider if any user could read it and find a loophole (e.g. an unauthenticated endpoint or a way to abuse the credit system). Also, test for basic web vulnerabilities: ensure that user inputted market questions are properly escaped in the UI (no XSS). Since the site uses an ORM, SQL injection is less likely, but still ensure no raw queries are vulnerable. If any third-party components are used (like for the slider or date picker), ensure they’re up to date and safe.
By the end of Phase 6, we should have high confidence in the system’s correctness and robustness. All critical paths should be covered by tests, and we’ll have fixed any bugs discovered during this intensive QA phase. This is essential before enabling the feature for real users.
Phase 7: Security and Fairness Checks
Goal: Harden the feature against abuse or exploits and ensure the markets remain fair and trustworthy for users.
Rate Limiting & Anti-Spam: We already added basic rate limits to API endpoints; now consider if they need adjustment or if other actions need limits. For example, limit how frequently a user can create markets (to prevent someone from flooding the platform with junk markets). Ensure that the chosen rate limits (e.g., 10 trades per minute per user, or 5 market creations per day) are enforced and tested. If not done yet, implement a simple mechanism (in-memory or Redis-based) to track request counts per user/IP and respond with HTTP 429 when limits exceeded.
Prevent Self-Dealing by Resolvers: The person resolving a market (oracle or creator) should not be able to unfairly profit from that knowledge. We’ve ensured trades can’t happen after a market’s close time (auto-close stops them). As an extra guard, you might prevent the resolver from placing any trades during the period between market close and resolution if, say, the outcome became known to them (in practice, if auto-close is timely and the outcome isn’t known until after close, this is covered). The key is strictly enforce the sequence: Open → (auto-close at deadline) → Resolve, with no trades after close. Also, double-check that the system never allows a market to be resolved twice or an outcome to be changed once set (the idempotency key helps with this).
Integrity of Payments: Verify and re-verify that no credits are created or destroyed improperly throughout the market lifecycle. During resolution, the total credits paid out should equal the credits that traders spent. The difference is covered by the “bank” of the automated market maker which was implicitly holding the unused probabilities – but since we’re using virtual credits, it all should sum up. Use the ResolutionLog and any ledger to audit a few markets after testing: sum of all user balances before vs. after each market, plus any credits “locked” in that market maker, should net out. This gives both the developers and the users confidence that the system isn’t leaking credits or being gamed.
Input Validation & Content Safety: Ensure all user-provided content (market questions, descriptions, etc.) is sanitized. Limit the question length (e.g., 140 characters as mentioned) to keep content concise and to limit attack surface. If you allow any Markdown or HTML in descriptions, make sure to strip or sanitize disallowed tags to prevent XSS. Verify on the backend that text fields are properly handled (the ORM likely handles SQL injection, but be mindful of things like storing HTML). Essentially, treat prediction market content as user-generated content and apply the same safety filters as you would for posts or comments elsewhere in Mesh.
Feature Flag & Kill Switch: Maintain the ability to quickly disable the prediction market feature if something goes wrong. This likely means wrapping the UI components and API routes with checks for an environment flag or using a service like LaunchDarkly. In practice, before full launch you’ll have it off for users (on for admins/internal testers), and then gradually enable it. But even after launch, if an exploit or severe issue appears (for example, someone finds a way to create credits or a major bug in trading logic), having a kill switch to turn off trading (or the entire feature) can save a lot of trouble. Test the kill switch to ensure it indeed blocks the actions when toggled.
At the end of Phase 7, the system should be very well-guarded. We will have mitigations in place for abuse, and we can assure users that the markets are fair (no cheating by insiders) and secure (no easy way to break the system or steal credits). This fosters trust, which is crucial for user adoption of the feature.
Phase 8: Deployment and Rollout Plan
Goal: Deploy the feature carefully and monitor it in production to ensure a smooth launch with minimal issues.
Staging Deployment: First, deploy all the new code to a staging or test environment. Run all database migrations (for new tables like ResolutionLog, new indexes, the wallet lock function, etc.) on staging. Populate some test data: create a few markets and execute trades between test users to simulate real usage. This is a final end-to-end rehearsal. Verify that everything works outside of the local dev environment: trades succeed, balances update, the cron job closes markets, resolution pays out, notifications fire, and the UI updates accordingly. Fix any issues discovered.
Internal Alpha Release: Enable the prediction market feature for a small set of internal users or alpha testers first. This could be done by enabling the feature flag for only those users. Encourage them to use the feature normally: create markets, trade, resolve outcomes. Closely monitor server logs, error tracking (e.g., Sentry), and feedback from these testers. This real-world usage might uncover edge cases that weren’t caught in testing (for example, a UI quirk on a different browser, or an unexpected user input). Address any issues that come up before expanding access.
Gradual Rollout to Users: Once confidence is gained from alpha testing, start a gradual rollout to the wider user base. For instance: enable the feature for 10% of users (perhaps randomly selected or a specific segment). Monitor for a day or two. Key metrics to watch:
Error rates: Any spike in API errors or uncaught exceptions related to markets?
Performance: Average and P95 latency of trade requests – aim to keep these fast (e.g., under 300ms at the 95th percentile). Also monitor database load from the new queries.
Usage patterns: Are users actually creating markets and trading? Any unexpected usage (like one user creating hundreds of markets)?
System stability: Check that the auto-close cron is running on schedule (e.g., markets close within a few minutes of their deadline) and that no background job failures are occurring.
If all looks good, increase the rollout: go to 50% of users, then 100% (full launch) over a span of days. If any concerning issues appear, pause and fix them before proceeding.
Performance Monitoring: Throughout the rollout, keep an eye on overall system performance. Ensure that adding prediction markets hasn’t significantly slowed down any part of the app. Use APM tools or logging to catch any slow database queries introduced (for example, if scanning the Trade table is slow, consider if more indexes or pagination are needed). The goal is that even at full load, the prediction market features do not degrade the user experience on the site. If you notice the cron job taking too long or trade latency creeping up, consider optimizations (like making expensive operations asynchronous, if any).
Post-Launch Audit & Feedback: After the feature is fully live, do a retrospective audit on the first several markets that resolve. Manually verify that all the numbers add up: no user’s balance looks incorrect, and the resolution payouts correspond to what they should be. This is essentially a final sanity check that the economics are sound in practice. Gather user feedback via surveys or interviews: Do users understand the feature? Is the UI intuitive? Are there requests for additional features? Use this feedback to plan iterative improvements (maybe users want a way to undo a trade, or more information displayed on the market card, etc.).
By following this deployment plan, we ensure that the prediction market feature is launched smoothly and safely. Monitoring and gradual rollout minimize the blast radius of any issue. A thorough post-launch review helps catch anything that slipped by. At this point, Mesh will have a fully functional, production-ready prediction market system. Milestone Overview: Finally, to summarize the phases above into broader milestones (each representing a logical batch of work and verification):
Milestone 1: Database ready – migrations applied for PredictionMarket, Trade, ResolutionLog; wallet locking in place; basic model checks done.
Milestone 2: Core backend complete – placeTrade and resolveMarket implemented and tested thoroughly (unit tests for LMSR and basic integration tests passing).
Milestone 3: API and background jobs – all endpoints (create, trade, resolve, get) are operational and cron job for auto-close is running; you can perform all core actions via API.
Milestone 4: Full frontend – UI components (creation form, market card, trade modal, resolution UI) are implemented and integrated with the backend, with live update mechanism.
Milestone 5: Polishing and hardening – notifications and analytics added, security checks (rate limiting, validation) in place, and the entire system passes QA (automated tests + alpha testing). Feature flag is ready to be turned on for release.
By achieving these milestones, Mesh will deliver a production-ready prediction market feature that is feature-rich, secure, and engaging for users. The implementation is theoretically sound (leveraging proven market-making math) and lays a strong foundation for future enhancements like multi-outcome markets or even real-money integration if desired. With this plan, the Mesh prediction markets can confidently match the reliability and functionality of platforms like Kalshi or Manifold, while providing a novel experience within the Mesh ecosystem.
