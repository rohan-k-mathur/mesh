Backend API Routes & AIF Legality
Enforce RA over direct claim support: The Mesh backend should disallow creating direct Claim→Claim support links in favor of inference (RA) nodes. In AIF, supports are always mediated by a scheme node (RA) rather than a direct I–I edge. Currently the /api/claims/[id]/edges endpoint allows linking claims with type "supports"
GitHub
, which violates that principle. We should deprecate or guard this route for support links. Instead, supporting a claim should go through /api/arguments to create an Argument (RA) with the premise and conclusion claims. For example, a user adding supporting evidence would trigger a new Argument with premiseClaimIds and conclusionClaimId (ensured by the existing guard requiring ≥1 premise
GitHub
). The ClaimEdge model can still be used only as a derived view (via maybeUpsertClaimEdge…) for analytics, but not created directly for supports. This change enforces that every support is an RA node, aligning with AIF’s I/RA separation. Attack route guards: The /api/arguments/[id]/attacks endpoint should be tightened to ensure each attack is well-formed. The assertAttackLegality guard already enforces valid AttackType/TargetScope combos (e.g. UNDERCUTS ⇒ targetScope “inference”, REBUTS ⇒ “conclusion”, UNDERMINES ⇒ “premise”
GitHub
). We should extend this to the claim-edge API as well – e.g. if a payload tries to set an attackType that doesn’t match the provided scope or claim, reject it. Currently, the attack creation uses a fixed EdgeType.rebut for all attacks
GitHub
, which is incorrect for undercuts. We should set the ArgumentEdge.type based on attackType (e.g. use EdgeType.undercut for UNDERCUTS attacks) so the edge semantics align with the attack nature. The roadmap explicitly calls for distinguishing rebuttal vs undercut in the schema, eliminating any generic “attack” type. In practice, this means when creating an ArgumentEdge, map: UNDERCUTS → EdgeType.undercut, REBUTS/UNDERMINES → EdgeType.rebut. (The EdgeType.concede mentioned in plans is a non-attacking link and can be added for completeness, though concessions are tracked via commitments as discussed below.) Additionally, ensure the attack payload includes the proper target reference: e.g. for a rebuttal the targetClaimId must point to the conclusion claim being attacked, for undermine the targetPremiseId must be one of the target argument’s premises
GitHub
GitHub
. These rules are partly enforced now (see the guard and the explicit check that an undermined premise ID belongs to the target argument
GitHub
), but we should comprehensively validate the payload before insertion. Dialogue move endpoint: The /api/dialogue/move route has recently been extended to include replyToMoveId and replyTarget fields
GitHub
, which allows us to enforce formal turn-taking and reply structure. We should make use of this by strictly validating moves through validateMove() on every submission (which is already being done
GitHub
). This ensures no illegal dialogue moves: e.g. no self-reply, no duplicate “WHY” on an already-open issue, no attacking a closed thread (CONCEDE/CLOSE)
GitHub
GitHub
. The validator returns reason codes (R1–R7) and the API rejects moves that violate these rules
GitHub
. For instance, a GROUNDS move is only accepted if there is a prior open WHY with the matching cqKey (R2)
GitHub
GitHub
. Likewise, a CONCEDE in reply to an argument (grounds) triggers R7 (should “accept” the argument rather than concede outright)
GitHub
. By enforcing these at the route level, we align the platform with a Prakken-style dialogue protocol. In Phase 1 of the roadmap, implementing these reply guards and explicit links was a key goal
GitHub
GitHub
. The result is that every dialogue move will be legal in AIF terms (attacks vs surrenders clearly classified, no improper sequences). We should also consider splitting out specialized endpoints for different move types (e.g. an explicit /api/claims/{id}/why or /api/claims/{id}/counter for clarity) as hinted by the plan, but this is optional if the main /move endpoint is well-typed via the kind field and guards. Finally, the combined AIF move endpoint (/api/dialogue/aif-move) already demonstrates the direction: it wraps argument creation and the dialogue move in one transaction for a GROUNDS move
GitHub
GitHub
. We should unify this logic with the main routes. For example, when a user posts a GROUNDS move, the server should ensure an Argument is created (with legality checks) and attach its argumentId to the DialogueMove (this is done in aif-move for type=='GROUNDS'
GitHub
GitHub
). Similarly, an ASSERT move that introduces a new claim could create a stub argument (or at least a Claim entry) for that assertion. Ensuring the back-end does this consistently means the data stays in sync with AIF: every assertion has an I-node, every argument introduced in dialogue has an S-node. In summary, the API layer should guarantee no ad hoc links: all supports go through RAs, and all attacks carry the correct type/scope metadata. These changes address the “no Claim→Claim support” and enforce proper attack targeting as required.
Prisma Schema & Model Adjustments
I–node, RA–node, CA–node, L–node structure: The current Prisma models map well to AIF’s node types, but we can refine them for full compliance. Claims serve as I-nodes, Arguments as RA-nodes, and ArgumentEdge as a representation of CA-nodes (attacks). DialogueMove corresponds to L-nodes (locutions). To solidify this correspondence, we should ensure the schema prevents structures that AIF forbids. For example, a Claim should not directly “support” another Claim without an Argument in between – as noted above, the ClaimEdge model (type supports/rebuts) should likely be used only for derived or convenience views, not as the authoritative link. We might even remove ClaimEdgeType.supports in the future or restrict ClaimEdge insertion to the system (when backfilling from ArgumentEdge). This guarantees that every support link in the DB has an actual Argument behind it. The roadmap envisions using Argument/ArgumentEdge as the primary graph and deriving claim-level edges for “AF reductions” and user views
GitHub
, which aligns with this approach. Argument & Edge model changes: The ArgumentEdge schema already has fields for fine-grained attack metadata (attackType, targetScope, plus optional targetClaimId, targetPremiseId, targetInferenceId)
GitHub
GitHub
. This is excellent for representing different attack schemes: e.g. an edge with attackType='UNDERCUTS' and targetScope='inference' means a CA-node targeting an inference (warrant). One adjustment is to ensure the enum EdgeType aligns with attackType. Currently, EdgeType has support | rebut | undercut
GitHub
, but it may not cover an “undermine” explicitly. We should clarify usage: likely any attack (rebut/undermine) that targets a claim or premise is classified as a rebut edge broadly, versus an undercut edge for warrant attacks. The Phase 1 roadmap suggests splitting the generic “attack” into explicit rebut and undercut types (and adding a concede type for surrender links). In practice, we can treat EdgeType.rebut as “generic attack on content” and use it for both REBUTS and UNDERMINES AttackTypes (since both target an assertion’s content, either a conclusion or a premise), while EdgeType.undercut is used when AttackType is UNDERCUTS (attacking the inferential link). It may be worth adding an EdgeType.support value for completeness if we ever allow arguments to support other arguments (though currently support is modeled by chaining claims, not by a direct Arg→Arg edge). The net effect is schema enforcement that an ArgumentEdge always has the proper combination of type + attackType + targetScope – we could add a Prisma constraint or a model-level check if possible (though Prisma’s constraint options are limited to unique indexes). At least, our business logic will only set valid combos as described. Support multiple premises and inferences: The schema supports multiple premises per Argument (ArgumentPremise relations)
GitHub
GitHub
. This allows RA-nodes with an arbitrary number of premises (convergent arguments). No change needed there, but we must handle them correctly in evaluation (see below). Each Argument currently has a single conclusionClaimId (one conclusion). We will maintain that since AIF RA-nodes produce one conclusion. If we ever want to model an argument with multiple conclusions, that would actually be multiple RA-nodes in AIF, so we should continue to represent each inference separately. One area to examine is targetInferenceId on ArgumentEdge
GitHub
. This field suggests we anticipate arguments that have multiple inference steps or rules internally – for example, if an Argument has multiple implicit rules or a complex warrant that could be attacked in parts. Currently, we don’t instantiate separate “inference nodes” for each rule (the Argument itself is the RA). If we plan to allow multiple warrants, we might consider a sub-structure (like a separate model for Inference or using the existing DefaultRule model). However, an easier approach: keep Argument as the single inference node for now (since each Argument represents one applied scheme or enthymeme). In that case targetInferenceId might not be utilized yet. If future phases involve embedded logic sub-dialogues (e.g., checking an argument’s validity via a proof), we might generate multiple inference IDs (e.g., each step of a proof as an inference). For now, we can leave targetInferenceId as a placeholder – attacks with that field could simply be treated as undercuts on the whole argument. When we do implement multiple inference support, we would likely create a child record for each inference rule (or use the existing DefaultRule as a representation of a specific inference) and let targetInferenceId point to it. The AIF integration roadmap acknowledges the need to handle attacks on the “inferential link” separately, which we have covered with UNDERCUT edges. Thus, no fundamental Prisma changes are needed immediately for this, aside from using the field appropriately if present (e.g., storing which specific rule was undercut). Critical questions and schemes: The models for argumentation schemes (ArgumentScheme, SchemeInstance, CriticalQuestion) are already in place and should be leveraged more fully. Each Argument can link to a scheme (via schemeId on Argument) and thereby inherits a set of Critical Questions (CQs)
GitHub
GitHub
. We should ensure the schema supports mapping CQs to attacks: notably, CriticalQuestion.attackType and targetScope are present to indicate what kind of attack each CQ corresponds to (e.g. a particular CQ might be an undercut on an assumption, another a rebuttal of the conclusion)
GitHub
GitHub
. This is great – it means when a CQ is raised, we know what form of ArgumentEdge to create if someone wants to address it. We should enforce that each CQ entry for a scheme has those fields correctly set (which they appear to be by design). The cqKey stored on ArgumentEdge
GitHub
should be used: whenever an attack is created in response to a specific CQ, populate the edge’s cqKey with that identifier. This ties the new counter-argument back to the scheme’s question it addresses. The schema already has CQStatus to track which CQs are open or answered on a given target
GitHub
GitHub
. We might adjust that model slightly to include, for example, a reference to the answering argument if one exists (we have argumentId in CQStatus
GitHub
, which might serve that purpose). Ensuring that when an argument is created as an answer, we set CQStatus.satisfied and link the IDs appropriately will preserve the integrity of CQ workflows. Virtual attacks (implicit conflicts): The schema has a notion of claim negation: each Claim may point to another it negates (Claim.negatesClaimId) and be negated by others
GitHub
. We should utilize this to create implicit CA-nodes. For example, if Claim A is marked as negating Claim B, the system can automatically treat A and B as conflicting assertions. Concretely, we could on the fly create an ArgumentEdge (or at least a ClaimEdge) representing a rebuttal between A and B. One approach: when a negation link is set, create a hidden Argument for the negating claim (if none exists) and an ArgumentEdge with attackType=REBUTS, targetScope='conclusion' linking it to the argument(s) for the negated claim. In practice, since any standalone claim can be considered an “argument” asserting itself (the importer does exactly this by creating a trivial Argument for isolated claims
GitHub
), Claim A’s negation of B means “Argument A (asserting claim A) rebuts Argument B (asserting claim B)”. We might not literally create these records until needed, but our evaluation logic can account for negations by treating negated claims as conflicting. At minimum, we should mark such pairs in the UI and when exporting to AIF. The export function currently does not special-case negations beyond the user-defined edges; we may consider adding, during export, a CA-node for each negation link if no explicit attack exists. This ensures virtual attacks (like contradictory claims) don’t slip through the cracks of our graph. In summary, the Prisma schema is largely prepared for AIF structures — only minor tweaks are needed: tightening the coupling between EdgeType and AttackType, using scheme and CQ fields consistently, and possibly automating conflict links for negations. These changes support the richer I/RA/CA/L model envisioned in the Agora metastructure. They also set the stage for phases like scheme-based reasoning and critical question workflows (Phase 2 in the roadmap focuses on making CQs actionable attacks, which these schema provisions enable).
Evaluation Logic for Argument Frameworks
The evaluation engine (lib/eval/af.ts) should be updated to reflect the refined argument graph, particularly with the new attack types and multi-premise arguments. Currently, we build the abstract argument framework (AF) by treating each Argument as a node and each ArgumentEdge as an attack relation. The buildAF() helper already handles the various target scopes: it adds an attack from the attacker argument to the target argument for undercuts (inference attacks), to every argument using a targeted premise for undermines, and to every argument concluding a targeted claim for rebuttals
GitHub
. This logic should be reviewed and fine-tuned: it ensures that if an argument undermines a premise, all RA-nodes relying on that premise are considered attacked
GitHub
. Likewise, a rebuttal attack on a claim propagates to all arguments with that claim as conclusion
GitHub
. This effectively implements the notion that attacking a proposition defeats any inference that depends on it, which is consistent with how AIF’s CA-nodes work in an Argument Framework. We should verify that this covers edge cases: e.g. if an argument has multiple premises and only one is undermined, our current approach will still mark the whole argument as under attack (since the attacker appears in its attackers set). This is appropriate under a defeasible logic assumption – an argument fails if any premise is defeated. If our semantics later allow an argument to “withstand” a challenge to one premise (say, in a cumulative probabilistic sense), we’d need a more complex evaluation. But for classical argument acceptability, the current scheme is fine (one successful attack is enough to make a node OUT). We should document this assumption clearly. Also, note that targetInferenceId is not explicitly used in buildAF – undercuts simply attack the argument node as a whole
GitHub
. If in the future we allow an argument with multiple independent inference rules, we might adjust the attack propagation: e.g. an undercut targeting a specific inference rule would only defeat the argument’s conclusion if no alternative inference remains undefeated. Implementing that would mean representing each inference as a separate node in the AF (so that undercutting one rule doesn’t immediately knock out the whole argument node). That is a more advanced feature; for now, we assume one argument = one inference node, so undercut = attack on that node. The labeling algorithms themselves – grounded and preferred – need slight enhancement to incorporate the new data but are otherwise logically sound. The grounded labelling function marks a node IN if none of its attackers are IN, and OUT if it has any attacker IN
GitHub
. This remains correct in our scenario; the only adjustment is ensuring the attackersOf map is built with all the computed attacks (which buildAF provides). We should test that the presence of multiple attacks from one node to many (or vice versa) doesn’t break anything (it shouldn’t – the sets simply aggregate attackers). The preferred semantics function enumerates conflict-free sets and then admissible sets
GitHub
 – this will work as is, since it too just relies on the set of attack pairs. However, one thing to consider is support relations: if we introduce the concept of support edges (not currently used in AF calculations), a more sophisticated approach (bipolar AF or support as additional constraints) is needed. The roadmap mentions “support edges & AF reductions” in later phases
GitHub
, which suggests we might incorporate support in evaluations (e.g. an argument being supported might justify reinstatement in some semantics). For now, we are focusing on attack-based labeling (Dung’s AF). Any support edges can be ignored in the AF, or we can transform them (some frameworks convert a support into a meta-attack on an attack, etc.). In the immediate term, we will exclude support edges from the AF or handle them outside the core labeling (e.g., simply count supports for UX scoring, not for IN/OUT determination). The code already effectively does this by only considering ArgumentEdge entries (which currently represent attacks) and not direct ClaimEdge supports in the AF construction. We should also ensure explanation of labels leverages our rich metadata. The ClaimLabel model stores the grounded label and an optional explainJson for why a claim is in or out
GitHub
GitHub
. We can populate this explanation by tracing through the argument graph. For example, if a claim is OUT, the explanation could list the attacking argument (or arguments) that caused it to be defeated, and those arguments’ statuses. Since we know each CA-edge’s type, we can generate user-friendly explanations like “Claim C is rebutted by Argument A (which is IN)” or “premise P of Argument B was undermined by Argument X, defeating B, which in turn defeats claim C.” Generating these traces might involve a recursive walk: start from an OUT node, find an IN attacker, then if that attacker is an argument, see if that argument is IN due to no attackers, etc. We can use the existing data in attackersOf or even the ClaimEdge table for a higher-level view. This is more of a nice-to-have for transparency, but it aligns with making the AF status visible, which is noted as a UI goal (e.g. “AF labels visible” in the roadmap). Finally, we must test the label evaluators on various scenarios now possible: arguments with multiple premises (test that undermining one premise flips the argument to OUT as expected), chained arguments (A supports B’s conclusion, B supports a claim – ensure if A is OUT then B’s support might fail, etc.), and mixed attack types (e.g. an argument that is rebutted by one attacker and undercut by another – either attacker alone should make it OUT). The fundamental grounded/preferred algorithms will handle multiple attackers correctly (since even one IN attacker suffices to make a node OUT). But documenting these cases will be important for users. We might also consider implementing other semantics (e.g. ideal or stable extensions) if needed for certain decision support features, but grounded and preferred (skeptical) are a good start and already implemented. As a future improvement, to reflect dialectical status in real-time, we could recompute labels on every move or change and store them (the code calls recomputeGroundedForDelib after certain writes
GitHub
, presumably to update ClaimLabel). This ensures the UI can show, say, which claims are currently accepted (IN) given the state of debate. In summary, the evaluation logic is mostly a matter of confirming the attack propagation covers all new attack types and that we correctly interpret multi-premise arguments. The buildAF function should be kept in sync with any changes (for example, if we ever allow a support edge as a pro-attack, we’d adjust it to perhaps treat support as negative attack weight or ignore it). For now, by adhering to the rules we’ve set (each attack type mapped to an appropriate relation), the grounded and preferred label calculations will produce a correct analysis of the CA/RA graph including undercuts and rebuttals on conclusions or premises. This meets the needs of Phase 1 and 2 where argument defeat status is crucial (e.g. to implement the “accept argument” vs “concede” distinction in the protocol, we rely on knowing if an argument is undefeated)
GitHub
.
UI Component Enhancements
With the back-end enforcing proper structures, the front-end should be upgraded to visualize and guide those structures. Key components to improve: ArgumentCard, SchemeComposer, AttackMenu, and LegalMovesChips (among others). The aim is to make scheme-based argument creation and critical questions intuitive, and to clearly distinguish undercuts vs rebuttals in the UI. ArgumentCard: This component displays an argument (premises, conclusion, etc.) and should reflect the argument’s scheme and status. We recommend showing the argument scheme name or icon on the card if the argument has a schemeId. For example, an Argument using the “Expert Opinion” scheme could have a small badge or color indicating that, and perhaps a tooltip with the scheme’s title/summary
GitHub
GitHub
. This helps users understand the nature of the argument at a glance (is it an analogy, a causal argument, an authority argument, etc.). Additionally, if the argument has any implicit premises or warrant, the card can hint at them – e.g. “(Assuming [warrant])” in smaller text if implicitWarrant is set or if a ClaimWarrant exists for the conclusion
GitHub
GitHub
. Visually, undercut and rebuttals affecting this argument should be indicated on the card. One idea is to highlight the conclusion or the inference with an icon when it’s under attack. For instance, if Argument A is undercut, draw a ⟂ symbol on the connection between its premises and conclusion to signify an attack on the warrant. If it’s rebutted, maybe flag the conclusion claim text with a ⚔ or strikethrough. These visual cues tie into how the AttackMenu adds attacks (“Challenge reasoning” for undercut, vs “Challenge claim” for rebuttal)
GitHub
GitHub
. We can also use color-coding: perhaps rebuttals (attacks on claims) use a red outline on the conclusion, undercuts (attacks on inference) use a different color on the inference line, etc. In addition, ArgumentCard could offer quick-action buttons: e.g. a “Why?” button to ask for grounds on this argument, or an “Attack” dropdown that opens the AttackMenu targeting this argument. This would streamline the workflow by not requiring users to find the AttackMenu elsewhere. SchemeComposer: The SchemeComposer is central to scheme-based creation. It currently lets the user choose a scheme, select a conclusion claim (passed in as prop), and enter premise IDs, then creates the argument and shows its CQs
GitHub
GitHub
. To enhance this: we should replace the plain premise ID input with a Claim picker/autocomplete, so users can find existing knowledge base claims or add new ones by text (the component even notes this: “Use your real ClaimPicker here”
GitHub
). This will make constructing arguments much easier and less error-prone than typing IDs. Next, we can utilize the scheme’s slotHints which provide roles/labels for premises
GitHub
GitHub
. Instead of just displaying them as reference chips (as is done now
GitHub
), we could render dedicated input fields for each expected premise role. For example, if the scheme expects a premise for “Expert’s statement” and one for “Expert’s credibility”, we show two input slots labeled accordingly. The user can then fill each slot with a claim (or indicate “none” if not applicable). This structured input ensures the argument fits the scheme format. Moreover, after creating the argument, SchemeComposer already fetches the critical questions for that argument
GitHub
GitHub
 and displays them as chips. We should refine this CQ workflow: when a CQ chip is clicked, it currently calls askCQ() which likely marks the question as opened
GitHub
. We should then prompt the user to answer it – possibly by launching an AttackMenu or scheme composer pre-configured to address that CQ. For example, if the CQ is “Is the expert biased?” (which might map to an undermining attack on a premise “Expert is trustworthy”), clicking it could open a modal to create an argument that provides evidence of bias (an undermining premise against the credibility premise). This ties the CQ directly into an attack creation. Even without a full modal flow, we should at least highlight that the CQ is now open (the chip could change style) and maybe provide a text area for the user to jot an answer or context that can later be turned into an argument. The roadmap suggests that clicking a CQ should pre-configure the DeliberationComposer to the appropriate move (e.g. a rebuttal or undercut) – integrating SchemeComposer’s CQ chips with the global dialogue composer would achieve this. AttackMenu: Currently, AttackMenu provides three attack options on an argument: rebut the conclusion, undercut the inference, or undermine a premise
GitHub
GitHub
. It’s functional but needs polish for real use. First, for rebuttals, it asks for a “counter-claim id” input
GitHub
. This should be a searchable dropdown of claims (and an option to create a new Claim on the fly). Ideally, the user can type the counter-argument statement, and under the hood we create a new Claim (if it doesn’t match an existing one) and then create the Argument and Edge. We should hide the complexity of IDs – the user just selects or writes the content of their counter-claim. The UI can still internally fetch /api/arguments and then /api/arguments/{id}/attacks as it does, but with actual data. Similarly for undercuts and undermines, the code currently uses placeholder fake claim IDs ("exception:<argId>", "contrary:<premiseId>")
GitHub
GitHub
 – instead, we need to prompt the user for what exception or contrary premise they have in mind. For example, if they choose “Challenge reasoning”, we should ask them to provide a short statement describing the exception to the rule. That statement would become the conclusion of a new Argument (the undercutting argument). We might use a default template like “The general rule doesn’t apply because… [user input]”. But at minimum, allow a text input to create a claim for the exception. For undermine, if the argument has multiple premises, the AttackMenu already lets the user pick which premise to target via a dropdown
GitHub
. This is good – it lists the premises by text. Once the user selects a premise, we should ask for a contradicting claim to undermine it (e.g. if premise is “X causes Y”, the user might input “X does NOT cause Y” or some counter-evidence). The current design just fabricates "contrary:<premiseId>" as a claim ID, which will not work in practice unless that exact ID exists. So, integrating a Claim creation step here is crucial. In summary, AttackMenu should work like: user clicks attack type, a dialog or inline form appears to fill in the counterclaim’s content (unless they chose a known claim via an autocomplete), then the system creates the needed claim/argument/edge. On the visual side, we want to clearly differentiate rebuttals vs undercuts in the map. As mentioned for ArgumentCard, undercuts might be drawn to a “warrant” symbol. If our diagram (DiagramView) can support it, we could draw RA nodes as boxes and I-nodes as circles/ovals (standard AIF notation), then an undercut CA could be drawn as a special node linking into the RA. However, implementing a full separate CA node in the UI might be too involved. Instead, a simpler approach: draw undercutting argument arrows to target an argument’s link line or just slightly offset to indicate it hits the argument’s internals rather than its conclusion. Using different arrow styles or colors is also effective (perhaps a ⟂ symbol or dashed red line for undercut, vs a solid red line to the claim for rebut). The AttackMenu’s text “lands on the warrant box”
GitHub
 suggests the intended design is to have a warrant box in the UI – if we do have a box (or just treat the argument node as having a distinct warrant segment), then indeed attach the undercut arrow there. This will help users see the distinction: rebuttals attack claims, undercuts attack reasoning. The LegalMovesChips and general dialogue UI should also reflect this in wording – e.g. a “counterargument” could be broken down into “challenge the claim” vs “challenge the reasoning” options if appropriate. Perhaps when a user chooses “Counterargue” in response to a claim, we could then ask: do you want to rebut the claim’s truth or undercut the way it was inferred? This may be an advanced option; initially, we might default to rebuttal unless the user specifically indicates otherwise (for example, via the critical questions interface, which would naturally lead to undercuts if the issue is with an assumption). LegalMovesChips: This component shows the set of allowed moves (e.g. “Why?”, “Concede”, “Counterargue”) for a selected target in the dialogue. To improve it, we should incorporate force labels and contextual cues. Each chip can be visually tagged as an attack move or a surrender move. For instance, attach an “attack” icon (⚔) or red highlight to chips like WHY and Counterargument (since they keep the dispute going), and a peace/check icon or green highlight to CONCEDE or RETRACT (since those resolve or yield on a point). The importance of distinguishing these was noted in our research on dialogue systems – it helps users see which moves will extend the debate vs close an issue. We can obtain this info either from the move type (we know which are attacks vs surrenders) or explicitly from the backend if we extend /legal-moves to tag each option with a force: 'ATTACK' | 'SURRENDER' attribute. In addition, LegalMovesChips can display relevance hints: for example, if the user has asked “Why?” on a claim, then a “Provide Grounds” move (which is an attack responding to that Why) might be shown prominently. Indeed, the current /api/dialogue/legal-moves logic already accounts for open CQs and suggests GROUNDS when appropriate
GitHub
. We should surface the context on the chip label — e.g. “Answer WHY: give grounds” instead of a generic “Grounds” label. Moreover, when a branch is closed (say a claim was conceded or the locus closed), we should either not show attack moves or disable them with a tooltip (“This issue is resolved – no further attacks allowed”), reflecting rule R5 (no attack after surrender) which the backend enforces
GitHub
GitHub
. Critical question integration: Beyond the SchemeComposer’s CQ panel, we might have CQs appear in context elsewhere. For instance, in an ArgumentCard, if there are unanswered critical questions for that argument’s scheme, we could show a small “⚠ Open Questions” indicator. Clicking it could scroll the user to that argument’s section in the deepdive panel where they can see and address the CQs. Another UI element could be a CQ chip list under a claim or argument in the map view, showing which typical challenges are still pending. This would guide users to fill gaps in reasoning. The roadmap calls for CQ workflows to be first-class: e.g. the system should map each CQ to a specific kind of counter-argument and make it easy to post that. So ideally, if a user sees an open question “What if the expert is biased?”, they click it and the interface might open a composer with “premise: The expert has a conflict of interest (bias)” ready to go as an undermining argument. This kind of guided interaction would be a big UX win. While some of this is phase-2 polish, we can start with simpler cues: mark answered questions with a check (as SchemeComposer already does in its list
GitHub
) and perhaps hide or de-emphasize CQs that have been satisfied (status “answered”). In general, visual distinction for undercut vs rebut should be consistent across AttackMenu, ArgumentCard, and the map diagram. For example, we might use different icons: perhaps a curved arrow icon for rebut (since it attacks a claim node) and a T-shaped icon for undercut (attacking the inference). LegalMovesChips could even use these icons in the chip text (e.g. “Challenge Claim ⟲” vs “Challenge Reasoning ⟂”) to reinforce understanding. On the diagram itself (e.g. DiagramView component), ensure the legend or node styling conveys this: maybe draw a small “warrant” box on argument nodes so that an undercut can connect there – as the AttackMenu hint suggests, the undercut arrow should visibly terminate at the argument’s warrant line
GitHub
. Finally, a word on general UX improvements: The user should have feedback when they perform these actions. For instance, after creating an argument or posting an attack, the relevant UI panels should update in real-time to show the new node or edge, and any affected labels (like a claim that became out should get a visual mark). The deepdive or map view can highlight newly added elements briefly. The roadmap’s cross-cutting tasks mention “UX fit-and-finish” on exactly these items (legal move chips, CQ chips, AF status badges) – our recommendations above are in line with that. For example, once we have AF labels computed, we can put an “IN/OUT” badge on claims and arguments in the UI (perhaps in a corner of the card or node). An OUT claim could be shown faded or with a red X badge, an IN argument with a green check, etc., to communicate the evaluation outcome. This helps users see which parts of the debate are accepted or defeated at a glance. All these UI tweaks should be implemented phase-wise: Phase 1 focused on the basic dialogue chips and explicit replies (so ensure LegalMovesChips reliably shows moves like “Why, Concede” after an assertion, and enforce one move per reply). Phase 2 will bring scheme and CQ integration (enhancing SchemeComposer, linking CQs to attacks). By Phase 3 and beyond, we’ll have visualization of evaluation results and perhaps ludics-based highlights (mentioned as heatmaps, etc., which is outside our current scope but suggests deeper visualization). Our immediate UI goal is a smoother workflow for constructing arguments with schemes and posting counter-arguments with clear options. When these improvements are in place, users can naturally create AIF-valid structures without needing to know the underlying formalisms (the UI will guide them to, say, pick a scheme, fill in premises, respond to critical questions, and choose the right attack type when challenging something).
Import/Export and Interoperability
The Mesh platform’s AIF import/export functionality should be reviewed to ensure full fidelity with the AIF standard (both JSON-LD and AIFdb JSON formats). On the export side, our exportDeliberationAsAifJSONLD function already serializes the debate into AIF: it creates I-nodes for each Claim (with text)
GitHub
, S-nodes for each Argument (type “aif:RA”, including a pointer to the scheme used)
GitHub
, and constructs CA-nodes for each ArgumentEdge (with attackType and targetScope recorded)
GitHub
GitHub
. It also handles L-nodes for each DialogueMove, linking them via “Illocutes” and “Replies” edges
GitHub
. This is a solid start. We should test the output against known AIF tools (OVA+, AIFdb) to ensure it’s valid. A few things to verify/adjust in export:
* Scheme references: We output usesScheme as the scheme’s key on RA-nodesGitHub. That is good, but AIF expects a URI or reference to a scheme definition. If our keys correspond to standard scheme IDs (or we have a context defining them), that’s fine. If not, we might consider adding more info (maybe the scheme name or a reference to a known ontology). At minimum, including the scheme’s key (which might be something like “argument from expert opinion”) is useful. In JSON-LD, we could also embed a small scheme definition or at least ensure the context has usesScheme defined appropriately (the provided context.json likely covers this).
* Virtual nodes for stand-alone claims: If a claim appears in the deliberation with no argument as its conclusion (say a free-standing claim that wasn’t used), our export currently will still output it as an I-node. But if that claim was attacked by a CA-node (e.g., someone rebutted it directly), the CA in export expects an attacker I-node and a target I-node being attacked. In our current logic, if an ArgumentEdge has targetScope “conclusion” with a targetClaimId (meaning a rebuttal on a claim), we output the CA such that it attacks an I-node (the target claim)GitHub. We also output an edge from the attacker’s conclusion I to the CA as premiseGitHub. This yields a CA node attacking an I-node, which is correct for a direct rebuttal scenario. We should double-check that the CA node in this case is properly formed with one premise (attacker I) and one attack edge to the target I. The current code does handle all three cases (conclusion attack → Attacks edge to I:targetClaimIdGitHub, inference attack → Attacks edge to S:argumentIdGitHub, premise attack → Attacks edge to I:premiseIdGitHub). So structurally it looks good. Ensuring no information is lost: we include attackType and targetScope on the CA nodeGitHub, which is effectively custom metadata beyond core AIF (standard AIF doesn’t have those properties by default). But since we control the context, that’s fine – it will help round-trip back into our system.
* Content of L-nodes: We label L-nodes with illocution type and text (taking payload.expression as text)GitHub. We should confirm that for assertions the payload.expression indeed contains the statement, and for moves like WHY or CLOSE it’s appropriately set (e.g. WHY might have an expression of a question or be blank – which is fine). If needed, we might enrich L-nodes by linking them to the content they assert or question. In AIF, an L-node “Illocutes” an I-node or S-node. We do add Illocutes edges: if a move has an argumentId, we Illocute to S:argument; if it has contentClaimId (which might correspond to an ASSERT move’s claim) we Illocute to I:claimGitHub. The export code expects m.contentClaimId, but our DialogueMove schema didn’t explicitly list contentClaimId. Possibly, in practice targetType:'claim' and targetId serve that role. We might need to adjust the export: for an ASSERT move where targetType was 'claim', the targetId is the claim id of the assertion – so we should use that as contentClaimId. In implementation, we can set contentClaimId = (m.targetType==='claim' ? m.targetId : null) when preparing the moves for export. This way, the L-node will Illocute to the I-node of the content claim asserted. That preserves the connection between a locution and the proposition it puts forward (important for reconstructing dialogues).
For import, our importAifJSONLD function reads I, RA, CA, L nodes and edges and maps them into Mesh structures
GitHub
GitHub
. There are a few improvements to consider:
* Scheme handling: Currently, when creating Arguments for RA-nodes, we do not set a schemeId (we pass schemeId: null)GitHub. We should parse the RA node’s usesScheme field (if present) – e.g., if the JSON has "usesScheme": "argumentFromExpertOpinion", we should attempt to find an ArgumentScheme in our DB with key "argumentFromExpertOpinion" and associate it. If the scheme isn’t found, we might create a placeholder in ArgumentScheme so that we don’t lose that info. Similarly, for CA-nodes, if they had any standard identifiers (though our export uses custom fields for attackType/targetScope), the import might not use those directly except to decide which attack type to create. But since we embed attackType in the CA node JSON, our import does use it: it checks if target is RA or I to decide undercut vs rebut/undermineGitHub. We actually ignore the attackType string in the JSON and infer it from context: CA attacking an RA becomes UNDERCUTSGitHub, CA attacking an I that is a premise in some RA becomes UNDERMINESGitHub, otherwise CA attacking an I (not a premise) is treated as REBUTSGitHub. This logic should be consistent with how we exported, and it appears to be (it’s essentially the inverse mapping of export). One tweak: using attackType property explicitly could simplify this logic, but since we trust the structural inference, it’s okay.
* Creating minimal arguments for orphan claims: The import code smartly uses ensureArgumentForClaim to handle attacker I-nodes that aren’t already conclusions of an argumentGitHub. It creates a trivial Argument with the claim as both premise and conclusion (marked implicit) to serve as an attacker node if neededGitHubGitHub. This ensures every attack has an Argument node on the “from” side. We should do something similar for targets that are standalone claims: in the code, if a CA attacks an Information node that is not used as a premise (meaning no RA has it as conclusion or premise), they currently create a rebuttal edge from attackerArg to itself (toArgumentId = attackerArgId)GitHub. This is a bit odd – effectively a self-edge – which likely was meant to represent an attack on an isolated claim. It might be better to instead create another trivial Argument for the target claim. For example, if claim X is attacked but had no RA, we can call ensureArgumentForClaim for X as well, to get a target Argument node. Then create an ArgumentEdge from attackerArg to targetArg with REBUTS. That would be more semantically clear than a self-loop. So a recommended change: modify the import logic such that in the else branch at GitHub, we do: find/ensure an Argument for the target I (tgt.to), then create an ArgumentEdge from attackerArg to that new targetArg with REBUTS, targetScope:'conclusion'. This way, the imported graph remains consistent (no dummy self-edges).
* Dialogue moves (L-nodes): The current import function ends with a note “Optional: import L-nodes later”GitHub, meaning it doesn’t yet recreate the dialogue moves. In a full AIF JSON-LD, we have L-nodes representing each locution and “Replies” edges forming the dialogue tree. Importing those would involve creating DialogueMove records. We could implement this in a future iteration: for each L-node, create a DialogueMove with the given illocution (map aif:Assert → type='ASSERT', etc.), and content linking: if there’s an Illocutes edge from L to an I node, that means the move asserted that claim (so targetType='claim', targetId = claimId). If Illocutes to an S node, the move put forward an argument (so maybe that move was a GROUNDS move and we link argumentId). The Replies relations between L-nodes can be used to set replyToMoveId. Essentially, we have enough in AIF to reconstruct a lot of the dialogue, especially if the AIF file came from our export originally. Doing this would preserve the discussion structure on import, not just the argument graph. While not strictly necessary for aligning with AIF (the critical part is the argument network), it’s a completeness step to consider, especially if the user wants to round-trip debates and keep the dialogue context. For now, we can document that our import focuses on the argument graph, and leaves dialogue moves aside unless needed.
* AIFdb JSON support: AIFdb (and OVA) sometimes uses a slightly different JSON (non-JSON-LD) or CSV formats. We should ensure our importer is flexible if the @context is missing or if keys are named slightly differently (for example, nodes might have a type field instead of @type). We can either adjust parsing or require JSON-LD format. Given that JSON-LD is our default, it might be acceptable to ask users to provide that. However, since the question explicitly mentions AIFdb JSON, we might implement a small normalization: if a node doesn’t have @type but has type, set @type = 'aif:'+type. Or provide a separate import path/flag for “AIFdb” where we tweak the parser accordingly. Similarly, ensure text is captured; if AIFdb JSON uses a field like node.text or node.label, adapt to that. These are minor parsing nuances.
After making these improvements, we should test an export→import round trip on a sample deliberation. According to the roadmap, a success criterion is being able to export from Mesh and import into OVA/Carneades, and vice versa. We should try exporting a known argument map, importing it into OVA (which uses AIF), making a small change, exporting from OVA, and then importing back into Mesh to see if everything (claims, arguments, attacks, maybe dialogue structure) comes through intact. Any metadata we can’t import (like OVA’s node positions or author info) can be safely ignored or stored in a generic way if desired. The core is structural integrity: no duplication of identical claims (our moid hashing in Claim helps avoid duplicate text), correct linking of premises and conclusions, and all attack relations preserved. We should also preserve scheme information in round-trip. If we export an argument with usesScheme = ExampleScheme, and someone imports it back, that argument should end up with that scheme in Mesh. As noted, adding scheme lookup/creation in import will handle this. Likewise, critical questions: our export doesn’t explicitly list CQs, but if an argument was unresolved on some CQ, that typically manifests as an open WHY in the dialogue (which would be an L-node with illocution “Question” and linked to a particular S or I). If we eventually import L-nodes, we could also reconstruct open questions and mark the corresponding CQ as open in our DB. This is an advanced aspect, but it highlights that our data model actually carries more nuance than standard AIF (which doesn’t natively understand which question corresponds to which CQ scheme – that’s our extension). However, since we embed cqKey on CA nodes and on edges, an imported CA might carry cqKey (we include it in export
GitHub
). We didn’t parse that in import explicitly. Perhaps we should: if a CA node has a cqKey property, and we create an ArgumentEdge for it, we can set the same cqKey on our edge, thus preserving that link to a critical question. This way, if the scheme definitions are present, we know exactly which CQ prompted that attack. In summary, to fully align our import/export with the AIF roadmap: we ensure no data loss of structure (schemes, CQs, etc.), produce valid JSON-LD that AIF tools accept, and handle incoming AIF data gracefully. The Phase 6 roadmap item explicitly calls for an /api/deliberations/{id}/aif export and the ability to round-trip a map with OVA+ – with the adjustments above, we will meet that. We'll document the usage (e.g., instruct that the import expects JSON-LD format unless we add auto-detection for AIFdb JSON). These import/export capabilities will allow Mesh’s agora to interoperate with research tools and legacy data, fulfilling the promise of not being a “walled garden”.

Implementation Priorities: We can implement these improvements in phases corresponding to the roadmap:
* Phase 1 (Immediate): Strengthen backend route guards (assertAttackLegality usage everywhere, no direct claim→claim supports), update EdgeType handling, integrate validateMove fully, and add reply metadata on DialogueMoves. Simultaneously, tweak LegalMoveChips and dialogue UI for explicit replies and force (attack/surrender) indicationsGitHub.
* Phase 2: Focus on schema and UI for schemes and CQs. Ensure Prisma models for schemes/CQs are fully utilized (no new tables needed, just better usage), and enhance SchemeComposer, ArgumentCard, AttackMenu as described to facilitate scheme-based argument entry and CQ-driven counterarguments. Introduce visual distinctions for rebut vs undercut in maps and cards.
* Phase 3: Refine evaluation feedback. Use buildAF and label results to show AF status on UI (e.g., badges on ArgumentCard for IN/OUT) and perhaps implement more nuanced evaluations if needed (like highlight undefeated arguments for user attention). This is also where we consider if any “support” edges will factor into representation (if so, implement as per bipolar AF conversion or simple highlighting).
* Phase 4: Complete import/export polish. Add scheme matching on import, include dialogue moves if possible, and test round-trip with external tools. Provide both JSON-LD and a simplified JSON export if needed for AIFdb compatibility. This phase ensures the platform can fluidly exchange data using AIF standards.
By following this plan, each module is incrementally improved and kept in alignment with the AIF integration roadmap and the evolving “Digital Agora” architecture. Each recommendation above has a direct tie to the roadmap goals (noted in citations), ensuring that our implementation not only fixes current gaps but also moves the project toward the envisioned end-state of a fully AIF-compliant, user-friendly deliberation system.

Citations

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/claims/[id]/edges/route.ts#L10-L18

guards.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/guards.ts#L28-L36

guards.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/guards.ts#L44-L53

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/arguments/[id]/attacks/route.ts#L50-L58

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/arguments/[id]/attacks/route.ts#L42-L49

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/arguments/[id]/attacks/route.ts#L44-L52

MeshAgoraPlanning.txt
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/MeshAgoraPlanning.txt#L20-L28

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/dialogue/move/route.ts#L2-L5

validate.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/dialogue/validate.ts#L38-L47

validate.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/dialogue/validate.ts#L50-L58

MeshAgoraPlanning.txt
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/MeshAgoraPlanning.txt#L92-L98

validate.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/dialogue/validate.ts#L44-L52

MeshAgoraPlanning.txt
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/MeshAgoraPlanning.txt#L70-L78

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/dialogue/aif-move/route.ts#L18-L27

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/dialogue/aif-move/route.ts#L51-L59

MeshAgoraPlanning.txt
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/MeshAgoraPlanning.txt#L14-L16

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2219-L2227

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2230-L2238

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2-L5

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2163-L2171

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2208-L2216

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2948-L2956

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2966-L2974

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L3038-L3046

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L3047-L3055

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2973-L2981

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2976-L2984

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2822-L2830

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L4-L13

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

buildAf.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/eval/buildAf.ts#L20-L28

buildAf.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/eval/buildAf.ts#L22-L25

buildAf.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/eval/buildAf.ts#L24-L28

buildAf.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/eval/buildAf.ts#L20-L23

af.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/eval/af.ts#L15-L24

af.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/eval/af.ts#L40-L50

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2812-L2820

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2831-L2833

MeshAgoraPlanning.txt
file://file-A6q3JCQCgtsbYcYvJJ8Ffw

route.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/app/api/claims/[id]/edges/route.ts#L62-L65

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2966-L2973

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2799-L2807

schema.prisma
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/models/schema.prisma#L2801-L2809

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L82-L91

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L94-L101

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L86-L95

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L112-L120

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L114-L122

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L4-L11

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L90-L98

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L94-L101

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L62-L70

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L126-L134

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L76-L84

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L50-L59

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L74-L81

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L88-L97

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L111-L119

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L124-L129

AttackMenu.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/AttackMenu.tsx#L99-L104

Formal Foundations for the Mesh Digital Agora .txt
file://file-Qhxf3D7SUWWfwWnUk6TXZX

MeshAgoraPlanning.txt
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/MeshAgoraPlanning.txt#L6-L13

validate.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/dialogue/validate.ts#L54-L63

validate.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/dialogue/validate.ts#L60-L68

SchemeComposer.tsx
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/components/arguments/SchemeComposer.tsx#L130-L138

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L16-L24

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L20-L28

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L27-L35

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L36-L43

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L45-L53

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L30-L38

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L38-L41

export.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/export.ts#L40-L43

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L23-L31

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L37-L45

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L40-L48

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L63-L71

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L64-L71

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L72-L80

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L80-L88

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L54-L62

import.ts
https://github.com/rohan-k-mathur/mesh/blob/1c70052c135919829ba1623f709fb8323de4a18f/lib/aif/import.ts#L92-L95

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS

MeshAgoraPlanning.txt
file://file-A6q3JCQCgtsbYcYvJJ8Ffw

MeshAgoraPlanning.txt
file://file-A6q3JCQCgtsbYcYvJJ8Ffw

MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS
All Sources

MeshRese...Notes.txt

github

MeshAgor...nning.txt

Formal F...gora .txt
