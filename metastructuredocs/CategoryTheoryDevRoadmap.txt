Treat each deliberation as a small evidential closed category (objects = claims, morphisms = sets of arguments), expose join (âˆ¨) and composition at the API, let roomâ€‘level â€œconfidence measuresâ€ choose how strengths combine (min / product / DS), and let Plexus be the â€œcategory of roomsâ€ with typed metaâ€‘edges. Amblerâ€™s axioms justify your UI affordances (undercuts on an inference, GROUNDS joins, default rules), and your labeling/selection widgets become derived views over these operations.

Amblerâ€™s â€œevidential closed categoryâ€ gives you a clean, formal substrate for everything youâ€™re buildingâ€”from a single Toulmin box up through Plexus. Below I turn your synthesis into concrete architecture and code hooks you can drop into the stack today, plus a minimal semantics API that makes the categorical ideas operational.


1) The â€œroom as categoryâ€ contract
Objects: Claim (or canonicalized propositions).Morphisms: sets of arguments from Aâ†’B. In your DB thatâ€™s the set of Argument instances and/or ClaimEdge + the supporting ArgumentEdge chains that establish A â‡’ B.
	â€¢	Join (âˆ¨): aggregation of lines of support. In practice: union of argument IDs (no duplicates).
	â€¢	Zero morphism (0): empty set (no known arguments Aâ†’B yet).
	â€¢	Monoidal product (âŠ—): â€œuse A and B togetherâ€ â€” you already model this as premises inside ArgumentDiagram.inferences.
	â€¢	Internal hom [A,B]: the warrant â€œA â‡’ Bâ€ as a firstâ€‘class target. Your targetScope: 'inference' + attackType: 'UNDERCUTS' is the UI/API face of attacking a morphism of type [A,B].
	â€¢	Comonoid (Î”, t): duplication/weakening (reuse or ignore a premise) â€” justify the composerâ€™s ability to reuse a cited premise across multiple links and to drop irrelevant premises without â€œlogical errorâ€ flags.
Amblerâ€™s move is exactly your current practice: each homâ€‘set ğ’œ(A,B) is a joinâ€‘semilattice (SLatâ€‘enriched); composition distributes over joins; and â€œconfidence measuresâ€ map morphisms to a commutative monoid for scoring. This is why your â€œpile up GROUNDS to answer a WHYâ€ interaction is not just UXâ€”it is the âˆ¨ operator.

2) Make it real: minimal semantics service
Add a tiny service that materializes homâ€‘sets, join, composition, and scoringâ€”then your existing panels can call it.
API shape

GET /api/deliberations/:id/evidential?mode=min|prod|ds&supportDefense=0|1
â†’ {
  objects: string[],                             // claim ids
  hom: { [pair: "A|B"]: { args: string[] } },    // argument ids for Aâ†’B
  score: { [pair: "A|B"]: number },              // confidence c(f)
  support: { [claimId: string]: number }         // S(Ï†) = sup c(Iâ†’Ï†)
}
Server sketch (TypeScript)

type Mono = 'min'|'prod'|'ds';
function combineChain(xs: number[], mode: Mono) {
  if (!xs.length) return 0;
  if (mode === 'min')  return Math.min(...xs);          // weakest link
  if (mode === 'prod') return xs.reduce((a,b)=>a*b, 1); // independent supports
  // 'ds' placeholder: fold via Dempsterâ€™s rule or map to belief mass first.
  return xs.reduce((a,b)=>a*b, 1);
}

function joinScores(fs: number[], mode: Mono) {
  // different choices are defensible; Ambler shows â€œaccrual inside hom-setsâ€:
  // use bounded sum or noisy-or if you want reinforcement; start simple:
  return Math.max(...fs, 0);
}
Implementation note: Start with min and prod; plug a DS variant next (map each argument to a basic belief assignment over {Ï†, Â¬Ï†, âŠ¤}, then combine with Dempsterâ€™s rule; your UI can surface â€œbelief/plausibilityâ€). Amblerâ€™s Sec. â€œconfidence measuresâ€ gives you the algebraic guardrails.

3) Data model touches (small and additive)
You already added the three Plexus metaâ€‘edge tables. To support categorical ops and belief revision, add two light helpers:

model ArgumentSupport {
  id             String  @id @default(cuid())
  deliberationId String
  fromClaimId    String
  toClaimId      String
  argumentId     String   // concrete argument contributing to Aâ†’B
  weight         Float?   // optional per-argument confidence in [0,1]
  createdAt      DateTime @default(now())
  @@index([deliberationId, fromClaimId, toClaimId])
  @@unique([fromClaimId, toClaimId, argumentId])
}

model AssumptionUse { // for belief revision and â€œculprit setsâ€
  id             String  @id @default(cuid())
  argumentId     String
  assumptionId   String   // claimId used as an open assumption in this argument
  role           String?  // 'default','exception','background'
  createdAt      DateTime @default(now())
  @@index([argumentId])
  @@index([assumptionId])
}
	â€¢	ArgumentSupport materializes the membership of a morphism (homâ€‘set) as rows you can join fast.
	â€¢	AssumptionUse lets you surface the â€œfree variablesâ€/culprit assumptions Ambler talks about for belief revision (which premise deletions discharge a bad conclusion). 

4) Make undercuts firstâ€‘class (internal hom in the UI)
You already have targetScope: 'inference' and attackType:'UNDERCUTS'. Two quick refinements:
	â€¢	Diagram â†’ Morphism binding: store an inferenceId on an undercut edge so an attack points to a specific [A,B] instance.
	â€¢	Composer hinting: when a user picks Challenge warrant, prefill a chip â€œattack [Aâ‡’B]â€ and route to createClaimAttack({ type:'undercut', scope:'inference' }).
This is exactly Amblerâ€™s â€œattack the arrow, not just the nodesâ€â€”it operationalizes [A,B] as a firstâ€‘class thing your UX can poke.

5) Scores = confidence measures (roomâ€‘level ruleset)
Expose a perâ€‘room setting:

// deliberation.rulesetJson
{
  "confidence": { "mode": "min" | "prod" | "ds" },
  "accrual":    { "join": "max" | "noisy-or" | "bounded-sum" }
}
	â€¢	Weakestâ€‘link: skeptically cautious dialogs (policy, safety).
	â€¢	Product: independent evidences reinforce (empirical, many studies).
	â€¢	DS: when evidence has mass on ignorance, show belief/plausibility intervals.
These are exactly the monoids Ambler uses to interpret arrowsâ€™ strength in the enriched setting.

6) Belief revision: â€œculprit setâ€ flow
	â€¢	When a claim Ï† gets labeled OUT (or a moderator flags it), call /evidential to fetch the strongest Aâ†’Ï† arrows; for each argument pick its AssumptionUse set; surface â€œculprit setsâ€ sorted by (a) how many bad consequences they explain, (b) minimal retraction cost.
	â€¢	Provide oneâ€‘click RETRACT assumption â†’ posts a RETRACT move and recomputes labels.
Amblerâ€™s notion that closed Î»â€‘terms are indefeasible proofs (max confidence) while open terms inherit uncertainty gives you the rule: only rows with assumptions are retractable; logical maps stay maxed.


7) Plexus = â€œcategory of roomsâ€ (and how your new edges fit)
Keep what you shipped but name the kinds and add a legend toggle:

type EdgeKind = 'xref'|'overlap'|'stack_ref'|'imports'|'shared_author';
const COLORS: Record<EdgeKind,string> = {
  xref:'#6366f1', overlap:'#ef4444', stack_ref:'#f59e0b', imports:'#14b8a6', shared_author:'#64748b'
};

const [show, setShow] = React.useState<Record<EdgeKind,boolean>>(
  { xref:true, overlap:true, stack_ref:true, imports:true, shared_author:false }
);

{/* legend */}
<div className="flex gap-3 text-[11px]">
  {(['xref','overlap','stack_ref','imports','shared_author'] as EdgeKind[]).map(k=>(
    <label key={k} className="inline-flex items-center gap-1">
      <input type="checkbox" checked={show[k]} onChange={e=>setShow(s=>({ ...s, [k]:e.target.checked }))}/>
      <span className="inline-block w-2 h-2 rounded" style={{background:COLORS[k]}} />
      {k.replace('_',' ')}
    </label>
  ))}
</div>

{/* filter before drawing */}
const edges = data.edges.filter(e => show[e.kind as EdgeKind]);
Interpretation: each room is a small evidential category; a Plexus edge is a typed relationship between rooms (crossâ€‘refs, shared authorship, imports, stackâ€‘based ties). If you later want true functors between rooms (mapping objects/claims across rooms), add an optional roomFunctor table that records how â€œobject IDsâ€ translate; then a click in Plexus can transport an argument pattern from room A to B.

9) UI upgrades that pay off immediately
	â€¢	DebateSheetReader: Show a thin â€œsupport barâ€ under each node = support[claimId]. Click toggles to list the contributing arguments (the members of the homâ€‘set Iâ†’Ï†).
	â€¢	DiagramView: For each inference, surface an Undercut pill; clicking opens a composer that posts a move:{kind:'WHY', targetScope:'inference'} preâ€‘tagged to that inference.
	â€¢	HUD (CommandCard): Add a rule selector that writes the roomâ€™s rulesetJson.confidence.mode and reâ€‘queries /evidential.

10) Why this is safe and extensible
Amblerâ€™s account (i) explains your â€œGROUNDS joinâ€ and default rules as SLatâ€‘enrichment and comonoids, (ii) justifies undercutting an inference via internal hom, and (iii) gives you principled scoring plugâ€‘ins (min/product/DS) instead of adâ€‘hoc weights. It also cleanly separates proofs (closed, max confidence logical maps) from arguments (open, defeasible) so belief revision has a clear target set. All of that is exactly the structure you need to keep Plexus coherent as it grows.

A crisp â€œship itâ€ checklist
	0.	Add /api/deliberations/:id/evidential with join/compose + scoring.
	0.	Materialize ArgumentSupport; backfill from ClaimEdge/ArgumentEdge.
	0.	Add AssumptionUse on argument save; populate via composer when users tag assumptions.
	0.	Thread rulesetJson.confidence.mode through DeepDivePanel â†’ API.
	0.	Wire undercut attacks to a specific inferenceId.
	0.	Upgrade Plexus with legend/toggles (edge kinds you already return).
	0.	In DebateSheetReader, render support bars and the list of contributing arguments (hom(I,Ï†)).
If you want, I can package #1â€“#3 into a single PRâ€‘sized set of routes/types that slot straight into your existing /graph and /dialectic flows.


â€”Arguments as arrows, not (single) proofs.
In Amblerâ€™s semantics, objects are propositions and arrows are sets of proofs (finite sets of Î»â€‘terms). That change lets the homâ€‘sets âŸ¨A,BâŸ© carry an algebra for accruing evidence (join).

SLatâ€‘enrichment (â€œaccrual inside the semanticsâ€).
Each hom(A,B) is a join semilattice with a neutral 0 (empty set) and a commutative, associative âˆ¨ (union) so you can say â€œf âˆ¨ gâ€ is a new argument that contains both lines of reasoning. Composition distributes over joins.

Conjunction and implication stay categorical.
Conjunction is a symmetric monoidal tensor âŠ— (with comonoid structure per object for copy/discard), and implication is the right adjoint [X,â€“] to (â€“)âŠ—X (i.e., an internal hom). This yields an evidential closed category (ECC): the CCC laws you want, but enriched over joins.

Logical maps vs. defeasible arguments.
â€œLogical mapsâ€ are arrows built only from structural/identity morphismsâ€”i.e., closed proofsâ€”so they always have max confidence; ordinary arrows can carry free assumptions (uncertainty). Clear separation of strict vs defeasible support.

Confidence measures live on arrows.

A confidence measure is a morphism from the homâ€‘sets into a commutative monoid with composition â†¦ monoid multiplication, join â†¦ monoid addition (in the abstract sense). It captures â€œweakest linkâ€, independent reinforcement, etc.

Evidence theories plug in.

Ambler shows compatibility with Dempsterâ€‘Shaferâ€”you can treat confidence as â€œprobability of provabilityâ€ over argument sets and combine masses along composition and join.

Key payoff: accrual, combination, and strict/defeasible distinctions are not adâ€‘hoc rulesâ€”theyâ€™re laws the arrows already satisfy. This is exactly the layer you need between DebateSheets and AF/Dung acceptance.



How to embed Ambler in Mesh/Plexus (practical mapping)
Think of three layers:
L0 (Graphical): what you already shipâ€”claims, arguments, edges (supports/rebuts/undercuts), CQs, defaultâ€‘rule template âŸ¨Î±,Â¬Î²âŸ©â‡’Î³.
L1 (ECC runtime): a lightweight arrow algebra you run in memory (and optionally persist).
L2 (Measures): pluggable confidence maps used by DebateSheets, AF acceptance, and Plexus weighting.
B1. Arrow representation (software primitive)
Treat each argument node as an arrow
A
â†’
B
Aâ†’B
Aâ†’B whose value is a finite set of derivations (your â€œlines of reasoningâ€).

B2. What is a â€œderivationâ€ in your stack?
Back it by what you already store:
Define a generic interface over arrows that only depends on the derivations and their assumptions:


Three useful presets (all lawful for ECC):
	â€¢	Weakestâ€‘link (cautious):
	â€¢	derivation = min(weights of assumptions, defaults to 1 if none)
	â€¢	join = max (best line of reasoning)
	â€¢	compose = min
	â€¢	Probabilistic independence (optimistic):
	â€¢	assign each assumption a failureâ€‘prob q=1âˆ’wq=1-wq=1âˆ’w
	â€¢	derivation = Î  w_i (independent success)
	â€¢	join = 1 - Î (1 - x_i) (noisyâ€‘OR across lines)
	â€¢	compose = x * y
	â€¢	Dempsterâ€‘Shaferâ€‘lite:
	â€¢	treat each derivation as a mass on its conclusion; composition multiplies masses, join uses normalized orthogonal sum (pragmatically: m = (x + y - xy)/(1 - K) with a conflict K you estimate from contradicting derivations).
Wire the choice into DebateSheet ruleset (sheet.rulesetJson.confidence = 'weakest'|'product'|'ds') and expose it in your â€œRuleâ€ selector next to Utilitarian/Harmonic/MaxCov.
B4. Where this touches AF/Dung
	â€¢	In /api/deliberations/[id]/graph you already support lenses and (optionally) supportâ€‘asâ€‘defense. Add an optional weighting pass that computes the arrow confidence for every supports edge feeding a claim and converts total incoming support to a prior for the node; then you can:
	â€¢	use a thresholded prior to hide trivially weak arrows,
	â€¢	or weight your preferred/grounded tieâ€‘breaking when multiple admissible labels exist.
	â€¢	Accrual (âˆ¨) across multiple supportsâ†’claim edges is exactly the join over arrows with same codomain. This is what your DebateSheet â€œaccepted share ringâ€ and DiagramView â€œpremise chipsâ€ can now visualize.


D) Belief revision, defaults, and CQs (how it plugs into your flows)
	â€¢	A derivationâ€™s assumption set is your â€œculprit setâ€. If a conclusion is later rejected (label OUT) or a WHY expires without GROUNDS, you can:
	0.	list culprit sets ranked by confidence contribution,
	0.	suggest minimal deletions (assumptions to retract) that kill the unwanted path,
	0.	emit an EnthymemeNudge (â€œ+Warrantâ€ or â€œPresupposition?â€) for the specific assumption.
	â€¢	Your default rule scaffold SUPPOSE Î± Â· UNLESS Â¬Î² Â· THEREFORE Î³ can be encoded as a derivation with an assumption of kind defaultâ€‘exception on Â¬Î². If Â¬Î² gets instantiated (a user fills the exception), all derivations referencing that assumption drop (belief revision by local deletion).
	â€¢	Unresolved CQs are assumption atoms of kind cqâ€‘open; when resolved, you reâ€‘score the derivation (confidence rises) and your acceptance rings update automatically.

