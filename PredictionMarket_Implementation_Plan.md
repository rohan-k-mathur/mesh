Prediction Market Implementation Plan for Mesh
Executive Summary
MVP Design: Start with a simple binary YES/NO prediction market using an automated market maker (e.g. LMSR) for continuous liquidity. Each market poses a question (e.g. “Will X happen by date Y?”) with a probabilistic price between 0 and 1 (0–100%)[1]. This foundation is easy to implement and can be extended later to match Kalshi/Manifold-level sophistication.
Virtual Currency (Credits): Use Mesh’s in-app Credits as the trading currency[2]. Trades will debit/credit user balances, treating 1 credit like \$0.01 of play money. No special constraints on the credit economy are needed initially; just ensure wallet balances update atomically with trades.
Data Model Extensions: Extend the existing Post model to include a PredictionMarket subtype and add a Trade log. The PredictionMarket table stores market specifics (question text, YES/NO outcome pools, state=OPEN/CLOSED/RESOLVED, etc.), and each Trade record logs a user’s transaction (side YES/NO, shares bought, price paid, cost in credits)[3][4]. These schema migrations have already been applied in the codebase ✅[5].
Current Progress: Some groundwork is in place. The database tables for markets and trades exist, core LMSR math utilities are written (for price and cost calculations), and the UI supports creating a prediction post type[5]. Key remaining tasks include writing the trading and resolution logic on the backend, wiring up API routes, and building the trading interface on the frontend.
Trading Logic: Implement a robust placeTrade service function to handle buys/sells. It should lock the user’s wallet row (to prevent race conditions), verify sufficient balance, compute the cost & shares via the LMSR formula, then atomically debit the user’s credits, update market pools, and create a Trade record[6][7]. This ensures no double-spending and maintains ledger integrity. The LMSR cost function will dynamically adjust prices to be arbitrage-free, as each purchase increases the cost for subsequent shares[8].
Resolution Mechanism: Support resolution via moderators (or designated oracles). Only the market creator, an assigned oracle, or an admin can resolve a market when it’s closed. Implement a resolveMarket function that locks the market, records the chosen outcome (YES or NO), and pays out winners by crediting their wallets (e.g. YES-share holders get 1 credit per share if outcome=YES)[9]. All resolution actions should be logged in a new ResolutionLog table for audit and transparency[10]. Oracle self-dealing is prevented by blocking the oracle from trading after market close[11].
API & Auth: Expose REST or tRPC endpoints for market actions. Key routes include creating a market (POST /api/market), placing a trade (POST /api/market/{id}/trade), resolving a market (POST /api/market/{id}/resolve), and fetching market data (GET /api/market/{id})[12]. Enforce proper authentication and authorization on these routes: only logged-in users can trade, and only authorized resolvers can call the resolve endpoint[13]. Use server-side validation to ignore any client-supplied probability and always recompute prices server-side for security[14].
Frontend Integration: Build out the UI components for a seamless user experience. This includes a creation form (CreatePredictionPost) where users input the question, close date, and (optionally) a liquidity parameter[15]; a feed card (PredictionMarketCard) showing the question, current probability bar, a “Trade” button (disabled if market closed), and outcome if resolved[16]; a trade modal (TradePredictionModal) with a slider for how many credits to spend, showing estimated shares & price impact, and confirming the trade via the API[17]; and a resolution panel for moderators to select the winning outcome when the market closes (e.g. a dialog with YES/NO options and a resolve button). The feed card’s probability bar should live-update (e.g. via polling or websockets) so all users see new odds within seconds of a trade[18].
Theoretical Soundness & Security: The chosen LMSR market maker ensures prices adjust with each trade, preventing infinite profit arbitrage (the cost to buy shares rises as you buy more, following the log-sum-exp cost function)[8]. To maintain fairness, implement checks and safeguards: e.g., no trading after resolution trigger (creator/oracle cannot secretly trade right before resolving)[11], minimum liquidity parameter b to avoid extreme price swings from tiny trades[19], and atomic transactions so no partial updates occur. Also add rate limiting (e.g. max 10 trades per minute per user) to mitigate spam or bot exploitation[20]. All calculations (shares, costs, payouts) happen server-side to prevent client manipulation[14].
Testing & Rollout: Rigorously test each layer. Write unit tests for LMSR math (price and cost calculations) to ensure no edge-case bugs[21]. Add integration tests for the API (creating markets, executing trades, insufficient balance errors, resolving outcomes) and concurrency tests to ensure the wallet locking works (e.g. simulate many simultaneous trades on the same market with no double-spend or negative pool)[22]. Use E2E tests (Playwright/Cypress) to simulate user flows: creating a market, trading from multiple accounts, auto-closing, and resolving[23]. Once ready, deploy behind a feature flag – enable internally first, seed some demo markets on staging, then gradually roll out to beta users while monitoring performance (latency under 300ms for trades) and any anomalies in credit balances[24].
Detailed Implementation Plan
Below is a phase-by-phase roadmap, aligned with logical development milestones. This plan incorporates the current state of the Mesh codebase and outlines the steps needed to reach a production-ready prediction market feature.

Phase 0: Foundations & Prerequisites
Before coding new features, ensure the foundation is ready:
1. Database Schema in Place: Confirm that the PredictionMarket and Trade models (tables) have been added via migrations and are applied to the database[5]. According to the docs, this migration is already done ✅. Verify also the base wallet table exists (with fields for user balance) since we’ll be debiting credits[25].
2. Feature Flags and Config: Set up a feature flag (e.g. predictionMarkets) to gate the new feature for rollout[26]. Also ensure environment variables or config for any scheduled jobs (e.g. MARKET_CRON_SECRET for cron auth, NEXT_PUBLIC_MARKETS_WS if using websockets) are prepared[26].
3. Review Existing Code: Examine any partial implementations. The LMSR math functions (lib/prediction/lmsr.ts) should already be present and tested (these compute current price and cost to buy shares)[27][28]. Similarly, if a basic post creation form or card component exists (as indicated by the presence of PredictionMarketCard.tsx and a modal), get familiar with their current state so you can integrate new functionality smoothly.

Phase 1: Database & Wallet Hardening
Goal: Ensure the database layer can safely handle concurrent trades and resolutions without consistency issues.
1. Add Wallet Locking: Implement a row-level locking mechanism on the wallet. For example, add a small migration to create a PostgreSQL function lock_wallet(user_id) that selects the wallet row FOR UPDATE[29]. This will be called at the start of any transaction that modifies a wallet balance, to prevent race conditions (two trades at the same time).
2. Optimize Indexes: Add a composite index on the Trade table for (marketId, userId)[30]. This will speed up any queries that fetch a user’s trades in a given market (useful for computing a user’s position or P&L, and for preventing duplicate resolutions or checking if a user already traded, etc.).
3. Resolution Audit Log: Create a new table (e.g. ResolutionLog) to record when a market is resolved[31]. Fields should include the market ID, who resolved it (moderator’s userId), the outcome, timestamp, and perhaps a transaction hash or reference if using an external oracle. This provides an audit trail and can help with debugging or future analytics (like how many markets resolved YES vs NO, average payout, etc.).

Outcome: By the end of Phase 1, the database will have all necessary tables and safety mechanisms. We’ll be confident that our transactions (trades and resolutions) can lock the appropriate rows and maintain consistency.

Phase 2: Core Service Logic (Trading & Resolution)
Goal: Implement the backend logic for executing trades and resolving markets in a theoretically sound way.

LMSR Cost Calculation: Ensure the LMSR formulas are correctly implemented. LMSR (Logarithmic Market Scoring Rule) uses two state variables q_yes and q_no (the yesPool and noPool in our schema) to track the amount of YES and NO shares in existence. The instantaneous price of YES is exp(q_yes/b) / [exp(q_yes/b) + exp(q_no/b)][8]. Buying Δ shares of YES increases q_yes and the cost is the difference in the LMSR cost function C(q_yes,q_no) before and after the trade[8]. This mechanism guarantees liquidity and prevents arbitrage opportunities because the price moves against the trader as they buy more shares. (If needed in future, we can consider other market makers like constant-product or an order book, but LMSR is a solid starting point for a play-money market.)
Implement placeTrade: In the service layer (lib/prediction/service.ts or equivalent), write the placeTrade function to execute a trade atomically[6][7]. It should:
a. Lock the user’s wallet row (SELECT lock_wallet(userId)) to prevent concurrent balance changes[32].
b. Fetch the user’s wallet balance and the market’s current state (pools and status).
c. Validate that the market is still open for trading; if state !== OPEN throw a “Market closed” error[33]. Also ensure the user has enough balance for the intended spend; otherwise throw insufficient funds error.
d. Calculate shares & cost: Use the LMSR helper to determine how many shares the user gets for spending X credits on the chosen side. This might involve a binary search or iterative approach to find Δq such that cost ≈ X credits[34][35]. (The provided code snippet uses a binary search over shares to match the spend[36].) This yields the number of shares and the actual cost (ceil to nearest credit).
e. Persist atomically: Still inside the DB transaction, create a new Trade row (with userId, marketId, side, shares, cost, and price = cost/shares)[37]. Then decrement the user’s wallet balance by cost credits[38], and update the PredictionMarket pools: increment yesPool or noPool by the number of shares bought on that side[37]. Because all three writes (Trade, Wallet, Market) happen in one transaction, any failure will roll back fully, preventing partial updates.
f. Return the result (shares purchased and new probability or pool state) to the caller. This function encapsulates all the critical business logic for trading.
Implement resolveMarket: Similarly, create a service function resolveMarket(marketId, outcome, resolverId) to finalize a market outcome[9]. It should:
a. Lock the market (to avoid race conditions with any late trades). If using the wallet lock approach, you might lock all participants’ wallets or simply ensure no open trades remain by setting the market state to CLOSED before resolution.
b. Verify the caller has permission (must match the market’s creator, designated oracle, or be an admin).
c. Update the PredictionMarket record: set its state to RESOLVED, set the outcome field (YES or NO), and mark a resolvesAt timestamp.
d. Compute payouts: find all Trades for this market (or at least all users’ net positions). For a simple LMSR, one approach is to credit each user who holds winning shares with 1 credit per share of the winning side they hold. Since we didn’t explicitly store “holdings”, we can derive it: sum of user’s YES shares minus sum of their NO shares (though in binary LMSR, users don’t hold a persistent number of shares like in order books—they effectively buy into a position and the LMSR bank handles payouts). Another approach: on resolution, simply pay out the difference between 100% and the price they paid for each share. Simpler: If outcome = YES, every YES share can be redeemed for 1 credit; if NO, every NO share for 1 credit. Credit users accordingly and maybe deduct any “unused” probability. (Ensure total credits paid out equals total paid in, to conserve the play-money economy.)
e. Create a ResolutionLog entry recording who resolved the market and the outcome[31].
f. Mark any related state, and possibly emit events (e.g., via WebSocket or pusher) to notify front-end that the market resolved.
g. All of the above should occur in a transaction so that payouts and market state change atomically.
Auto-Close Markets: Implement a cron job or scheduled task to automatically transition markets from OPEN to CLOSED when their deadline (closesAt) passes[39]. For example, a small script (scripts/closeMarkets.ts) can run every 5 minutes (via a GitHub Action or server cron) to find all markets where state = 'OPEN' AND closesAt <= now() and set those to state = 'CLOSED'[40]. This prevents trades after the official closing time, enforcing the market lifecycle. Use an environment-protected secret (MARKET_CRON_SECRET) if exposing this via an API route, so only the cron job can call it[41].
Wallet Ledger (Optional): For theoretical soundness and future extensibility, consider maintaining a wallet ledger of all credit movements. Instead of just a balance field, log credit debits and credits in a ledger table whenever trades or resolutions happen. This provides a clear audit trail that the sum of all credits remains constant (conservation of money) and helps in tracking each user’s P&L (profit and loss). This isn’t strictly needed for functionality, but is a good practice when building financial features (even with virtual currency).
By the end of Phase 2, the backend should handle trades and resolution correctly and securely. We’d have confidence in the market mechanism’s correctness (no arbitrage, fair payouts) and the integrity of transactions.

Phase 3: API and Endpoint Integration
Goal: Expose the prediction market functionality through well-defined API or tRPC endpoints, and secure them properly.

Create Market Endpoint: If not already implemented, add an API route (Next.js API route or tRPC mutation) for creating a new market[12]. This should accept the question, closing date/time, and perhaps the initial liquidity parameter b. On creation, insert a new Post with type=PREDICTION and a corresponding PredictionMarket entry. The user invoking it becomes the market’s creator (store their userId as creatorId in the market record). Return the new post ID or market ID. This allows the frontend to redirect to or display the newly created market post.
Trade Endpoint: Implement the POST /api/market/[id]/trade route[12] (or tRPC mutation). This endpoint simply needs to call the service placeTrade function with the current user’s ID, the market ID (from URL), the side (YES/NO), and the number of credits the user wants to spend (from request body)[13]. It should respond with the result of the trade, e.g. how many shares were purchased and perhaps the new probability or pools, so the client can update UI. Use your framework’s auth middleware to ensure only logged-in users can trade. Also, implement basic rate limiting here: e.g., if a user tries to spam the endpoint, return 429 Too Many Requests (using an in-memory or Redis counter)[20].
Resolve Endpoint: Implement POST /api/market/[id]/resolve[12]. This should check that the current user is authorized (match creatorId or oracleId or has admin role). Also ensure the market is CLOSED (trading period over) but not yet RESOLVED to prevent double resolution (use a 409 Conflict if already resolved). Then call the resolveMarket service function. Consider using an idempotency key mechanism for this endpoint[20]: resolution should ideally only happen once, and if the request times out or is retried, the additional calls should be no-ops. An Idempotency-Key header that stores a short-lived token in Redis can help avoid accidentally resolving twice if a moderator double-clicks.
Get Market Endpoint: Implement GET /api/market/[id] to fetch market details[12]. This should return the PredictionMarket data along with recent trades or aggregate info (e.g., total YES shares, total NO shares, current price). This is used for both the feed (to show current odds) and the market detail page. It can be public (no auth needed to read market info). Implement caching (e.g., 60s SWR cache headers) to reduce load[13].
Tie into Post Feed: Ensure that when a PredictionMarket post is created, it appears in the home feed or relevant section of the app. Likely, the backend already treats posts generically. You might need to extend the post-fetch query to join the PredictionMarket table to get the needed fields (question text, current price, state) when rendering a PREDICTION post in the feed. This is likely handled by a PostWithMarket type or similar[42]. Confirm that integration so the feed card has the data it needs (perhaps a custom serializer or an include in Prisma query).
Security Note: Double-check all inputs on these endpoints. Use server-side calculations for anything critical (share counts, costs) and do not trust any client-submitted values for price or shares. The client should only send intent (e.g. “spend 50 credits on YES”), and the server computes the outcome. This prevents tampering[14]. Also ensure that users can’t craft requests to trade in markets that are closed or resolve markets they don’t own – cover these in your tests too.

By the end of Phase 3, the system’s core backend (service + API) is complete. We can programmatically create markets, trade, resolve, and retrieve market info. The next step is to build a great user interface around these capabilities.

Phase 4: Frontend User Interface
Goal: Develop the UI components and client-side logic so users can interact with prediction markets easily and in real-time.

Market Creation Form: Implement the prediction market post creation UI, if not done yet. This likely lives in the post composer flow (perhaps a separate component like CreatePredictionPost.tsx as per the guide)[15]. It should collect: the market question (string up to 140 chars), the closing date/time (with a datetime picker), and possibly a “liquidity” slider or input for the initial b value (or use a sensible default, e.g. b = 100 or 1000, to start). On submit, call the create market API endpoint and then redirect the user to the newly created post (or show it in their feed). Basic validation: question not empty, closing time in the future, etc.
Prediction Market Card: Ensure the feed can render a prediction market post. The PredictionMarketCard.tsx should display the question, a visual probability bar, and a “Trade” button[43][44]. Use the current yesPool and noPool (plus formula) or a precalculated field to determine the current YES probability (e.g. price = post.prediction.currentPrice might be provided by backend)[42]. The probability bar can be a simple filled percentage bar. If the market is resolved, show the final outcome (YES or NO) clearly[45]. If the market is still open, the Trade button opens the trading modal. If closed (awaiting resolution), the button can be disabled or say “Closed”.
Trade Modal: Build the TradePredictionModal.tsx component to handle user trades[17]. Key elements:
A slider input (for example using @radix-ui/react-slider) to choose how many credits to spend[46]. This slider might go from 0 up to the user’s available credits or some cap. It should snap in increments (e.g. 10 credits) for ease.
Display the estimated shares the user would buy for the selected spend. To get this, you can either call a preview endpoint or replicate the LMSR calculation on the client. A quick approach: the server’s GET market endpoint could return current pools and b, and you can compute a preview in the modal as the user adjusts the slider. Alternatively, expose a lightweight endpoint or reuse the cost function in JS.
Show the potential price impact: e.g. if current probability is 60% and the user is buying 100 credits of YES, maybe the new probability will move to 65%. It’s nice to show “Your trade will move the market to ~65% YES”. Calculate this by simulating the trade (add Δq shares and compute new P_yes).
Show the user’s wallet balance change: e.g. “Cost: 100 credits, your new balance: X credits”.
On confirmation (user hits a “Buy” or “Sell” button), call the trade API endpoint. If it succeeds, update the UI: close the modal, and update the market card’s displayed probability optimistically. You can do an optimistic update by adjusting the local state of price in the card, or invalidate the SWR/tRPC cache for the market[47]. If the API returns the new probability or new pools, use that.
Handle errors: if the trade fails (e.g. not enough credits or market just closed), show a toast or inline error message (the API should return a descriptive error).
Live Updates: Implement live updating of market odds on the frontend. Two strategies:
Polling: Use SWR or React Query to re-fetch the market data every few seconds (e.g. 5s)[18]. This is simple and ensures that even if multiple users are trading, everyone’s client refreshes periodically to see the latest price.
Realtime push: Optionally, integrate with a WebSocket or Pusher channel. The backend can emit an event whenever a trade executes or a market resolves, and clients subscribed to that market’s channel can instantly update the data. This is more complex, so as an MVP, polling is fine, but keep the architecture open for adding websockets later (perhaps using Supabase Realtime or Pusher as indicated by the env var NEXT_PUBLIC_MARKETS_WS).
Resolution UI: If the current user is the market creator, designated oracle, or an admin, and the market is in CLOSED state (trading finished but not resolved), show a Resolve button on the market page or card[48]. When clicked, it should open a confirmation dialog allowing the resolver to pick the outcome (YES or NO). This likely is a simple form: two radio buttons or a dropdown, and a confirm. On submission, call the resolve API. After a successful resolve, you can update the UI to show the chosen outcome (and possibly the final payout info, if relevant). Also consider a safety prompt like “Are you sure? This will pay out all shares and cannot be undone.”
Market Details & History (Stretch): Eventually, you might want a dedicated market detail page (e.g. navigating to the post’s page with a tab like ?view=market). There you could display more info: a depth chart or probability chart over time, a list of recent trades, maybe comments or discussion on the market[49]. For MVP, this can be minimal, but plan the route for it (maybe reuse the existing post page with conditional rendering for prediction type). Logging trades with timestamp means you could show a trade history table under the post as well.
By the end of Phase 4, users can create markets, see them in the feed, trade on them with a user-friendly interface, and resolve them through the UI. The feature should be functionally complete from a user perspective.

Phase 5: Additional Features and Enhancements
Goal: Add the supporting features that improve the experience and robustness, making the market “production-ready” and on par with established platforms.

Notifications: Integrate a notification system for key events. For example, when a market is resolved, all users who traded could get a push or in-app notification: “Market X has resolved to YES. You earned 𝅃120 credits.”[50]. Implement this by creating Notification entries in the database within the resolveMarket transaction, or by sending events to a real-time channel. Supabase Realtime or another pub-sub can push a notification to users’ devices[50]. Also notify users of their own trade execution (“Your trade on Market X executed at 60%”). These niceties make the system feel more responsive and engaging.
Analytics & Leaderboards: Emit events or logs for analytics. For instance, log a market_traded event (with details like marketId, userId, amount) and a market_resolved event[51]. If using a tool like Segment + ClickHouse, pipe these events for analysis. This helps to track usage (e.g. number of trades, open interest) and user performance. You can even create a materialized view for user profit & loss over time[52]. Later, build a simple leaderboard or profile stat showing top predictors by profit, etc., to gamify the experience.
Theoretical Upgrades: Plan for more advanced market types once the MVP is stable. This might include multi-outcome markets (instead of just YES/NO, have multiple options, requiring a different market maker like LMSR with more outcome buckets, or a different mechanism) – for example, markets on a numeric range or multiple-choice questions[27]. Another future enhancement could be liquidity provider incentives or letting users fund markets (as on Manifold, users can contribute liquidity or act as the house). For now, these are stretch goals, but the architecture (especially using LMSR with a configurable b) is designed to accommodate more outcomes and more liquidity[53].
Alternate Mechanisms: If needed later, consider other prediction market mechanisms: for instance, an order-book based market like Kalshi (which would require matching buyers and sellers, and possibly market maker bots to provide liquidity), or a Constant Product Market Maker (CPMM) like Uniswap’s formula (used by some prediction sites for simplicity). Each mechanism has trade-offs: LMSR charges a “liquidity fee” on every trade (market maker subsidy), CPMM can be simpler but can run out of liquidity at extremes, and order-books are complex but allow limit orders. The roadmap can include swapping in or adding these mechanisms if the product requirements evolve. Starting with LMSR is fine, as it’s theoretically sound (proper cost function) and widely used in play-money markets (Manifold uses a variant of CPMM, but LMSR is equally sound for binary markets).
Scaling & Performance: As the feature grows, keep an eye on performance. The cost calculation is cheap, but ensure the database writes (Trade inserts, wallet updates) are efficient. The composite index added earlier helps if you need to query trades. For high load, consider moving heavy computation off the main thread (but in our case, LMSR formula is quick). If using websockets, ensure the server can handle the subscription load.
Compliance (Real Money): Although Mesh uses virtual credits now, if there’s ever an intent to move toward real money (like Kalshi’s regulated markets), plan a phase for compliance. This would include KYC (know-your-customer) processes, legally approved market topics, limits on positions, etc. That’s beyond the current scope, but the roadmap in the docs even mentions a “real-money pilot” as a stretch goal[54]. The key is that the architecture (with a clear separation of market logic, wallet ledger, and resolution audit trails) puts you in a good position if regulation ever comes into play.
Phase 6: Testing and Quality Assurance
Goal: Rigorously test the system to ensure correctness, security, and reliability before releasing to all users.

Unit Testing: Test the LMSR math functions thoroughly. Given known inputs and outputs, ensure that priceYes(qYes,qNo,b) returns expected probabilities, and that buying shares produces the correct cost and updated pools. Include edge cases: e.g., starting with empty pools gives 50/50 price, large b vs small b effects, etc. Also test helper functions like any rounding of cost (ensure no fractional credits issues).[21]
Integration Testing: Use Supertest or your API testing tool to simulate the API calls[22]. Test the full flow: creating a market, trading on it, attempting invalid trades (e.g. overspend, or trading after close), and resolving. Check that after resolution, the sum of credits in all user wallets is the same as before (conservation of credits) within a tiny float error[55]. Also test permission controls (e.g., user A cannot resolve a market they don’t own).
Concurrent Trades: Write a test or script (could use k6, JMeter, or a custom loop) to simulate many trades hitting the same market at once[22]. This ensures your wallet locking and transaction logic truly prevent double spending or race bugs. For example, 100 concurrent requests to buy shares in the same market – all should succeed or some fail gracefully if the wallet didn’t have enough, but none should corrupt the pools (no negative pool values, etc.). Monitor that the final pool sizes and prices are correct as if the trades happened sequentially in some order. This tests the ACID compliance of your transactions under load.
End-to-End Testing: Use a browser automation tool (Cypress or Playwright) to simulate a user’s experience[23]. For example: User Alice creates a market, user Bob visits the site and trades on that market, the market auto-closes after the deadline (you might speed up time for test or trigger the cron manually), then an admin user resolves it. Verify that at each step the UI updates appropriately (Alice sees Bob’s trade reflected in the probability bar, Bob sees the outcome after resolution, both get notifications, etc.). Test on multiple browsers and devices for UI responsiveness.
Load Testing: If you expect heavy usage, test how the system behaves with, say, 1000 markets and hundreds of trades. Monitor query performance (the index on trades should help for lookups). Also measure the trade API latency – aim for <300ms at 95th percentile under moderate concurrency[55]. If any part is slow (e.g., maybe the initial page load if it pulls a lot of data), optimize accordingly (lazy load trade history, etc.).
Make sure to run the full test suite in CI/CD (set up a GitHub Action if not existing)[56] so that future changes don’t break the prediction market features.

Phase 7: Security and Fairness Checks
Goal: Harden the feature against abuse or exploits, ensuring trust from users.

Rate Limiting: As mentioned, enforce a rate limit on trading actions[20]. You can use an in-memory store for simplicity or a distributed rate limiter (like Upstash Redis with a fixed window or token bucket algorithm). For example, 10 trades per minute per user is reasonable. This prevents bots from spamming the system or creating undue load. Also consider rate-limiting market creation if needed (to prevent someone from creating thousands of markets).
Oracle/Resolver Restrictions: Build in checks to prevent conflicts of interest. The docs suggest preventing the oracle (if one is assigned) from trading after the market closes[11]. In practice, once a market is closed (closesAt passed), you might simply reject any trade API calls. Additionally, you could flag or prevent the resolver from trading even just before resolution (e.g., the creator shouldn’t be able to sneak in a last-minute trade after seeing outcome information). A simple rule: once the resolve button is clicked (or outcome determined), trading is locked. Since we auto-close at the deadline, this is mostly covered. Enforce that state transitions (open→closed→resolved) happen in order and only allowed roles can trigger them.
Integrity of Payments: Double-check the logic for payouts so that no credits are created or destroyed improperly. A good practice is to verify that total credits in the system remain constant (within rounding error) from market creation to resolution[55]. LMSR is a closed system (the market maker’s bank absorbs the difference), so if implemented right, the sum of all user balances plus any “in-market” value should be invariant. The ResolutionLog and wallet ledger can be used to audit this.
Input Validation: Ensure all inputs (question text, etc.) are sanitized to prevent XSS or SQL injection (though using Prisma/ORM and parameterized queries should cover SQL safety). For example, limit question length to 140 chars as specified[1], and ensure it’s plain text or basic markdown to avoid any script injection in the UI. This is more of a general web security step, but important for a user-generated content feature.
Feature Flag & Kill Switch: Keep the feature behind a LaunchDarkly (or config-based) feature flag initially[26]. This allows gradually enabling it for a subset of users and turning it off quickly if something goes wrong (e.g., an exploit or severe bug). Even after full launch, having a kill switch for the trading functionality can be a safety measure.
Phase 8: Deployment and Rollout Plan
Goal: Deliver the feature to users in a controlled, monitored way, ensuring a smooth launch.

Staging Verification: Deploy the new code to a staging environment. Run the migrations to create any new DB structures (wallet lock function, index, ResolutionLog). Then manually test key flows on staging with a few users. It’s a good idea to create two or three demo markets on staging and perform trades to see everything working end-to-end[57]. Check that notifications fire, UI updates, etc., in the wild.
Internal Release: Enable the feature flag for internal team members or a small group of alpha testers first[58]. This lets real users try it with minimal blast radius. Have them create markets and trade, and gather feedback on usability or any issues. Monitor the server logs and error tracking for any exceptions (e.g., race conditions or unhandled errors).
Gradual Rollout: Assuming all looks good, ramp up exposure. For example, turn the feature on for 5-10% of users (randomly selected)[58]. Observe metrics for a day or two. Metrics to watch: API error rates, average trade latency, database load (the auto-close job and trade volume), and user engagement with the feature (are markets being created? traded?). If stable, increase to 50%, then 100%.
Performance Monitoring: Use monitoring dashboards to ensure the feature doesn’t degrade site performance. The goal is <300ms latency for trade operations at the 95th percentile and no significant impact on the database[55]. Also ensure the cron job closes markets within, say, 5-10 minutes of their closing time[55] (should be easy with a 5-min schedule). If any metric is off (e.g., spike in errors or slow queries), pause rollout and address the issue.
Post-Launch Audit: After full release, do a retrospective check on a few resolved markets. Ensure that all credits reconcile (no discrepancies in the wallet balances vs what trades and outcomes occurred). Also gather user feedback – do they find the markets useful, is the trading experience smooth? This can guide future improvements like UI polish or new features (like limit orders, etc.).
Following these phases and steps will lead to a robust, theoretically sound prediction market feature in Mesh. Each phase builds on the last[59], mitigating risks through locking, auditing, and testing, and ensuring the end result is on par with the reliability of platforms like Kalshi or Manifold (albeit with play money for now).

Milestone Overview: For clarity, here’s a milestone breakdown aligned with development sprints (each roughly one day of work)[60]:

Milestone 1: Database migrations & wallet locking in place; basic models verified.
Milestone 2: Core backend complete – trading and resolution services implemented with tests.
Milestone 3: API endpoints and cron jobs operational; system supports all core actions.
Milestone 4: Frontend components (create form, trade modal, live updates, resolution UI) done and integrated.
Milestone 5: Notifications, analytics, security/rate-limits added; thorough testing and QA passed. Feature flag turned on for release.
By achieving these, Mesh will have a production-ready prediction market functionality that is feature-rich, secure, and engaging for users, while laying the groundwork for future enhancements like multi-outcome markets or real-money integration. Good luck, and happy shipping![61]

 
[1] [2] [3] [4] [8] [11] [12] [15] [16] [17] [19] [21] [27] [28] [34] [35] [36] [37] [38] [42] [43] [44] [45] [49] [53] [54] PredictionMarket_Post_Type_Guide.md

https://github.com/rohan-k-mathur/mesh/blob/bb82e80dbdff397561ff2e869058beb7675a4903/PredictionMarket_Post_Type_Guide.md
[5] [6] [7] [9] [10] [18] [20] [22] [23] [25] [26] [29] [30] [31] [32] [33] [39] [40] [41] [46] [47] [48] [50] [51] [52] [56] [58] [59] [60] [61] PredictionMarket_Next_Steps.md

https://github.com/rohan-k-mathur/mesh/blob/bb82e80dbdff397561ff2e869058beb7675a4903/PredictionMarket_Next_Steps.md
[13] [14] [24] [55] [57] PredictionMarket_Development_Playbook.md

https://github.com/rohan-k-mathur/mesh/blob/bb82e80dbdff397561ff2e869058beb7675a4903/PredictionMarket_Development_Playbook.md
