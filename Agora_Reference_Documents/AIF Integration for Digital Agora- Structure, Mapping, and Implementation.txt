AIF Integration for Digital Agora: Structure, Mapping, and Implementation
AIF Conceptual Structure and Node Types
Information Nodes (I-nodes) – Represent atomic propositions or statements in an argument. These are the basic content units: claims, premises, conclusions, etc., that carry truth-value[1]. In Digital Agora terms, an individual Claim (or any explicit statement a user makes) would correspond to an I-node in the AIF ontology[2]. Each I-node holds the propositional text (e.g. “Carbon pricing will reduce emissions”) and can appear in multiple roles (as a premise in one argument, a conclusion in another) without duplication – supporting the reusability of claims across the debate graph.
Scheme Nodes (S-nodes) – Represent applications of reasoning or dialogue rules, capturing the relationships between I-nodes[3]. S-nodes are subdivided into Rule of Inference applications (RA-nodes) for support/inference, Conflict applications (CA-nodes) for attacks, and Preference applications (PA-nodes) for preference-based comparisons[3]. An RA-node corresponds to a step of reasoning that draws a conclusion from one or more premises (for example, an instance of the Argument from Expert Opinion scheme). A CA-node represents a conflict or attack relation – such as rebutting a claim or undercutting an inference – making the reason for opposition explicit rather than a generic “con” link[4]. This explicit separation prevents ambiguity: instead of a simple attack edge, we know if it’s targeting a conclusion (rebuttal) or the inferential link (undercut) as different CA-node types[5][6]. In Digital Agora’s current model, these map to the distinction between Argument objects (inferences) and Edge attack types. For example, an Argument record that bundles premises and a conclusion is analogous to an RA-node, whereas an ArgumentEdge of type “undercut” would be realized as a CA-node that targets an RA-node (the inference it undermines)[7].
Locution Nodes (L-nodes) – Represent utterances in dialogue (who said what, and when), introduced by the Inference Anchoring Theory extension of AIF[8]. An L-node is essentially a special kind of I-node that carries the event of a speech act – e.g. Alice’s statement at 5:02 PM, “Carbon pricing will reduce emissions.”[9]. The content of a locution node is the proposition asserted (which can be linked to a corresponding I-node), but the L-node itself carries context like speaker and timestamp. In Agora’s terms, a DialogueMove (the record of a user posting a message) functions as a locution: it has an author, a time, and a reference to the content being asserted or asked. The AIF’s locution nodes will be mapped to DialogueMove entries, anchoring the conversational aspect of arguments without conflating it with the propositional content. This separation is crucial for tracking dialogue structure – e.g. distinguishing “Bob’s claim X” from claim X itself[10].
Dialogical Scheme Nodes (TA and YA) – AIF, when extended for dialogues, adds specialized S-nodes for dialogue protocol transitions and illocutionary acts[11][12]. A Transition Application (TA-node) represents the permissible sequence between locutions (e.g. that a “Why?” question can be followed by a “Because…” answer in a debate protocol). TA-nodes connect L-nodes to L-nodes, encoding the reply structure or turn-taking rules of the dialogue[13]. Meanwhile, Illocutionary Application (YA-nodes) link the content layer to the dialog layer by “anchoring” inference moves in the dialogue – capturing the illocutionary force of an utterance[12]. For example, if Alice gives a reason in response to Bob’s challenge, there is an illocutionary act of arguing that connects Alice’s locution (her stating a premise) to the fact that it is intended as support for Bob’s earlier claim[14][12]. In implementation, we can model these with metadata on DialogueMove records: e.g. a move’s type (“CLAIM”, “WHY”, “GROUND”) and a pointer to the move it replies to (as Agora already does via a justifiedByLocus or similar thread reference) implicitly create TA-node links[15][16]. A YA-node (illocutionary act, such as “asserting” or “questioning”) can be recorded as a property of the move’s payload indicating the speech-act performed[17]. In practice, the system doesn’t need to literally create separate YA node records; it can encode that “Move 7 was an Argue act replying to Move 6” – thereby anchoring an RA-node (the argument content) to the dialogue. This preserves the richness of AIF’s dialogical semantics: for instance, we know whether a given support was put forward as an answer to a challenge or volunteered preemptively, etc., which can inform conversation logic (like enforcing that a “Why?” must be addressed by a proper justification)[18][19].
Summary: In an AIF-compliant model, every piece of content and every inferential or dialogical relationship becomes a node in a graph. Content nodes (I-nodes) stand for propositions (claims), while scheme nodes (S-nodes) stand for the relationships (the “glue” – inference or conflict) between those propositions[3]. Locution nodes represent the discourse events connecting arguments into a dialogue[20]. By adopting this structure, Digital Agora can cleanly separate what is being said from why/how it is being said. This conceptual clarity lays the groundwork for modeling advanced argument structures.
Argument Schemes, Critical Questions, and Inference Modeling in AIF
Argumentation Schemes: AIF’s intermediate layer provides a library of abstract argument patterns (forms) such as Walton’s argumentation schemes[21]. Each scheme (often denoted as an F-node in extended AIF ontologies for “Form”) defines a general pattern of inference – for example, Argument from Expert Opinion might have slots like: Expert says Claim; Expert is credible; therefore Claim is true[22]. In AIF, an RA-node in an argument graph can be annotated as an instance of a specific scheme form[23]. In practical terms, this means an RA-node “knows” what kind of reasoning it represents, which in turn tells the system what premises are expected and what typical challenges apply. The AIF design separates the scheme definition (ontology layer) from the individual RA-nodes in the graph (instance layer)[23]. Digital Agora can leverage this by maintaining a catalog of ArgumentScheme definitions (with a key, name, expected premises, conclusion, etc.) and storing a reference on each argument instance to the scheme it instantiates (e.g. an argument.schemeKey or a join through a SchemeInstance)[24][25]. By doing so, the system recognizes, for example, that a particular Argument (RA-node) is an “Argument from Cause to Effect” versus an “Argument from Example.” This is already partially in place: the platform’s CriticalQuestions module infers scheme types from textual cues and assigns a schemeKey[26]. Formalizing that link (perhaps via a dedicated SchemeInstance model tying an argument or claim to an ArgumentScheme entry in the database) will fully align Agora’s data with AIF’s scheme semantics.
Inference Structure: In AIF, an inference (supporting argument) is represented by an RA-node with edges in from one or more I-nodes (the premises) and an edge out to an I-node (the conclusion)[27][28]. This naturally allows linked premises: multiple premises can converge into one RA-node to produce a conclusion, capturing the notion of a single argument with several supporting reasons. In the current Agora implementation, arguments are often authored as “cards” that may contain multiple premises; adopting AIF means representing that internally as a single RA-node linking all those premise Claims to the conclusion Claim. For example, if an Argument card has 3 premises supporting a claim, in AIF we create one RA-node with three input edges (premise I-nodes → RA) and one output edge (RA → conclusion I-node). This is a shift from a simpler graph model where multiple supports might have been separate edges – AIF insists on explicating when premises are meant to work together (linked) versus independently[29]. We may need to adjust the data model to reflect this: e.g. introduce an ArgumentDiagram entity (or reuse the existing one mentioned in Agora plans) to group premises. In practice, the Argument model can serve as the RA-node container: it already has references to a conclusion claim (the claim it supports) and can be linked to premise claims (perhaps via a join table or a ClaimEdge used for premises). To fully align with AIF, we ensure that each Argument corresponds 1:1 with one RA-node, regardless of number of premises – rather than, say, multiple ClaimEdges each acting like its own inference. This way, the distinction between a single argument with two premises and two separate arguments is maintained. The value is a more accurate representation of linked vs. convergent arguments (AIF can distinguish a scenario where two premises are jointly required from one where they independently support the conclusion).
Critical Questions: In Walton’s theory (which AIF embraces), each argumentation scheme comes with a set of Critical Questions (CQs) – standard challenges that test the argument’s weak points[30][31]. AIF does not model critical questions as a separate node type per se; instead, critical questions manifest as potential attacks (CA-nodes) on the argument’s RA-node or premises. In other words, a critical question identifies a condition under which the argument would fail, which corresponds to an undercutter or rebuttal in the graph. For example, a key critical question for Argument from Expert Opinion is “Is the expert biased or not credible?” If the answer is “Yes, they are biased,” that instantiates an undercutting attack on the inference from the expert’s testimony[32][33]. AIF encourages us to treat that scenario explicitly: the attack would be a CA-node taking as input an I-node representing “The expert is biased” and targeting the original RA-node (thereby undercutting the inference). Similarly, a question like “Is there evidence to the contrary?” might lead to a rebuttal CA-node attacking the conclusion I-node. In practice, Digital Agora’s approach of mapping each critical question to a specific attack type aligns with this concept: questions about a premise’s truth map to undermining (attacking a premise node), questions about an inference’s warrant/exception map to undercutting (attacking the RA-node), and questions about alternative conclusions or counter-cases map to rebuttal (attacking the conclusion node)[32]. The system already encodes such mappings in its CriticalQuestion presets (e.g. a CQ “Is there an alternative cause?” is typed as an undercut on the inference for a causal argument)[34][35]. By adopting AIF, we formalize these as structural relations: for any given Scheme that an argument uses, each Critical Question corresponds either to a needed premise (whose absence can be flagged) or to a potential CA-node that could attack the argument. We can extend our data model with a concept of unanswered critical questions as virtual CA-nodes that make an argument tentative until addressed[36]. Concretely, Agora could maintain a CriticalQuestionStatus for each scheme instance on each argument (already indicated by cQStatus tracking in the code) to record if a CQ is “answered” (defeated) or still open[37][38]. An open critical question is essentially a standing attack awaiting a rebuttal. This can even be visualized as a dummy attacker in the UI (e.g. a red question mark node attached to the argument) until the user provides an answer, at which point that node is resolved (or replaced by the user’s counterargument). The AIF mindset thus turns CQs into first-class citizens of the argument graph: not just hints in text, but structurally as nodes/edges that can be manipulated.
Example: Suppose we have an argument that “Policy X will be effective because Dr. Smith (an expert) said so.” This instantiates the Expert Opinion scheme. The AIF graph would include: I-nodes for “Dr. Smith said X” and “X is true,” plus an RA-node labeled as RA(expert opinion) linking them. The scheme’s critical questions include “Is Dr. Smith an expert in this domain?” and “Is Dr. Smith trustworthy (unbiased)?” Initially, these are potential undercutters. If no information is given about Dr. Smith’s expertise or bias, the argument is prima facie valid but defeasible. AIF would allow an implicit assumption node like “Dr. Smith is an expert and unbiased” to be presumed; a critical question is essentially an invitation to challenge that node. In our system, we might not explicitly create an “assumption” node by default (though we could, as an implicit premise). Instead, we track that the argument has outstanding CQs. If another participant asks “Is the source really an expert?” the system will log a CQ challenge (a WHY move tied to that scheme) and prompt the proponent to respond[39][40]. AIF would model the act of asking as an L-node (the question utterance) and perhaps a CA-node placeholder. If the proponent then provides evidence of credentials, that becomes an argument addressing the CQ – effectively adding an RA-node that supports the once-implicit premise “Dr. Smith is a qualified expert,” thereby defeating the undercutter. This interplay shows how AIF handles inference structures with critical questions: by explicitly representing them as nodes and edges in the graph, we can automate consistency checks (an argument isn’t fully justified if a critical question’s corresponding attack is unanswered)[41][26].
Defeasible vs. Strict Inference: Many argument schemes are defeasible – they warrant a conclusion only if no exceptions apply. AIF’s design, especially when combined with critical questions, inherently supports defeasible reasoning. An RA-node can be understood as “if premises, then conclusion, subject to no successful attacks.” In the system, we plan to implement a backend logic that periodically evaluates the argument graph as an Abstract Argumentation Framework (AF) to determine which arguments (RA-nodes) stand undefeated[42]. Each RA-node (argument) can be seen as an “argument” in Dung’s sense, and each CA-node is an attack relation between arguments. For instance, if a CA-node links argument A to argument B, that means A attacks B. Tools like TOAST or Dung-O-Matic can compute extension labels (IN, OUT, UNDEC) for all RA-nodes given the CA-node network[42]. Because AIF makes the support/attack graph explicit and well-typed, we can directly feed it into these solvers. This is a huge advantage over a less structured approach: since we distinguish rebuttals vs undercuts, we can translate them properly (e.g. as different forms of defeat in ASPIC+ or a meta-level handling that undercuts prevent an inference from being used)[43][44]. The outcome – marking which conclusions are tentatively accepted – can then feed back into the UI (e.g. showing a claim as “justified” or “challenged” with colored badges)[5][45]. In summary, AIF’s modeling of inference and attacks, combined with a library of schemes and critical questions, provides semantic rigor: every link in an argument has a known type and conditions for defeat, enabling automated reasoning support and user guidance for constructing stronger arguments.
AIF Serializations and Interoperability
One motivation for adopting AIF is to ensure Agora’s arguments aren’t locked into a proprietary format. The AIF community has developed several serialization formats to facilitate data exchange[46]. The canonical reference implementation is an AIF-RDF/OWL ontology – a set of classes (I-node, RA-node, CA-node, etc.) and relationships (like supports, conflictsWith) defined in RDFS/OWL[47]. By serializing Agora deliberations to RDF/OWL, we can publish argument data in a standard, machine-readable form that any semantic web toolkit or argument analysis tool can ingest. For example, each Claim can be an RDF node of type aif:InformationNode with a text property, each Argument an aif:RA node linked via aif:Premise and aif:Conclusion relations, etc. In practice, we might not expose RDF directly to end users, but having an RDF export means researchers could query debates with SPARQL or merge our data with other argument datasets.
Another increasingly popular format is JSON-LD, which combines JSON ease-of-use with Linked Data semantics. AIF can be expressed in JSON-LD by defining a context that maps our JSON keys to the AIF ontology URIs. For example, we could have a JSON serialization like:
{   "@context": {"aif": "http://www.arg.dundee.ac.uk/aif#"},   "nodes": [     {"@id": "I123", "@type": "aif:InformationNode", "text": "Carbon pricing will reduce emissions."},     {"@id": "S45", "@type": "aif:RA", "scheme": "ExpertOpinion"}   ],   "edges": [     {"from": "I456", "to": "S45"},      {"from": "S45", "to": "I123"}   ] }
This JSON document, especially with @type and @id, is both human-friendly and semantically rich (tools can interpret it using the AIF ontology). AIFdb JSON is another practical format: the Argument Web’s AIFdb uses a JSON structure to transmit argument graphs to web interfaces like OVA. We can mirror that format for compatibility – essentially a list of nodes (with their types and content) and a list of edges, similar to the snippet above or the simplistic mapping code already in our codebase[27][28]. In fact, the team has prototyped an AIF-JSON exporter in lib/export/aif.ts which constructs exactly such a JSON: it iterates through Mesh nodes and edges and produces a JSON graph with I-nodes and S-nodes[27][28]. This confirms that a straightforward JSON representation is feasible and largely done.
Supporting multiple serializations (RDF, JSON-LD, GraphML, etc.) ensures interoperability. A debate map created in Agora could be exported to a .aif or .json file and then loaded into academic tools like OVA+, Carneades, or Argunet for analysis[48][49]. Conversely, argument datasets available in AIF (for example, in AIFdb or in the literature) can be imported into Agora, so users can extend or discuss them[50]. We plan to provide import/export endpoints (/api/deliberations/{id}/aif for export, and a corresponding import route) to handle this conversion[51][7]. Because AIF is a lingua franca, this step positions Agora as a node in the larger Argument Web: arguments flow in and out without losing structure. RDF/JSON-LD also means we could integrate with the Semantic Web at large – e.g., linking an argument’s I-nodes to DBpedia or other datasets if appropriate, though that’s an advanced use case.
In summary, AIF can be “reified” in many formats including RDF, OWL, JSON, Prolog, and even visual DOT diagrams[46]. For immediate purposes, JSON-LD is likely the most practical, as it dovetails with web APIs. We will define a JSON schema closely matching AIF’s structure so that conversion is lossless. The slight overhead of managing node IDs and separate S-nodes is worth the gain that any other AIF-compliant system can interpret our data. This is crucial to avoid the “walled garden” trap: using AIF means our users’ contributions become part of a broader, interoperable ecosystem[52][53]. Researchers, for instance, might export a whole debate from Agora and run their own analyses (argument mining, network metrics) on it, or conversely import a corpus of arguments (say, from a public policy debate archive in AIF format) to kick-start a discussion on our platform[50].
Interoperability in practice: Once the serialization is in place, we can directly interface with tools like AIFdb – a repository of AIF arguments[54]. A user could click “Export to AIF” and get a file that AIFdb accepts, immediately contributing to the Argument Web’s knowledge base[55]. Or an admin could import an AIF file from an external analysis tool, populating the Agora debate with a complex argument structure pre-annotated by experts. This fluid exchange is a strategic benefit: it amplifies Agora’s utility (for instance, educators could use Agora as a front-end to visualize argument corpora from research, and then have students continue the debate).
Design Considerations for Internal AIF Modeling vs. User Simplicity
Adopting AIF under the hood brings significant complexity to how data is structured – but this complexity should remain invisible to end users. The design must balance a rich internal semantic model with a simple user experience. Key considerations include:
Preserving the Illusion of Simplicity: Users should still feel like they are interacting with a straightforward forum or mind-map, not a formal graph. The UI can present familiar concepts (claims, pros, cons, questions) while internally we maintain the I-node/S-node separation. For example, when a user creates a supporting argument, they need not know an RA-node and several edges were created; they just see their premises attached under a conclusion. This means the application layer should translate intuitive actions into AIF structures behind the scenes. Fortunately, our current architecture already moves in this direction: e.g. a user clicking “Add Reason” triggers code that will create the necessary records (Claim, Argument, edges) to represent that support[56]. We will extend those handlers to possibly create multiple records (I-nodes and S-nodes) in one go. The user, however, experiences it as one action.
Atomic Operations Mapped to Graph Changes: Each user action (posting a claim, linking an argument, asking a question, etc.) will correspond to a small graph transformation in AIF. We must ensure these operations remain transactional and undoable. For instance, posting an argument might create 1 RA-node and N edges; asking a critical question might create a CA-node or mark a CQ as open. Our backend should encapsulate these multi-node creations in single API calls. This is already envisioned – e.g. the /api/claims/[id]/rebut endpoint can create an ArgumentEdge with target scope, which under the hood might actually map to creating a new Argument (RA) and a linking CA relation[57]. By keeping these atomic, we reduce the risk of partial graph states that could confuse the UI or violate AIF’s consistency rules (AIF, for example, requires that S-nodes always connect I-nodes – we should not leave a floating S-node)[58].
Data Model Extensions: To fully embody AIF, some new tables or fields will likely be introduced, but we can do so in a way that augments rather than replaces existing models. For example, we might add an Inference model to represent S-nodes explicitly. However, since we already have an Argument model, we could simply use that for RA-nodes. It may require slight changes: e.g., ensure an Argument has a field for schemeKey or a foreign key to a scheme definition (to know what type of RA it is)[26], and possibly a way to reference which premise claims it uses. If previously premises were implicitly all ClaimEdges pointing to a conclusion, we might formalize it by having an Argument.premises: Claim[] relation (or use the existing ClaimEdge but point it at Argument as target instead of Claim). The ClaimEdge model currently links claims to claims with types like supports/rebuts[59]; going forward, we might deprecate direct Claim→Claim edges in favor of always routing through an Argument object (Claim→Argument via a premise association, and Argument→Claim for the conclusion). This is a significant shift: it means even a single-premise support would have an Argument container (RA-node). The benefit is consistency – every inferential step is uniformly represented – at the cost of a bit more bookkeeping. The system can hide this by auto-creating an Argument record whenever someone links one claim to another for the first time. From then on, that Argument can accumulate additional premises or metadata.
Identifying Node Types Implicitly: We might choose not to store a separate table for CA-nodes at all. Since a CA-node (attack) often doesn’t carry additional content (it’s just an application of a conflict rule), we can infer its existence from an ArgumentEdge or similar. For instance, if user A’s argument undercuts user B’s argument, we create an ArgumentEdge record with type='undercut' pointing from A’s Argument to B’s Argument[60]. This single record actually encodes an AIF CA-node (the attack relationship). Instead of materializing a row “ConflictNode123”, we interpret the edge at runtime as “there exists a CA S-node linking A’s RA to B’s RA.” This was exactly our approach in the prototype exporter: we didn’t have stored S-nodes for conflicts, we generated them on export[28][61]. We should carefully evaluate if this is sufficient or if we need to explicitly store conflict nodes (for example, if we want to attach properties to an attack, like a name or scheme, e.g. a CQ identifier). If critical questions are implemented as special kinds of attacks, we might tag the ArgumentEdge with a cqKey to denote which question it corresponds to[24]. The design decision comes down to complexity: introducing a full “Conflict” entity might complicate the schema and ORM relationships, whereas leveraging the existing edge with additional metadata (type, targetScope, schemeKey) might cover all cases[60]. The current blueprint indicates that ArgumentEdge.targetScope and targetInferenceId already allow fine-grained targeting (premise vs inference)[62][63]. That plus knowing the scheme can tell us exactly what kind of CA-node to create on export (e.g. a rebuttal CA attacking an I-node vs an undercut CA attacking an RA-node).
Ensuring Internal Consistency: AIF has some invariants (no I→I edges, S-nodes must connect properly, etc.)[58]. By construction, if we always manipulate through our high-level models, we should maintain these. But we might add some safeguards. For example, we should never allow a ClaimEdge or ArgumentEdge that connects a Claim to a Claim directly without an intermediate Argument if that breaks our new structure. Similarly, a DialogueMove that is of type “GROUNDS” should always have an associated Argument (content) – we can enforce this by validation: if someone tries to post a justification without content, it’s invalid. Essentially, the app’s business logic becomes responsible for only producing valid AIF graphs. We can implement unit tests on the export function: create various debate scenarios in the database, run the AIF export, and verify the output graph meets the spec (e.g., each S-node has requisite I-nodes around it, each attack is well-formed, etc.).
Hiding Syntax, not Structure: It’s worth noting that while we hide the jargon (I-node, RA-node) from the user, we do want to expose the logical structure in an intuitive way. For instance, users don’t see an “RA node”, but they might see a warrant or a visual cue that multiple premises are linked together supporting a claim. In the Toulmin model, what AIF calls an RA-node might surface as the “since [warrant]” or a grouping bracket around premises. The design principle is to surface structure in domain language: say “these reasons combine to support that claim” rather than “an RA-node connects these I-nodes.” We have to be careful that the added complexity of undercuts and the like is introduced to users gradually. The platform can provide explanations or guided steps when users perform an advanced action. For example, if a user chooses “Challenge Inference” (undercut) in the UI, we can pop up a brief hint: “You are questioning the connection between the reasons and the claim – i.e., saying the reasons don’t really prove the point.” This maps to AIF’s undercut concept but communicates it in plain English[64]. The system already plans such user education through tooltips and non-jargon labels[64].
In summary, using AIF internally means the data model grows a bit more complex (more node types and relationships), but each piece is logically motivated. We will carefully containerize this complexity: one-click user actions trigger potentially multiple low-level changes, and the UI language remains non-technical. We need to extend our database schema in a few places (scheme references, possibly an explicit inference table or at least a more structured way to link premises to arguments) and enforce new constraints (no direct claim-to-claim support edges without an argument in between, etc.). By doing so, we gain a robust backbone that can capture nuances (rebut vs undercut, implicit assumptions, etc.) that were previously hard to model or enforce[65][66]. The guiding design heuristic is: if an important distinction or rule exists in argumentation theory, represent it in the backend; but only expose it to users as an optional aid or visualization. Agora will thus benefit from AIF’s rigor while keeping the user experience as smooth as a typical discussion platform.
Mapping AIF Elements to Digital Agora Components
To integrate AIF as the “native substrate,” we map each AIF concept to the nearest Agora concept, adjusting our models where necessary. The table below summarizes the mapping and notes the required model/API changes:

With these mappings, AIF’s abstract graph maps onto concrete objects in our system. Where necessary, we have introduced new linking logic (e.g., Argument as RA with multiple premises, ArgumentEdge as CA) or new fields (scheme references, move anchors). The table highlights that much of the structure can be achieved by evolving existing models rather than completely new ones. Claims and Arguments remain primary, but we enrich them to cover AIF’s needs. DialogueMoves encapsulate the extra dialogical layers (L, TA, YA).
Changes to Data Models and APIs: Based on the above, we anticipate the following modifications:
Prisma schema updates: Add schemeId (foreign key to ArgumentScheme) in the Argument model[25]. Ensure the Argument has conclusionClaimId if not implicit. Possibly add an ArgumentPremise join table (with fields argumentId, claimId, isImplicit) to list premises. Alternatively, reuse ClaimEdge for premises: a ClaimEdge of type “supports” with a target that is an Argument (instead of Claim) – though that may overload ClaimEdge’s meaning. A cleaner approach: have an Argument.premises JSON or structured field, but relational is better for querying. Also, define ArgumentScheme and CriticalQuestion schemas to populate the scheme library.
Edge schema: The Edge handling is a bit split in current design (ClaimEdge vs ArgumentEdge). We might unify them under one model now that we always have Argument nodes. For instance, we could have only ArgumentEdge: it links either Argument→Argument (for attacks/supports between two arguments), or Argument→Claim (if an argument supports a top-level claim that isn’t itself an argument’s conclusion). In our blueprint, an Argument had an optional link to a Claim it supports[73], and an ArgumentEdge handled argument-to-argument links[60]. We will maintain both link types: support links (Argument to a Claim, fulfilling that claim) and attack links (Argument to Argument, representing counterarguments). This means some existing ClaimEdge entries (those that are direct supports) will become redundant because we’ll use Argument records. We should migrate those: e.g., if Claim A “supports” Claim B, we create an Argument RA with premise A and conclusion B, and deprecate the direct ClaimEdge. Doing this migration and enforcing it in the UI will move users into the AIF-compliant model without loss of generality (the direct edge was a special case of a one-premise argument).
Dialogue moves: The DialogueMove payload can carry structured references for illocution and transitions. We might add explicit columns for replyToMoveId (if not there) and moveType (already exists, enumerated). If we want to store the illocutionary action separate from moveType (which might combine content type and illocution), we could add illocution as an enum (Assert, Question, Challenge, Respond, etc.). But since our move types largely encode illocution (e.g. a WHY move is essentially the illocution of questioning, a GROUND move is asserting an argument), we may stick to those. We just need to ensure we have enough move types to distinguish all needed acts (perhaps adding one for conceding, which is an illocution of surrender – the blueprint did add a concede type to Edge and move)[74].
Critical question tracking: Already, a CQStatus or similar tracks whether a critical question is satisfied for a target (which in code appears to be targetType 'claim' or similar)[37][38]. We will adapt this to target an Argument (RA-node) rather than a raw claim, since it’s the argument that instantiates a scheme. So CQStatus could key on argumentId + cqKey instead of (or in addition to) claimId. The logic in /api/cqs/summary would then aggregate by scheme for that argument’s conclusion claim[37][38]. We might redesign this such that each Argument (RA) has many possible CQs (join via scheme) and for each we record whether answered. This aligns with AIF: an unanswered critical question corresponds to a potential attack (CA-node) that has not been defeated.
API endpoints: We will create new endpoints for AIF import/export as noted[51][7]. Import will parse an AIF JSON and create the corresponding Claims, Arguments, and edges. Export will do the inverse. We’ll also update existing endpoints: e.g., posting a support should potentially create an Argument if multiple premises are provided or if we’re standardizing on that. The dialogue move posting (/api/dialogue/move) will include logic to attach moves to arguments (e.g. if a move is a GROUNDS with content, create Argument + link it)[14][17]. The attack posting (/api/deliberations/[id]/edges or equivalent) already handles targetScope – we will extend it to properly set ArgumentEdge.targetInferenceId if undercutting a specific inference within a complex argument[60][62]. That targetInferenceId will correspond to either the Argument’s ID (if we treat each Argument as one inference) or to a sub-inference if arguments get more granular. Given our approach, each Argument is one inference, so undercut simply targets that Argument’s ID.
In implementing the above, AIF adds value in several places: it enforces that we clarify what exactly an attack targets (premise vs conclusion vs inference), eliminating ambiguity that users previously had to resolve with “targetScope” dropdowns[66][75] – now the graph structure itself encodes it. It also adds the ability to represent implicit assumptions formally (via additional I-nodes that can be flagged as implicit and required for the inference to hold) and to automatically surface them as needed (the Enthymeme resolution feature can insert a new Claim as an implicit premise I-node linked into the RA)[76][77]. The separation of I-nodes from RA-nodes means the system can, for example, detect when two different arguments share a common premise or sub-conclusion (since they’d literally use the same I-node ID in both), enabling merging of duplicate claims and a more connected graph rather than isolated trees. AIF’s abstractions (schemes, critical questions) bring domain knowledge into the system – we gain a ready-made “checklist” of potential counterarguments for each argument via the scheme’s CQs[78][33]. This is a step beyond current practice where a user might not know how to challenge an argument – the system can now guide them (“You could question the expert’s credibility, or provide a counter-example, etc.”) in a context-specific way.
However, we must also note where AIF’s standard model needs extension or adjustment for Agora’s specific goals:
Complex Debate Structures: Agora’s notion of a DebateSheet or multi-threaded debate where whole arguments (even sequences of arguments) are nodes in a higher-level graph[79][80] goes beyond vanilla AIF. AIF is great at modeling the micro-structure of a single argument and its direct attacks (argument1 and argument2 in Wigmore’s terms), but Agora aims to support graph-of-graphs – debates composed of many argument threads aggregated. We will implement this via the DebateGraph / ArgumentDiagram layering (where a DebateSheet is like an AIF meta-graph whose nodes map to subgraphs)[81][82]. This isn’t an extension to AIF per se, but a layering on top: effectively treating each self-contained AIF graph as a node in a bigger network. We might formalize this by assigning each deliberation or each top-level position its own AIF graph id and then linking across graphs via special edges (the cross-sheet relations like “rebuttal developed here” are pointers to attacks between content in different sheets)[83][84]. To keep AIF relevant, we can still express those cross-debate links in AIF if needed (just that those I-nodes or S-nodes belong to different subgraphs – we can use node naming conventions to keep them distinct). The Agora Debate Metastructure essentially wraps AIF graphs in a hierarchical structure[82][85]. We may define custom metadata (not in standard AIF) to identify which Argument belongs to which DebateSheet, etc.
Illocutionary Nuances: AIF’s YA-nodes account for standard speech acts (assert, question, challenge, etc.), but Agora has some specialized moves (like “concede” which is a surrender, or meta-dialogue moves to negotiate structure). We will need to see how to represent a Concession in AIF terms – possibly as a special illocutionary act node that doesn’t anchor an inference but rather changes a commitment store. There isn’t a direct AIF equivalent, but we can manage it by treating concession as an act that adds an I-node (the proposition) to the speaker’s commitment record. In the AIF graph, a concession might not appear except indirectly (it could be modeled as a transition that ends a line of argument). We likely handle it outside the core AIF graph (e.g., marking the claim as agreed-upon). This is a place where Agora’s requirements (tracking commitments over time) extend beyond AIF’s static graph. We’ll integrate by linking concession moves to an outcome: if user concedes claim C, perhaps we attach a special Preference node (PA-node) indicating a preference for not arguing C further, or simpler, we just mark the claim’s status as conceded for that party (outside the AIF graph but affecting what moves are allowed)[86][87].
User Identity and Roles: AIF’s nodes do not inherently carry information about who made them (except that L-nodes can have author metadata). In a multi-user Agora, we care about which participant asserted which claim (to avoid a user refuting themselves, etc.). We will carry that in DialogueMove (author id) and in Commitment records, not in AIF itself. This is an extra layer we maintain on top of AIF: each I-node can have zero or more owners committed to it, and so on. AIF doesn’t forbid adding this info – we can attach properties like author to L-nodes when exporting (since the ArgML allows attributes), but it’s not part of the interchange standard that affects reasoning. So we must manage consistency: e.g., if Alice attacks Bob’s argument, the system should log that appropriately, perhaps preventing Bob from having to attack his own argument. The AIF graph doesn’t do that for us; our protocol layer does.
Granularity of Inferences: In some arguments, especially complex logical ones, a single user contribution might embed multiple inferential steps (serial arguments). AIF would want each step to be a separate RA-node, chained (one RA’s conclusion becomes premise for another RA)[88][89]. Our current UI doesn’t explicitly support users making multi-step arguments in one go (they usually assert a conclusion and provide premises – that’s one step). If we ever allow, say, an argument with a sub-conclusion (like Toulmin’s backing/warrant structure or a proof chain), we might need to support RA-nodes feeding into RA-nodes. The data model can handle it (Argument can conclude a claim that is itself used as premise of another Argument), and our export would show an S-node-to-S-node link for such cases[90]. We just need to be mindful to implement UI that allows users to either break down steps or for us to automatically split them. This is not a limitation of AIF – it supports it – but a challenge for making it user-friendly to construct such structures.
Performance and Complexity: Storing everything as fine-grained nodes can impact performance, especially for retrieval and visualization. We should ensure our API can fetch an entire subgraph efficiently (likely via joins or batch queries) since a DebateSheet may contain dozens of nodes that now span multiple tables. We might provide a single endpoint that delivers the argument graph in one JSON (already planned with the deliberation AIF export)[51]. Also, certain operations like “compute grounded semantics” become more elaborate but still tractable given the graph sizes (these are more algorithmic than DB-bound).
To mitigate potential confusion or overhead, we’ll implement these changes gradually and maintain backward compatibility in the API where possible. For example, for a time we might accept a simple support submission (claim→claim) and internally convert it to an Argument, so existing client code isn’t broken. We’ll mark such uses as deprecated and update the front-end to use the new structure (ensuring, say, that every new “reason” a user adds results in an Argument created). Proper migrations will convert old data (maybe flatten existing ClaimEdges into Arguments). The end result is that the internal model becomes fully AIF-aligned, enabling all the powerful features we want, while the external behavior remains user-friendly.
Benefits of AIF Integration vs Current Practice
Adopting AIF offers numerous concrete benefits over the prior ad-hoc approach:
Unambiguous Semantics of Attacks and Supports: Previously, users could mark an edge as “rebut” or “undercut” and specify a target scope, but the system did not inherently understand the difference beyond that flag[66][75]. With AIF, the distinction is baked into the graph: a rebuttal appears as a CA-node attacking an I-node (conclusion) while an undercut is a CA-node attacking an RA-node (inferential link)[7]. This structural difference allows the reasoning engine to treat them differently (e.g., an undercut disables the inference rule, meaning even if premises are true the conclusion isn’t supported; a rebuttal simply provides a counter-claim). It also enables the UI to automatically display different icons or connector styles for these cases without relying on manual user input beyond the initial move type[5]. In short, AIF provides granular attack taxonomy out of the box, aligning with Pollock’s and others’ categories (undermine, rebut, undercut)[68][91].
Integration of Argument Schemes and CQs: By using the scheme and critical question apparatus, we enrich the user experience in a guided yet flexible way. Current practice had a CriticalQuestions sidebar that was informational (“Here are some questions you might consider”)[92]. In the new approach, those questions become actionable moves – the user can click one and the system formally registers a challenge tied to that CQ[39][40]. This is possible because behind that click, the system knows which scheme’s RA-node to target and what type of attack it should be (the CQ’s metadata tells us “this question is an undercut on the inference” or “a rebuttal of the premise”)[32]. The value added is that critical questions are no longer just text hints; they are triggers for creating structured counter-arguments. This leads to better engagement (users are prompted to address specific issues) and higher quality deliberation (each critical question must be answered by a corresponding argument or the original argument remains under a shadow of doubt)[33][24]. It operationalizes Walton’s insight that critical questions indicate standard defeaters[93][94]. Agora can become a teaching tool for critical thinking: participants learn the types of challenges appropriate to different arguments, but they don’t need to know the theory’s name – the interface guides them (“Is the analogy really applicable?” when someone makes an analogy argument, etc.).
Interoperability and Community Integration: As mentioned, an AIF-native backend immediately puts Agora on the “Argument Web” map. All our debates could contribute to research – for instance, a corpus of arguments about climate policy on Agora could be exported and added to AIFdb, letting researchers run analytics on it[50]. Conversely, interesting argument graphs from academic projects could be visualized and continued on Agora. This positions the project as a node in a global ecosystem of argument tools rather than an isolated product[52][49]. This can attract power users (like debate coaches, argumentation scholars) who value that their work isn’t locked in. It also future-proofs the platform: by adhering to a standard, we can adopt third-party improvements. For example, if someone develops a better argument evaluation module that takes AIF as input, we can plug it in. The evaluation engines like Dung-O-Matic or TOAST are ready to use – indeed we plan to feed our AIF graph to TOAST to compute argument acceptability semantics[95][96]. This yields immediate user-facing features: e.g., marking each Argument as in or out of the “justified” set according to grounded semantics, something we’ve aimed to do with our Argument Label (IN/OUT/UNDEC) mechanism[97]. With AIF, the pipeline from user content to formal evaluation is well-defined, as proven by existing pipelines in the Argument Web[98][99].
Enhanced Consistency and Error Checking: AIF’s formalism can serve as a built-in validator for the structure of debates. For instance, because each Argument must have at least one premise and one conclusion, the system can prevent or warn against degenerate cases (like an argument with no premises, or a “support” connection with no actual reason given – which might happen if a user posts a claim but doesn’t fill in the reason text). Likewise, since attacks must target something specific, the system can catch mismatches. We already implemented a check for users marking an attack incorrectly (e.g., if they said “undercut” but their content actually contradicts a premise, that’s an undermine, not undercut)[100][101]. In AIF terms, we’d notice they created a CA-node intended for an RA, but the logic might show it’s hitting an I-node. The structured model plus a bit of logic can automatically correct or guide the user (“It looks like you are attacking the truth of a premise, should this be marked as rebutting the premise?”)[102]. The AIF mapping thus reduces user error and semantic drift – arguments are placed in the right relation and any inconsistency (like attaching an attack to something that doesn’t exist, or leaving an argument dangling without a conclusion) can be detected by graph integrity rules.
Rich Dialogue Management: With locutions and transitions in play, we can enforce dialogue protocol more strictly and offer more advanced features. For example, because each move knows what it replies to and with what illocution, we can ensure that certain moves can only be answered by certain moves (as per the configured dialogue game rules)[103][104]. This was part of the plan (the Lorenzen/Prakken rules) and now it sits on a firm representational foundation: every move is categorized and linked, so a legal-move function can examine recent L-nodes and their YA/TA relations to output allowed next moves. In effect, AIF+IAT gives us a machine-interpretable dialogue history, enabling features like structured debate mode, turn-based moderation, etc., far beyond a typical forum. Also, because locutions are separate, we can have multiple users refer to the same underlying I-node without confusion (two people agreeing on the same claim will produce two L-nodes pointing to one I-node). The system can recognize that and perhaps merge the debate threads or at least mark that “Alice and Bob both asserted this claim” – something that’s clearer when you have L-nodes mapping to identical I-nodes.
Modularity and Composability: Each small piece of an argument graph (like an RA-node with premises) can be composed with others to form bigger structures. Users can build complex cases step by step, and because we model each step, the system can allow users to reuse or recombine steps easily. For instance, if a sub-argument (RA-node) supporting a premise becomes contested, that sub-argument is itself an Argument object that can be targeted by counterarguments or reused to support another related claim. We essentially get the benefits of a graph database of ideas, where any node can be linked to any other with appropriate semantics, instead of a rigid tree of posts. Our prior system allowed reference by IDs and linking claims, but with AIF it’s systematic. This modularity is also key for collaborative argument building: multiple people can contribute premises to the same RA-node (one user started an argument, another user suggests an additional premise), because the backend can attach another premise I-node to the existing RA-node. We’d need UI support to manage that (maybe a feature to “add a supporting premise to Alice’s argument”), but the data model will support it, whereas a simpler model might not (since it often assumes one owner per argument edge).
Expressivity for Advanced Reasoning: With the inclusion of Preference nodes (PA-nodes) and other scheme types, we can eventually represent value judgments or preferences (e.g., “Economic growth is more important than emission reduction” could be a PA-node reasoning that influences which argument wins when goals conflict)[105]. Agora hasn’t focused on preference handling yet, but in policy debates these often arise. AIF has a placeholder for it, so if we need it, we can extend our implementation to include a Preference model (similar to RA and CA). Additionally, if we explore meta-argumentation (arguments about arguments), AIF’s capability to have S-nodes as endpoints of attacks covers that (e.g., undercutting an inference is one example; one could also imagine an argument attacking the application of a scheme type generally). We are less likely to need exotic forms initially, but knowing the ontology can handle them is reassuring.
One caveat: Performance and UI complexity must be managed. The advantages listed assume a well-implemented system. If not done carefully, a naive AIF implementation could overwhelm users (by showing too many low-level nodes) or slow down due to the sheer number of elements. We have addressed this by deciding to hide AIF’s complexity by default and present aggregated views (see next section on UI flows), and by mapping AIF nodes to existing structures where possible to minimize overhead.
To highlight concretely: Where does AIF need extension or tweaking for Agora? Primarily in handling higher-level debate structures (grouping arguments into threads and sheets) and certain dialogue moves like concessions or procedural moderation moves (which we may need to represent outside the core AIF graph). We might also extend scheme definitions for our domain-specific needs (e.g., a scheme for “practical reasoning with costs and benefits” with its own CQs). But these are additive – they don’t break AIF, they build on it. The core abstractions of AIF (I, S, L nodes) cover our needs well, and we bend them only slightly (e.g., using an ArgumentEdge record to imply a CA-node rather than storing a separate CA entity).
In short, AIF’s abstractions map to Agora’s current concepts closely (claims, arguments, moves), but with more rigor and nuance. By adopting them, Agora gains a clearer separation of concerns, automated reasoning potential, and connectivity to a wider network, all of which outweigh the added model complexity. As the Formal Foundations report noted, following AIF ensures our “rich internal graph of Claims, Arguments, and Edges can be serialized for interoperability” and aligns with Walton’s schemes and Prakken’s dialogue moves that underpin our features[53][106]. Agora’s current practice already intuited many of these structures; AIF formalizes and extends that practice in a standardized way.
UI/UX Recommendations for an AIF-Powered Agora
One of the biggest challenges is to expose the power of AIF’s structured representations without requiring users to learn AIF or logic formalisms. The user interface should remain as intuitive as possible, while leveraging AIF to provide new guidance and visualization options. Below are recommendations for user-facing flows and features, informed by the need to preserve AIF’s modularity/composability in an intuitive manner:
1. Streamlined Argument Construction with Scheme Templates (Optional): When a user clicks “Add Argument” or responds to a “Why?” challenge, the system knows the expected scheme (if the user is answering a specific critical question, it even knows the attack type). We should provide a structured composer that aligns with that scheme’s slots only if it aids the user. For example, if the user is making an Expert Opinion argument, the UI can present labeled fields: “Claim (what did the expert assert?)”, “Expert’s Name and Credentials”, “Why this expert is credible”. This effectively walks the user through providing premises that match the scheme (source’s statement, source’s expertise, trustworthiness) without naming it formally[71][72]. This guided template can be optional – novices might prefer a freeform input and let the system infer scheme, whereas advanced users or those who choose from a “Argument Type” dropdown can get a form tailored to that type. The advantage is twofold: (a) Modularity – users see that an argument is made of parts (contention, support reasons, assumptions) which parallels AIF nodes, and (b) Completeness – it reminds them to fill in all parts (covering potential critical questions proactively). However, we must be cautious not to overwhelm or constrain creativity, so this should feel like help, not a requirement.
2. Critical Question Challenge Flow: We will elevate critical questions to first-class UI actions. Next to any argument (e.g., on an argument card or in a tooltip on a support link), the interface can show a “⚡ Challenge” or “Ask a Question” option. Clicking it can either directly list the relevant critical questions for that argument’s scheme (e.g., “Is the expert biased?”, “What if a counter-expert disagrees?” for an expert opinion argument)[39][40], or present a general challenge prompt. If the argument’s scheme is known, listing the CQs is ideal – the user can pick one that fits their concern. Each listed CQ is essentially a pre-configured attack: when selected, the system creates a new WHY move with that question text, targeted at the specific argument, and internally tags it with schemeKey and cqKey so we know its semantics[24][107]. The UI then could display this challenge inline as a “virtual attacker” node beneath the argument. For example, the argument card could now show a red question or an icon indicating an open challenge on it. This is much more engaging than before, where critical questions might have just been a checklist. The responder (original arguer or anyone defending that side) can then address this by clicking “Answer” on that challenge, which opens a composer for a GROUNDS move to answer it[36]. That answer will be treated as a counter-argument that defeats the attack (i.e., a new argument that undercuts the undercut or rebuts the rebuttal). The UI should reflect when a critical question is satisfied – e.g., the challenge icon turns green or is crossed out once answered, and the answered challenge may collapse to keep the interface tidy, perhaps now labeled as “Answered: The expert’s bias was addressed with evidence.” This flow ensures every critical question becomes a mini-thread in the dialogue, neatly anchoring potential attacks to specific points of the argument.
3. Distinguishing Attack Types Visually: Users don’t need to know the terms “RA” or “CA,” but they should be able to see the difference between attacking a claim vs attacking an inference. We recommend subtle visual cues in the debate map or argument diagram views. For example, rebuttals (attacks on conclusions) can continue to be shown as arrows pointing to the claim node, perhaps colored red. Undercuts (attacks on inference links) could be shown as arrows that hook into the support link or into a small icon representing the “warrant” between premise and conclusion[5]. In a textual interface, this could be an annotation like “(challenges the reasoning)” vs “(challenges the truth)” next to the counter-argument. The Dialogical Panel or map view can use different shapes or line styles: e.g., rebuttals might attach to the target claim bubble, whereas undercuts might attach to a diamond (representing the hidden RA) on the target argument’s link. We might also use icons: a rebuttal icon (⊥) vs an undercut icon (⇏) to hint at their meaning. All this can be done without naming them “RA/CA” – use phrases like “Rebuttal” and “Relevance Challenge” as in the UI copy[64]. Indeed, the earlier mitigation plan was to label undercut actions as “Challenge Relevance” to users[64]. The UI already considers highlighting these differences (e.g., different arrow styles)[108][5]; we will implement those. This helps preserve the underlying structure (users can literally see that one argument targeted another argument’s link) and fosters understanding of the debate’s logic. It’s like providing an interactive Toulmin diagram view: users can toggle a mode where the inference (warrant) is explicitly shown as a node that attacks can latch onto. That leads to the next point:
4. Toggle Between Simplified and Detailed Views (Collapsible Graph Detail): A core strategy to handle complexity is to offer multiple views or layers. By default, a casual user might see a collapsed view of arguments: each argument card shows its conclusion and premises indented below it, and maybe a summary of any counterarguments (e.g., a small badge “2 objections”) without all details. For power users or in “analysis mode,” we allow expanding an argument to see its full internal structure: premises, conclusion, and an explicit representation of the inference node (perhaps an empty or labeled box in between, or a highlighted connection) along with any critical questions as separate nodes around it. This corresponds to the “Harrell Lens” or meta-flow view that shows where objections target premises vs inferences[45]. For example, in an expanded argument diagram, you might see: Premise A and Premise B —> (Warrant: “if A and B then C”) —> Conclusion C. An undercutting objection would appear as an arrow into that warrant box, whereas a rebuttal appears as arrow into C[5]. Users can click “simplify view” to hide the warrant box and instead see a simple list where undercuts might just be listed under a section called “Challenges to the connection.” This expand/collapse approach was explicitly suggested in internal discussions: nodes on a debate map can expand into argument diagrams[109][110], and the need for two-level navigation was emphasized[82][85]. We should implement a UI where each argument (or top-level claim) has an expand toggle. Clicking it either switches to a dedicated view (overlay or panel) showing that argument’s structure (a “pop-out” argument diagram)[111][112], or in-place expansion if feasible. Conversely, collapsing hides the internal nodes to keep the bigger debate map clean. By preserving AIF’s modularity in the data, we enable exactly this: because each argument is a subgraph, we can show/hide it without confusion.
Multiple UI modes: In practice, we may have distinct UI modes: e.g., Outline View, Map View, Threaded Dialogue View. In Outline (text outline or tree), attacks can be shown nested under arguments with labels. In Map (graph) view, nodes can be dragged and visualized network-style. The two-column pro/con view is another representation (list arguments for and against side by side)[113]. Thanks to AIF, these are just different projections of the same underlying graph. For instance, an argument graph can be traversed to produce a tree (for outline) or rendered in a force-directed layout (for network). Providing these toggles caters to different user preferences and helps in teaching: novices might start with a friendly outline, and as they get more advanced, they might explore the network view to see the full interconnections. The multi-view approach was identified in research as beneficial[114]. We should ensure changes in one view reflect in others (live synchronization, since it’s one data model).
5. Dialogue Guidance and Move Restrictions: With dialogue moves formally typed and connected, the UI can proactively guide users on what moves are allowed or make sense next. For example, after someone makes a claim, the interface can highlight buttons like “Why?” (to challenge), “I agree” (to concede), “Counter” (to rebut) – pulled from the legal moves computation[103][104]. These options correspond to illocutionary moves (YA) and will create the appropriate AIF structure when clicked. This prevents users from making structurally incoherent moves (like offering a support when a concession was needed, etc.), thereby preserving the argument graph’s integrity. The UI chips for legal moves were planned[103][115]; they now tie in neatly because behind each chip we know exactly what structural addition will occur (e.g., a “Counterargue” chip means the user will input a claim that results in a new Argument RA-node whose conclusion negates the opponent’s claim, plus a CA-edge connecting it). By guiding the user through these choices, we effectively train them in argumentation protocols implicitly. It remains intuitive (“I click ‘Why?’ to ask for justification”) but it’s enforcing a formal dialogue game from IAT. We should make this guidance optional or adjustable (some users may prefer freeform, so a “Structured Debate Mode” toggle is wise)[103][104], to avoid stifling casual conversation.
6. Representing the State of the Debate: With the AIF graph, we can compute and visually indicate which arguments stand and which are defeated at any moment. A great UI feature is to provide a “Debate Status” or “Evaluate” button that runs the argument evaluation service (Dung’s algorithm or similar) and then annotates the map: e.g., arguments that are undefeated (in the current state) get a green check or a badge “Accepted,” arguments that are defeated (some stronger rebuttal exists) get a red X or “Rejected,” and undecided ones maybe a gray question mark[95][116]. This was mentioned as an on-demand analysis of “state of the debate”[117]. We could even show these statuses continuously as small icons on each argument card. For instance, a claim node might have a green dot if it’s currently justified (i.e., has at least one supporting argument in the accepted set and no undefeated attackers)[116]. This gives users feedback on how the conversation is progressing logically, not just rhetorically. It leverages the formal structure to provide a sort of “verdict” that can motivate further contributions (“All my arguments are marked OUT; I should strengthen them or attack the attackers”). It’s important to clarify that these are computational supports for insight, not moderator judgments, so we’d perhaps present it as “Analytic Aid: Based on the arguments so far, Claim X is not supported (because the one argument for it was undercut).” This can be done in an Analysis panel or mode so as not to distract casual chat, or as small indicators users can click for explanation.
7. Modular Reuse of Arguments (UI affordances for composability): Since AIF allows the same I-node in multiple relations, the UI should encourage reuse of existing claims and even arguments. For claims, we can provide an autocomplete or search when someone starts typing a claim – “Did you mean [Existing Claim]?” – to avoid duplicate nodes for the same proposition. If they choose an existing claim, we simply create a new locution (L-node) asserting it or use the claim in a new argument link, rather than a brand new I-node. This keeps the graph interconnected. For argument reuse, a user might say “Alice already provided a reason (Argument A) that also supports my point.” We could allow linking an existing Argument as support to another claim, effectively creating a second outgoing edge from that RA-node to a new conclusion (if logically applicable). However, caution: most arguments are context-specific, so reuse of entire RA-nodes might be rare unless it’s a generic inference rule. More realistically, reuse will occur at the claim level (shared evidence or shared sub-conclusion). The UI thus should make it easy to reference earlier claims: e.g., a sidebar of “Key Claims in this debate” that can be dragged into your argument as a premise. This preserves modularity: users build larger arguments by assembling previously established smaller ones, akin to how Lego pieces (I-nodes) connect via connectors (S-nodes). Over time, this could lead to a knowledge base underlying the debates, where frequently used claims (like common facts or principles) become reference points, and the interface might highlight them (like Wikipedia-style references or the “canonical claims” concept where one global claim is referenced in multiple debates)[118][119].
8. Intuitive Visualization of Dialogue: Given L-nodes and transitions, we can enhance the timeline view of the debate. Instead of a simple chronological list of posts, we could indent or thread them by reply (which we might already do), but also label them by move type. For example, prefix a post with “Challenge:” or “Answer:” to indicate its role. Perhaps use speech-act icons (❓ for question, 💬 for assertion, ✔️ for concession, etc.). This way, participants and observers see the flow: e.g., Alice: [Claim], Bob: (Why?), Alice: (Because …), which corresponds to L-node chaining with a YA “argue” on the second link. This is basically showing the protocol in action, but in friendly terms. Additionally, we can group dialogue moves by the issue being discussed – since AIF links moves to propositions, one could filter the dialogue to “show me all locutions about Claim X and the arguments around it.” This might be too advanced for UI initially, but it’s something AIF enables (because each locution has a content reference, one could pivot on that).
9. Educational and Onboarding Aids: Embracing AIF’s structure means we are introducing users to more structured argumentation. Many will not be familiar with terms like premise, inference, undercut, etc. We should include onboarding pop-ups or a quick interactive tutorial that explains our UI elements. For instance, when they first see an undercut icon, highlight it and show: “This icon means someone is questioning the relevance of the reason – they’re not saying the reason is false, but that it doesn’t prove the point. You can click it to see the challenge.” Similarly, an initial guide might show how to add a supporting argument vs how to rebut. Essentially, we are teaching critical thinking moves implicitly through UI cues. Over time, users might pick up argumentation scheme names or at least categories (“This is an analogy, I should check for counterexamples because the system always reminds me with that question.”). We could even have a “Explain this to me” button on an argument card that describes in plain language what is going on: e.g., “This argument uses the Argument from Consequences scheme, which means it assumes that if the consequences are good then the proposal is good. It could be challenged by asking if the consequences alone are sufficient (is there a missing value premise?).” This is a bit aspirational, but it shows how the rich internal model can power helpful explanations or tips.
10. Living Documents and Summaries: Because an AIF-backed debate maintains structure, we can generate summaries or visual maps automatically. For example, one could switch to a “Summary View” where each top-level claim is listed with icons of arguments pro and con, maybe collapsing those that are resolved. Or produce a print-friendly outline of the debate where arguments are numbered and listed hierarchically (similar to argument mapping tools outputs). The structured data could also be used to feed an AI summarizer to produce a narrative summary (“Participants agreed on A and B, but disagreed on C. The main argument for C was X, which was undercut by Y.” – gleaned from the graph structure and labels like IN/OUT). While building such summaries is beyond AIF itself, having the structured input is the prerequisite. This aligns with Agora’s goal of debates becoming “living documents” and having persistent maps that can be revisited and understood without reading every post verbatim[82]. A well-presented argument map, enabled by our internal AIF graph, is crucial for that.
In implementing these UI features, we rely on AIF’s modularity: because pieces of arguments are discrete objects (nodes), we can show or hide or annotate them at will. It’s not a monolithic blob of text; it’s a network. We ensure that any visual element (like an icon or arrow) corresponds to a real structural element (like a CA-node) so that the user interactions have clear semantics. Conversely, any user intent we want to capture, we map to creating or manipulating these graph elements through intuitive controls. The design philosophy is: empower the user to do powerful argument moves with simple actions. For example, “Ask a follow-up critical question” might be a single click that behind the scenes creates a new node and connects it – the user just sees their question appear under the argument.
Finally, we must remain open to feedback. Not all users will want a very formal experience. The UI should default to a conversational feel (perhaps the threaded view, where the structure is a bit implicit), and offer the more structured views as enhancements (like turning on “Map mode” or “Logic mode”). As users get more comfortable, they can venture into those modes. The multi-modal UI approach – outline, graph, two-column, etc.[113] – will cater to different comfort levels and preferences.
In conclusion, by carefully designing the UI to present the AIF-driven features in user-centric ways, we turn the theoretical benefits of AIF into tangible improvements in user experience: clearer debates, guided critical thinking, and interactive visualizations. Agora will feel to the user like a smart debate assistant – it helps them structure their thoughts, reminds them of what to consider, and keeps track of the discourse – all without requiring them to be argumentation experts. Internally, that intelligence is our AIF-informed architecture doing the heavy lifting, while externally the user interface remains inviting and intuitive.
Diagram: AIF Mapped Debate Example
Figure: Illustrative AIF-based argument graph for a debate fragment. Rectangles are I-nodes (propositions), diamonds are S-nodes. Here, Claim “Harry was in Scotland” is supported by an argument with two premises (RA-node S1 taking “Harry was in Dundee” and “Dundee is in Scotland” to infer the claim). A counter-argument “Harry was in the US” rebuts the conclusion (CA-node S4 attacking the claim node), while “Bob is not reliable” undercuts the inference that “Harry was in Dundee” (CA-node S3 attacking the RA-node S2). This graph structure would be hidden from end-users; they would see a debate with claims and objections labeled as rebuttals or challenges to reasoning. The system, however, has this rich internal representation to ensure each attack hits the correct target and to enable analysis of the argument’s status.[120][121]
Conclusion and Next Steps
By integrating the Argument Interchange Format deeply into its backend, the Digital Agora can significantly enhance its ability to support rigorous, scalable deliberation. We have detailed how I-nodes, S-nodes, and L-nodes correspond to familiar entities like claims, arguments, and user moves, and how incorporating argumentation schemes and critical questions provides a built-in expert system for what moves to make next. The recommended implementation mappings show that most of AIF’s structure can be realized with moderate extensions to current models (Claims, Arguments, Edges, etc.), harnessing their existing properties and adding scheme/illocution metadata[106]. Where AIF’s abstractions add new capability (like distinguishing undercuts), we highlighted UI mechanisms to surface them in intuitive ways (non-jargon labels, visual cues)[64][5].
AIF will add value by eliminating ambiguity, enabling interoperability, and powering new analytic features. Users will indirectly feel this in a more guided and insightful debate experience – fewer misunderstandings about “what are you attacking?”, more prompts like “Have you considered this counter-argument?”, and visual maps that help make sense of complex discussions. At the same time, we remain cautious to introduce these features with thoughtful design to avoid overwhelming newcomers. Through toggles and progressive reveal of complexity, the Agora can cater to both casual discussants and advanced mappers.
The development plan following this analysis would include: (1) finalizing the data model changes and migrating data, (2) updating service logic (especially for posting moves/arguments and evaluating graphs), (3) implementing import/export and ensuring an example Agora debate exports correctly to AIF and imports back losslessly, (4) incrementally updating the UI to incorporate scheme-based interactions (CQ challenges, scheme display) and new visualizations (expandable argument diagrams, debate maps), and (5) thorough testing with actual use cases to refine the usability of these new features. By grounding each step in the AIF ontology, we ensure our enhancements are not ad-hoc but part of a coherent, research-backed framework for argumentation[49][122].
In sum, making AIF the native semantic model of Digital Agora will transform it from a structured forum into a living argumentation system: one that not only hosts debates, but understands and can reason about them. This robust foundation opens the door to many future possibilities – from integration with intelligent agents that can participate in or summarize debates, to linking multiple Agora instances into a federated Argument Web. The detailed guidance above aims to equip the product and engineering team with a clear blueprint to achieve this integration, ensuring that the power of AIF’s formalism translates into tangible improvements in user engagement and deliberation quality.
Sources:
Chesnevar et al. (2006). Towards an argument interchange format. [123][124]
Bex et al. (2013). Implementing the Argument Web. Communications of the ACM. [125][124]
Lawrence et al. (2012). AIFdb: Infrastructure for the Argument Web. [126]
Mesh Research Notes and Blueprint (2025). Internal design documents for Digital Agora. [49][127][53][111]
Formal Foundations Report (2025). Mapping argumentation theory to Agora implementation. [53][106]

[1] [3] [4] [5] [7] [8] [9] [10] [11] [12] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] [26] [29] [30] [31] [32] [33] [36] [39] [40] [41] [42] [48] [49] [50] [51] [52] [54] [55] [56] [57] [64] [65] [66] [67] [68] [69] [70] [74] [75] [76] [77] [78] [86] [87] [91] [92] [95] [96] [98] [99] [100] [101] [102] [103] [104] [107] [108] [115] [117] [122] MeshResearchNotes.txt
file://file-MubStvzhVaN8h7nRw9vfAS
[2] [6] [53] [93] [94] [106] Formal Foundations for the Mesh Digital Agora .txt
file://file-Qhxf3D7SUWWfwWnUk6TXZX
[13] [PDF] Revisiting computational models of argument schemes
https://pure.uva.nl/ws/files/38829644/FAIA305_0313.pdf
[25] DigitalAgoraRelevantAPIs.txt
file://file-LbVNQvRFjpWFgEY9Z4GhnE
[27] [28] [34] [35] [61] [71] [72] RelevantDigitalAgoraLibFilesCode.txt
file://file-HN63oVvBRjMidSBUjLi22r
[37] [38] ClaimAPIs.txt
file://file-QMSd1jWneVRb7A1t3Qg97B
[43] [44] [58] [90] [120] [121] florisbex.com
http://www.florisbex.com/papers/CarnAIF.pdf
[45] [79] [80] [81] [82] [83] [84] [85] [109] [110] [111] [112] [113] [114] Agora_GraphOfGraph_CollectiveAndLiving_KnowledgeFabricsRoadmap.txt
file://file-5jKLef6HtXEkvDfWFUQTK4
[46] [47] [105] [123] [124] [125] [126] Argument Interchange Format - Wikipedia
https://en.wikipedia.org/wiki/Argument_Interchange_Format
[59] [60] [62] [63] [73] [97] [116] [118] [119] [127] AgoraBlueprint.txt
file://file-V1zEUSuy6MfsqtnarytMDL
[88] [89] An AIF argument graph linked to the Forms Ontology | Download Scientific Diagram
https://www.researchgate.net/figure/An-AIF-argument-graph-linked-to-the-Forms-Ontology_fig2_221650992